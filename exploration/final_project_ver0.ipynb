{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/l-monninger/ahl/blob/main/exploration/final_project_ver0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project Intro"
      ],
      "metadata": {
        "id": "DAbJ46_qS9Jl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project Explanaiton here"
      ],
      "metadata": {
        "id": "Uo9PakCqUnCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setting"
      ],
      "metadata": {
        "id": "LT8uFeKcStGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation \n",
        "\n",
        "!pip install kaggle\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "_loNZ4a8d1zf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d62a17b-0125-4731-93bf-38eefedb817e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (1.5.13)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.9/dist-packages (3.4.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.9/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# libraries\n",
        "import json\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import * "
      ],
      "metadata": {
        "id": "es6wACvEeom8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to mount your drive (you will be prompted to sign in)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-tkHq-ad-fd",
        "outputId": "3ae73f3f-18ae-4656-cd94-be8030ee21eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "e0mX283VeGKC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start sparkSession\n",
        "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()"
      ],
      "metadata": {
        "id": "YbabJoju28h7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Wrangling\n"
      ],
      "metadata": {
        "id": "0d5tPX-8TDlw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Arxiv Data - ahreum\n"
      ],
      "metadata": {
        "id": "Pk1nHIimTgWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a. Import Data"
      ],
      "metadata": {
        "id": "gSi8L7odT4ue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Arxiv Data**\n",
        "* id: ArXiv ID (can be used to access the paper, see below)\n",
        "* submitter: Who submitted the paper\n",
        "* authors: Authors of the paper\n",
        "* title: Title of the paper\n",
        "* comments: Additional info, such as number of pages and figures\n",
        "* journal-ref: Information about the journal the paper was published in\n",
        "* doi: [https://www.doi.org](Digital Object Identifier)\n",
        "* abstract: The abstract of the paper\n",
        "* categories: Categories / tags in the ArXiv system\n",
        "* versions: A version history\n",
        "\n"
      ],
      "metadata": {
        "id": "G_NEy4RjydPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d Cornell-University/arxiv\n",
        "!unzip /content/arxiv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4o9zPtDeHTE",
        "outputId": "4e2c60da-1404-4a63-bdc7-35dac8f88994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading arxiv.zip to /content\n",
            " 99% 1.12G/1.14G [00:09<00:00, 112MB/s]\n",
            "100% 1.14G/1.14G [00:09<00:00, 128MB/s]\n",
            "Archive:  /content/arxiv.zip\n",
            "  inflating: arxiv-metadata-oai-snapshot.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_df = spark.read.json(\"arxiv-metadata-oai-snapshot.json\", multiLine = False, primitivesAsString = True)"
      ],
      "metadata": {
        "id": "zhBZkXVh0yIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FjOlhdp3YM0",
        "outputId": "8c64305d-0d9e-4a48-adee-ef6f2f4639d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+-----------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+------------------+--------------------+-----------+--------------------+\n",
            "|            abstract|             authors|      authors_parsed|       categories|            comments|                 doi|       id|         journal-ref|             license|           report-no|         submitter|               title|update_date|            versions|\n",
            "+--------------------+--------------------+--------------------+-----------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+------------------+--------------------+-----------+--------------------+\n",
            "|  A fully differe...|C. Bal\\'azs, E. L...|[[Balázs, C., ], ...|           hep-ph|37 pages, 15 figu...|10.1103/PhysRevD....|0704.0001|Phys.Rev.D76:0130...|                null|    ANL-HEP-PR-07-12|    Pavel Nadolsky|Calculation of pr...| 2008-11-26|[{Mon, 2 Apr 2007...|\n",
            "|  We describe a n...|Ileana Streinu an...|[[Streinu, Ileana...|    math.CO cs.CG|To appear in Grap...|                null|0704.0002|                null|http://arxiv.org/...|                null|      Louis Theran|Sparsity-certifyi...| 2008-12-13|[{Sat, 31 Mar 200...|\n",
            "|  The evolution o...|         Hongjun Pan|  [[Pan, Hongjun, ]]|   physics.gen-ph| 23 pages, 3 figures|                null|0704.0003|                null|                null|                null|       Hongjun Pan|The evolution of ...| 2008-01-13|[{Sun, 1 Apr 2007...|\n",
            "|  We show that a ...|        David Callan| [[Callan, David, ]]|          math.CO|            11 pages|                null|0704.0004|                null|                null|                null|      David Callan|A determinant of ...| 2007-05-23|[{Sat, 31 Mar 200...|\n",
            "|  In this paper w...|Wael Abu-Shammala...|[[Abu-Shammala, W...|  math.CA math.FA|                null|                null|0704.0005|Illinois J. Math....|                null|                null|Alberto Torchinsky|From dyadic $\\Lam...| 2013-10-15|[{Mon, 2 Apr 2007...|\n",
            "|  We study the tw...|Y. H. Pong and C....|[[Pong, Y. H., ],...|cond-mat.mes-hall|6 pages, 4 figure...|10.1103/PhysRevA....|0704.0006|                null|                null|                null|      Yue Hin Pong|Bosonic character...| 2015-05-13|[{Sat, 31 Mar 200...|\n",
            "|  A rather non-st...|Alejandro Corichi...|[[Corichi, Alejan...|            gr-qc|16 pages, no figu...|10.1103/PhysRevD....|0704.0007|Phys.Rev.D76:0440...|                null|        IGPG-07/03-2| Alejandro Corichi|Polymer Quantum M...| 2008-11-26|[{Sat, 31 Mar 200...|\n",
            "|  A general formu...|     Damian C. Swift|[[Swift, Damian C...|cond-mat.mtrl-sci|   Minor corrections|   10.1063/1.2975338|0704.0008|Journal of Applie...|http://arxiv.org/...|LA-UR-07-2051, LL...|      Damian Swift|Numerical solutio...| 2009-02-05|[{Sat, 31 Mar 200...|\n",
            "|  We discuss the ...|Paul Harvey, Brun...|[[Harvey, Paul, ]...|         astro-ph|                null|      10.1086/518646|0704.0009|Astrophys.J.663:1...|                null|                null|       Paul Harvey|The Spitzer c2d S...| 2010-03-18|[{Mon, 2 Apr 2007...|\n",
            "|  Partial cubes a...|  Sergei Ovchinnikov|[[Ovchinnikov, Se...|          math.CO|36 pages, 17 figures|                null|0704.0010|                null|                null|                null|Sergei Ovchinnikov|Partial cubes: st...| 2007-05-23|[{Sat, 31 Mar 200...|\n",
            "|  In this paper w...|Clifton Cunningha...|[[Cunningham, Cli...|  math.NT math.AG|14 pages; title c...|                null|0704.0011|                null|http://arxiv.org/...|                null|Clifton Cunningham|Computing genus 2...| 2008-08-20|[{Sat, 31 Mar 200...|\n",
            "|  Recently, Bruin...|         Dohoon Choi|  [[Choi, Dohoon, ]]|          math.NT|                null|                null|0704.0012|                null|                null|                null|       Dohoon Choi|Distribution of i...| 2007-05-23|[{Sat, 31 Mar 200...|\n",
            "|  Serre obtained ...|Dohoon Choi and Y...|[[Choi, Dohoon, ]...|          math.NT|                null|                null|0704.0013|                null|                null|                null|       Dohoon Choi|$p$-adic Limit of...| 2008-05-26|[{Sat, 31 Mar 200...|\n",
            "|  In this article...|        Koichi Fujii| [[Fujii, Koichi, ]]|  math.CA math.AT|  18 pages, 1 figure|                null|0704.0014|                null|                null|                null|      Koichi Fujii|Iterated integral...| 2009-09-29|[{Sun, 1 Apr 2007...|\n",
            "|  The pure spinor...|     Christian Stahn|[[Stahn, Christia...|           hep-th|22 pages; signs a...|10.1088/1126-6708...|0704.0015|  JHEP 0705:034,2007|                null|                null|   Christian Stahn|Fermionic superst...| 2009-11-13|[{Mon, 2 Apr 2007...|\n",
            "|  In this work, w...|Chao-Hsi Chang, T...|[[Chang, Chao-Hsi...|           hep-ph|17 pages, 3 figur...|10.1088/0253-6102...|0704.0016|Commun.Theor.Phys...|                null|                null|           Li Tong|Lifetime of doubl...| 2008-12-18|[{Sat, 31 Mar 200...|\n",
            "|  Results from sp...|Nceba Mhlahlo, Da...|[[Mhlahlo, Nceba,...|         astro-ph|10 pages, 11 figu...|10.1111/j.1365-29...|0704.0017|Mon.Not.Roy.Astro...|                null|                null|     Nceba Mhlahlo|Spectroscopic Obs...| 2009-06-23|[{Sat, 31 Mar 200...|\n",
            "|  We give a presc...|  Andreas Gustavsson|[[Gustavsson, And...|           hep-th|20 pages, v2: an ...|                null|0704.0018|                null|                null|                null|Andreas Gustavsson|In quest of a gen...| 2007-05-23|[{Mon, 2 Apr 2007...|\n",
            "|  In this note we...|         Norio Konno|  [[Konno, Norio, ]]|  math.PR math.AG|6 pages, Journal-...|                null|0704.0019|RIMS Kokyuroku, N...|                null|                null|       Norio Konno|Approximation for...| 2007-06-23|[{Sat, 31 Mar 200...|\n",
            "|  The shape of th...|The BABAR Collabo...|[[The BABAR Colla...|           hep-ex|21 pages, 13 post...|10.1103/PhysRevD....|0704.0020|Phys.Rev.D76:0520...|                null|BABAR-PUB-07/015,...|   Patrick Roudeau|Measurement of th...| 2015-06-30|[{Sat, 31 Mar 200...|\n",
            "+--------------------+--------------------+--------------------+-----------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+------------------+--------------------+-----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b. Authors Analysis\n",
        "\n",
        "- authors article count (counted by all authors based, merged by first author)\n",
        "- collaboration T/F"
      ],
      "metadata": {
        "id": "HpulOOIyUA0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_df = arxiv_df.withColumn('first_author', regexp_replace(concat_ws(\" \", element_at(\"authors_parsed\", 1)), \",\", \"\"))\n",
        "arxiv_df = arxiv_df.withColumn(\"first_author\", trim('first_author'))\n"
      ],
      "metadata": {
        "id": "V_5HutncIfXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "author_flattened_ver = arxiv_df.selectExpr(\"*\", \"explode(authors_parsed) as authors_flat\")\n",
        "count_df = author_flattened_ver.withColumn('authors_join', regexp_replace(concat_ws(\" \", \"authors_flat\"), \",\", \"\"))\n",
        "count_df = count_df.withColumn(\"authors_join\", trim(count_df.authors_join))\n",
        "count_df = count_df.groupBy(\"authors_join\").agg(count('*').alias('article_counts_1st'))\n",
        "count_df = count_df.orderBy('article_counts_1st', ascending= False)\n",
        "count_df.show()"
      ],
      "metadata": {
        "id": "iGPwKpbNHpLA",
        "outputId": "f843435f-ba04-4f24-9b06-1c58e2e38a8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------------+\n",
            "|       authors_join|article_count|\n",
            "+-------------------+-------------+\n",
            "|           Zhang Y.|         2187|\n",
            "|            Wang Y.|         1536|\n",
            "|            Wang J.|         1433|\n",
            "|              Li Y.|         1359|\n",
            "|           Liu Yang|         1260|\n",
            "|           Zhang L.|         1247|\n",
            "|           Wang Wei|         1196|\n",
            "|             Liu X.|         1195|\n",
            "|             Gao Y.|         1181|\n",
            "|  CMS Collaboration|         1175|\n",
            "|  Taniguchi Takashi|         1165|\n",
            "|            Wang Z.|         1139|\n",
            "|     Watanabe Kenji|         1126|\n",
            "|ATLAS Collaboration|         1073|\n",
            "|            Yang Z.|         1038|\n",
            "|             Sun L.|         1015|\n",
            "|          Zhang Lei|          982|\n",
            "|              Xu Z.|          936|\n",
            "|        Krokovny P.|          936|\n",
            "|          Zhang Wei|          935|\n",
            "+-------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_df.filter(col('authors_join') == 'Zhang Y.').select('article_counts_1st').show()"
      ],
      "metadata": {
        "id": "r81JGKxFL1fB",
        "outputId": "4f150854-68af-4da4-b01a-8eb309b15368",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|article_count|\n",
            "+-------------+\n",
            "|         2187|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_df.filter(col('1st_author')=='Zhang Y.').show()"
      ],
      "metadata": {
        "id": "uc_DE0bV-L5l",
        "outputId": "85746898-b6ee-4c84-b5c5-c8b7500f9cdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+----------+\n",
            "|            abstract|             authors|      authors_parsed|          categories|            comments|                 doi|       id|         journal-ref|             license|report-no|           submitter|               title|update_date|            versions|1st_author|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+----------+\n",
            "|  We investigate ...|Y. Zhang, G. Liu,...|[[Zhang, Y., ], [...|cond-mat.mes-hall...|                null|                null|0708.3118|                null|                null|     null|Chun Ning (Jeanie...|Phase Diffusion i...| 2007-08-24|[{Thu, 23 Aug 200...|  Zhang Y.|\n",
            "|  With the availa...|Y. Zhang, Y. Zhao...|[[Zhang, Y., ], [...|            astro-ph|10 pages. accepte...|10.1016/j.asr.200...|0708.4273|Adv.Space Res.41:...|                null|     null|        Yanxia Zhang|Decision table fo...| 2009-09-29|[{Fri, 31 Aug 200...|  Zhang Y.|\n",
            "|  In this paper w...|Y. Zhang, W. Zhao...|[[Zhang, Y., ], [...|            astro-ph|28 pages, 11 figu...|10.1142/S02182718...|0806.2243|                null|http://creativeco...|     null|        Tianyang Xia|Relic Gravitation...| 2009-11-13|[{Fri, 13 Jun 200...|  Zhang Y.|\n",
            "|  The nature of s...|Y. Zhang, J. Wei,...|[[Zhang, Y., ], [...|cond-mat.supr-con...|  5 pages, 4 figures|10.1103/PhysRevLe...|0808.2738|Phys. Rev. Lett. ...|http://arxiv.org/...|     null|           Yan Zhang|Correlation effec...| 2013-05-29|[{Wed, 20 Aug 200...|  Zhang Y.|\n",
            "|  Ca3CoMnO6 is co...|Y. Zhang, H. J. X...|[[Zhang, Y., ], [...|   cond-mat.mtrl-sci|Phys. Rev. B, in ...|10.1103/PhysRevB....|0809.1234|                null|http://arxiv.org/...|     null|        Mike Whangbo|Interplay between...| 2009-11-13|[{Sun, 7 Sep 2008...|  Zhang Y.|\n",
            "|  We have used th...|Y. Zhang, H.-B. Y...|[[Zhang, Y., ], [...|         astro-ph.SR|19 pages, 6 figur...|10.1088/0004-637X...|0901.1411|Astrophys.J.695:4...|http://arxiv.org/...|     null|          Yong Zhang|Electron Temperat...| 2011-02-11|[{Sun, 11 Jan 200...|  Zhang Y.|\n",
            "|  The unconventio...|Y. Zhang, F. Chen...|[[Zhang, Y., ], [...|cond-mat.supr-con...|7 pages, 8 figure...|10.1103/PhysRevB....|0904.4022|Phys. Rev. B 83, ...|http://arxiv.org/...|     null|           Yan Zhang|The orbital chara...| 2011-02-25|[{Sun, 26 Apr 200...|  Zhang Y.|\n",
            "|  The electronic ...|Y. Zhang, F. Chen...|[[Zhang, Y., ], [...|cond-mat.supr-con...|  5 pages, 4 figures|10.1103/PhysRevB....|1001.5327|Phys. Rev. B 82, ...|http://arxiv.org/...|     null|           Yan Zhang|Strong correlatio...| 2010-10-15|[{Fri, 29 Jan 201...|  Zhang Y.|\n",
            "|  With LIGO havin...|Y. Zhang, M.L. To...|[[Zhang, Y., ], [...|   gr-qc astro-ph.CO|4 figures, 1 tabl...|10.1103/PhysRevD....|1004.2944|Phys.Rev.D81:1015...|http://arxiv.org/...|     null|         Zhengwen Fu|Constraints upon ...| 2010-05-25|[{Sat, 17 Apr 201...|  Zhang Y.|\n",
            "|  The three-dimen...|Y. Zhang, L. X. Y...|[[Zhang, Y., ], [...|   cond-mat.supr-con|  5 pages, 4 figures|                null|1006.3936|Physical Review L...|http://arxiv.org/...|     null|           Yan Zhang|Out-of-plane mome...| 2010-09-14|[{Sun, 20 Jun 201...|  Zhang Y.|\n",
            "|  The low energy ...|Y. Zhang, L. X. Y...|[[Zhang, Y., ], [...|   cond-mat.supr-con|4 pages, 4 figure...|    10.1038/NMAT2981|1012.5980|Nature Materials ...|http://arxiv.org/...|     null|           Yan Zhang|Heavily electron-...| 2011-04-15|[{Wed, 29 Dec 201...|  Zhang Y.|\n",
            "|  The superconduc...|Y. Zhang, Z. R. Y...|[[Zhang, Y., ], [...|   cond-mat.supr-con|6 pages, 4 figure...|   10.1038/nphys2248|1109.0229|Nature Physics 8,...|http://arxiv.org/...|     null|           Yan Zhang|Nodal superconduc...| 2012-05-09|[{Thu, 1 Sep 2011...|  Zhang Y.|\n",
            "|  We report the d...|Y. Zhang, R. I. H...|[[Zhang, Y., ], [...|         astro-ph.HE|7 pages, 5 figure...|10.1111/j.1365-29...|1110.1267|                null|http://arxiv.org/...|     null|          Yuan Zhang|Millihertz Quasi-...| 2015-05-30|[{Thu, 6 Oct 2011...|  Zhang Y.|\n",
            "|  The superconduc...|Y. Zhang, C. He, ...|[[Zhang, Y., ], [...|cond-mat.supr-con...| 11 pages, 9 figures|10.1103/PhysRevB....|1111.6430|Phys. Rev. B 85, ...|http://arxiv.org/...|     null|           Yan Zhang|Symmetry breaking...| 2012-02-28|[{Mon, 28 Nov 201...|  Zhang Y.|\n",
            "|  We measure radi...|Y. Zhang, W. Ong,...|[[Zhang, Y., ], [...|  cond-mat.quant-gas|5 pages, 4 figure...|10.1103/PhysRevLe...|1201.3560|PRL 108, 235302 (...|http://arxiv.org/...|     null|        J. E. Thomas|Polarons in the r...| 2012-06-28|[{Tue, 17 Jan 201...|  Zhang Y.|\n",
            "|  We present a ne...|Y. Zhang, R. Kita...|[[Zhang, Y., ], [...|         astro-ph.SR|                null|10.1088/0004-637X...|1203.2096|                null|http://arxiv.org/...|     null|           Yin Zhang|Magnetic helicity...| 2015-06-04|[{Fri, 9 Mar 2012...|  Zhang Y.|\n",
            "|  NGC 2392 is a y...|Y. Zhang, X. Fang...|[[Zhang, Y., ], [...|         astro-ph.SR|41 pages, 13 figu...|10.1088/0004-637X...|1205.3470|                null|http://arxiv.org/...|     null|          Yong Zhang|[Fe III] emission...| 2015-06-05|[{Tue, 15 May 201...|  Zhang Y.|\n",
            "|  The giant halos...|Y. Zhang, M. Mats...|[[Zhang, Y., ], [...|             nucl-th|                null|10.1103/PhysRevC....|1209.5263|Physical Review C...|http://arxiv.org/...|     null|          Ying Zhang|Pair correlation ...| 2013-10-08|[{Mon, 24 Sep 201...|  Zhang Y.|\n",
            "|  This paper buil...|            Y. Zhang|     [[Zhang, Y., ]]|             math.OC|            27 pages|                null|1301.6321|                null|http://arxiv.org/...|     null|        Yubiao Zhang|Two equivalence t...| 2013-01-29|[{Sun, 27 Jan 201...|  Zhang Y.|\n",
            "|  We compute the ...|Y. Zhang, S. G. W...|[[Zhang, Y., ], [...|   gr-qc astro-ph.HE|  5 pages, 6 figures|                null|1305.1122|                null|http://arxiv.org/...|     null|            Wen Zhao|Gravitational-Wav...| 2013-05-07|[{Mon, 6 May 2013...|  Zhang Y.|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_df = arxiv_df.join(count_df, arxiv_df.first_author == count_df.authors_join, \"left\")\n",
        "arxiv_df.show(10)"
      ],
      "metadata": {
        "id": "NYq-vRGTLfUj",
        "outputId": "cad19b0d-bd55-4ee4-9a87-f12bd5f8fc74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+-------------+\n",
            "|            abstract|             authors|      authors_parsed|          categories|            comments|                 doi|              id|         journal-ref|             license|           report-no|           submitter|               title|update_date|            versions|        first_author|        authors_join|article_count|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+-------------+\n",
            "|  A search for th...| ATLAS Collaboration|[[ATLAS Collabora...|              hep-ex|6 pages plus auth...|10.1103/PhysRevLe...|      1501.03276|Phys. Rev. Lett. ...|http://arxiv.org/...| CERN-PH-EP-2014-294|  Atlas Publications|Search for Higgs ...| 2015-04-01|[{Wed, 14 Jan 201...| ATLAS Collaboration| ATLAS Collaboration|         1073|\n",
            "|  We study a clas...|El Houcein El Abd...|[[Abdalaoui, El H...|math.DS math.CV m...|16 pages. Accepte...|                null|       1206.0493|                null|http://arxiv.org/...|                null|El Houcein El Abd...|Generalized Riesz...| 2014-12-22|[{Sun, 3 Jun 2012...|Abdalaoui El Houc...|Abdalaoui El Houc...|            9|\n",
            "|  In this paper, ...|Ahmed Aboudonia, ...|[[Aboudonia, Ahme...|       eess.SY cs.SY|                null|                null|      2005.04077|                null|http://arxiv.org/...|                null|     Ahmed Aboudonia|Distributed Model...| 2020-05-11|[{Fri, 8 May 2020...|     Aboudonia Ahmed|     Aboudonia Ahmed|            8|\n",
            "|  In this paper w...|Wael Abu-Shammala...|[[Abu-Shammala, W...|     math.CA math.FA|                null|                null|       0704.0005|Illinois J. Math....|                null|                null|  Alberto Torchinsky|From dyadic $\\Lam...| 2013-10-15|[{Mon, 2 Apr 2007...|   Abu-Shammala Wael|   Abu-Shammala Wael|            3|\n",
            "|  We propose a ma...|Pasquale Claudio ...|[[Africa, Pasqual...| math.NA cs.MS cs.NA|                null|10.1016/j.jcp.202...|      2205.05136|                null|http://creativeco...|                null|Pasquale Claudio ...|A matrix-free hig...| 2023-03-01|[{Tue, 10 May 202...|Africa Pasquale C...|Africa Pasquale C...|            9|\n",
            "|  The Android ope...|Mohammed K. Alzay...|[[Alzaylaee, Moha...|cs.CR cs.LG cs.NE...|                null|10.1016/j.cose.20...|      1911.10113|                null|http://creativeco...|                null|Mohammed K Alzayl...|DL-Droid: Deep le...| 2019-11-25|[{Fri, 22 Nov 201...|Alzaylaee Mohamme...|Alzaylaee Mohamme...|            6|\n",
            "|  We study the in...|R. E. Amritkar an...|[[Amritkar, R. E....|nlin.CD cond-mat....|  4 pages, 2 figures|10.1103/PhysRevLe...|    nlin/0602041|Physical Review L...|                null|                null|   Ravindra Amritkar|Spatial synchroni...| 2009-11-11|[{Mon, 20 Feb 200...|      Amritkar R. E.|      Amritkar R. E.|           31|\n",
            "|  We have studied...|James G. Analytis...|[[Analytis, James...|cond-mat.supr-con...| 9 pages, 11 figures|                null|       0810.5368|                null|http://arxiv.org/...|                null|      James Analytis|Bulk superconduct...| 2008-11-07|[{Thu, 30 Oct 200...|   Analytis James G.|   Analytis James G.|           67|\n",
            "|  For the first t...|N.S. Ananikian, S...|[[Ananikian, N. S...|            cond-mat|LaTeX file, 10 pa...|10.1016/0375-9601...|cond-mat/9508137|                null|                null|Preprint IC/95/10...|    Nerses Ananikian|Chaotic Repellers...| 2009-10-28|[{Wed, 30 Aug 199...|     Ananikian N. S.|     Ananikian N. S.|           31|\n",
            "|  We study variat...|     Giuseppe Ancona|[[Ancona, Giusepp...|     math.AG math.NT|       final version|10.1142/S17930421...|       1403.5187|International Jou...|http://arxiv.org/...|                null|     Giuseppe Ancona|Degeneration of H...| 2017-02-15|[{Thu, 20 Mar 201...|     Ancona Giuseppe|     Ancona Giuseppe|           10|\n",
            "|  Understanding h...|Ronda-Pupo Guille...|[[Armando, Ronda-...|cs.SI cs.DL physi...|            25 Pages|10.1007/s11192-01...|      1710.08688|Published in Scie...|http://arxiv.org/...|                null|Guillermo Armando...|The Evolutions of...| 2018-10-25|[{Tue, 24 Oct 201...|Armando Ronda-Pup...|Armando Ronda-Pup...|            1|\n",
            "|  We study the co...|Srinivasan Arunac...|[[Arunachalam, Sr...|      cs.CC quant-ph|30 Pages; several...|                null|      2005.04068|                null|http://arxiv.org/...|                null|Srinivasan Arunac...|Communication mem...| 2020-09-10|[{Fri, 8 May 2020...|Arunachalam Srini...|Arunachalam Srini...|           27|\n",
            "|  Let K be an alg...|Ivan Arzhantsev a...|[[Arzhantsev, Iva...|             math.AG|            12 pages|                null|      1501.03270|Documenta Mathema...|http://arxiv.org/...|                null|     Ivan Arzhantsev|Equivariant embed...| 2015-10-21|[{Wed, 14 Jan 201...|     Arzhantsev Ivan|     Arzhantsev Ivan|           27|\n",
            "|  In this note we...|         Nikos Bagis|  [[Bagis, Nikos, ]]|             math.GM|12 pages, ellipti...|                null|       1305.1591|                null|http://arxiv.org/...|                null|     Nikolaos Bagkis|On Algebraic Func...| 2014-03-28|[{Sun, 5 May 2013...|         Bagis Nikos|         Bagis Nikos|           38|\n",
            "|  Giant impacts b...|C.A.L. Bailer-Jon...|[[Bailer-Jones, C...|astro-ph.EP astro...|Minor typos corre...|10.1111/j.1365-29...|       1105.4100|MNRAS 416, 1163-1...|http://arxiv.org/...|                null|  Coryn Bailer-Jones|Bayesian time ser...| 2015-05-28|[{Fri, 20 May 201...|Bailer-Jones C. A...|Bailer-Jones C. A...|            9|\n",
            "|  In this paper, ...|Zhigang Bao, Guan...|[[Bao, Zhigang, ]...|math.PR math-ph m...|            39 pages|10.1007/s10955-01...|       1206.0508|                null|http://arxiv.org/...|                null|           Wang Zhou|Central limit the...| 2015-06-05|[{Mon, 4 Jun 2012...|         Bao Zhigang|         Bao Zhigang|           30|\n",
            "|  In this report ...|Daniel Bauer, Jam...|[[Bauer, Daniel, ...|hep-ph astro-ph.C...|Report prepared f...|10.1016/j.dark.20...|       1305.1605|Phys. Dark Univ. ...|http://arxiv.org/...|                null|  Konstantin Matchev|Dark Matter in th...| 2015-07-06|[{Tue, 7 May 2013...|        Bauer Daniel|        Bauer Daniel|            9|\n",
            "|  Scalar particle...|Martin Bauer (U. ...|[[Bauer, Martin, ...|              hep-ph|  6 pages, 2 figures|                null|      1607.01016|                null|http://arxiv.org/...|         MITP/16-067|    Matthias Neubert|The \"forgotten\" d...| 2016-07-06|[{Mon, 4 Jul 2016...|Bauer Martin  U. ...|Bauer Martin  U. ...|            3|\n",
            "|  Let $A$ be a no...|        Charlie Beil| [[Beil, Charlie, ]]|             math.RA|20 pages. This pa...|                null|      1805.08047|Journal of Algebr...|http://arxiv.org/...|                null|        Charlie Beil|Noetherian criter...| 2021-09-13|[{Mon, 21 May 201...|        Beil Charlie|        Beil Charlie|           22|\n",
            "|  The Large Scale...|David Bellamy and...|[[Bellamy, David,...|       cs.LG stat.ML|                null|                null|      2010.01149|                null|http://arxiv.org/...|                null|         Andrew Beam|Evaluating Progre...| 2020-10-06|[{Fri, 2 Oct 2020...|       Bellamy David|       Bellamy David|            1|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_df = arxiv_df.withColumn('collab_tf', when(lower(col('authors')).contains('collaboration'), 1).otherwise(0))"
      ],
      "metadata": {
        "id": "GBqf2h3sAONM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_df.groupBy('collab_tf').agg(count('*').alias('count')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de11242-d956-4586-f48d-60696a4ee575",
        "id": "J2KSsgof7Mw2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+\n",
            "|collab_tf|  count|\n",
            "+---------+-------+\n",
            "|        1|  24873|\n",
            "|        0|2206644|\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### c. Category Name Mapping"
      ],
      "metadata": {
        "id": "HHG1-8o-UNr5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**category name mapping** \n",
        "\n",
        "- parsing from arxiv official taxonomy web page \"https://arxiv.org/category_taxonomy\" : \n",
        "**currently parsing is blocked. Trying to use another way.**\n"
      ],
      "metadata": {
        "id": "Glvcgmbp7ifo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_df.withColumn('categories_parsed', concat_ws(\" \", \"categories\")).show()"
      ],
      "metadata": {
        "id": "1y6TWNW0RfmV",
        "outputId": "f9997532-28d9-4f9a-ccf4-c67d1cb605ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+------------------+---------+--------------------+\n",
            "|            abstract|             authors|      authors_parsed|          categories|            comments|                 doi|              id|         journal-ref|             license|           report-no|           submitter|               title|update_date|            versions|        first_author|        authors_join|article_counts_1st|collab_tf|   categories_parsed|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+------------------+---------+--------------------+\n",
            "|  A search for th...| ATLAS Collaboration|[[ATLAS Collabora...|              hep-ex|6 pages plus auth...|10.1103/PhysRevLe...|      1501.03276|Phys. Rev. Lett. ...|http://arxiv.org/...| CERN-PH-EP-2014-294|  Atlas Publications|Search for Higgs ...| 2015-04-01|[{Wed, 14 Jan 201...| ATLAS Collaboration| ATLAS Collaboration|              1073|        1|              hep-ex|\n",
            "|  We study a clas...|El Houcein El Abd...|[[Abdalaoui, El H...|math.DS math.CV m...|16 pages. Accepte...|                null|       1206.0493|                null|http://arxiv.org/...|                null|El Houcein El Abd...|Generalized Riesz...| 2014-12-22|[{Sun, 3 Jun 2012...|Abdalaoui El Houc...|Abdalaoui El Houc...|                 9|        0|math.DS math.CV m...|\n",
            "|  In this paper, ...|Ahmed Aboudonia, ...|[[Aboudonia, Ahme...|       eess.SY cs.SY|                null|                null|      2005.04077|                null|http://arxiv.org/...|                null|     Ahmed Aboudonia|Distributed Model...| 2020-05-11|[{Fri, 8 May 2020...|     Aboudonia Ahmed|     Aboudonia Ahmed|                 8|        0|       eess.SY cs.SY|\n",
            "|  In this paper w...|Wael Abu-Shammala...|[[Abu-Shammala, W...|     math.CA math.FA|                null|                null|       0704.0005|Illinois J. Math....|                null|                null|  Alberto Torchinsky|From dyadic $\\Lam...| 2013-10-15|[{Mon, 2 Apr 2007...|   Abu-Shammala Wael|   Abu-Shammala Wael|                 3|        0|     math.CA math.FA|\n",
            "|  We propose a ma...|Pasquale Claudio ...|[[Africa, Pasqual...| math.NA cs.MS cs.NA|                null|10.1016/j.jcp.202...|      2205.05136|                null|http://creativeco...|                null|Pasquale Claudio ...|A matrix-free hig...| 2023-03-01|[{Tue, 10 May 202...|Africa Pasquale C...|Africa Pasquale C...|                 9|        0| math.NA cs.MS cs.NA|\n",
            "|  The Android ope...|Mohammed K. Alzay...|[[Alzaylaee, Moha...|cs.CR cs.LG cs.NE...|                null|10.1016/j.cose.20...|      1911.10113|                null|http://creativeco...|                null|Mohammed K Alzayl...|DL-Droid: Deep le...| 2019-11-25|[{Fri, 22 Nov 201...|Alzaylaee Mohamme...|Alzaylaee Mohamme...|                 6|        0|cs.CR cs.LG cs.NE...|\n",
            "|  We study the in...|R. E. Amritkar an...|[[Amritkar, R. E....|nlin.CD cond-mat....|  4 pages, 2 figures|10.1103/PhysRevLe...|    nlin/0602041|Physical Review L...|                null|                null|   Ravindra Amritkar|Spatial synchroni...| 2009-11-11|[{Mon, 20 Feb 200...|      Amritkar R. E.|      Amritkar R. E.|                31|        0|nlin.CD cond-mat....|\n",
            "|  We have studied...|James G. Analytis...|[[Analytis, James...|cond-mat.supr-con...| 9 pages, 11 figures|                null|       0810.5368|                null|http://arxiv.org/...|                null|      James Analytis|Bulk superconduct...| 2008-11-07|[{Thu, 30 Oct 200...|   Analytis James G.|   Analytis James G.|                67|        0|cond-mat.supr-con...|\n",
            "|  For the first t...|N.S. Ananikian, S...|[[Ananikian, N. S...|            cond-mat|LaTeX file, 10 pa...|10.1016/0375-9601...|cond-mat/9508137|                null|                null|Preprint IC/95/10...|    Nerses Ananikian|Chaotic Repellers...| 2009-10-28|[{Wed, 30 Aug 199...|     Ananikian N. S.|     Ananikian N. S.|                31|        0|            cond-mat|\n",
            "|  We study variat...|     Giuseppe Ancona|[[Ancona, Giusepp...|     math.AG math.NT|       final version|10.1142/S17930421...|       1403.5187|International Jou...|http://arxiv.org/...|                null|     Giuseppe Ancona|Degeneration of H...| 2017-02-15|[{Thu, 20 Mar 201...|     Ancona Giuseppe|     Ancona Giuseppe|                10|        0|     math.AG math.NT|\n",
            "|  Understanding h...|Ronda-Pupo Guille...|[[Armando, Ronda-...|cs.SI cs.DL physi...|            25 Pages|10.1007/s11192-01...|      1710.08688|Published in Scie...|http://arxiv.org/...|                null|Guillermo Armando...|The Evolutions of...| 2018-10-25|[{Tue, 24 Oct 201...|Armando Ronda-Pup...|Armando Ronda-Pup...|                 1|        0|cs.SI cs.DL physi...|\n",
            "|  We study the co...|Srinivasan Arunac...|[[Arunachalam, Sr...|      cs.CC quant-ph|30 Pages; several...|                null|      2005.04068|                null|http://arxiv.org/...|                null|Srinivasan Arunac...|Communication mem...| 2020-09-10|[{Fri, 8 May 2020...|Arunachalam Srini...|Arunachalam Srini...|                27|        0|      cs.CC quant-ph|\n",
            "|  Let K be an alg...|Ivan Arzhantsev a...|[[Arzhantsev, Iva...|             math.AG|            12 pages|                null|      1501.03270|Documenta Mathema...|http://arxiv.org/...|                null|     Ivan Arzhantsev|Equivariant embed...| 2015-10-21|[{Wed, 14 Jan 201...|     Arzhantsev Ivan|     Arzhantsev Ivan|                27|        0|             math.AG|\n",
            "|  In this note we...|         Nikos Bagis|  [[Bagis, Nikos, ]]|             math.GM|12 pages, ellipti...|                null|       1305.1591|                null|http://arxiv.org/...|                null|     Nikolaos Bagkis|On Algebraic Func...| 2014-03-28|[{Sun, 5 May 2013...|         Bagis Nikos|         Bagis Nikos|                38|        0|             math.GM|\n",
            "|  Giant impacts b...|C.A.L. Bailer-Jon...|[[Bailer-Jones, C...|astro-ph.EP astro...|Minor typos corre...|10.1111/j.1365-29...|       1105.4100|MNRAS 416, 1163-1...|http://arxiv.org/...|                null|  Coryn Bailer-Jones|Bayesian time ser...| 2015-05-28|[{Fri, 20 May 201...|Bailer-Jones C. A...|Bailer-Jones C. A...|                 9|        0|astro-ph.EP astro...|\n",
            "|  In this paper, ...|Zhigang Bao, Guan...|[[Bao, Zhigang, ]...|math.PR math-ph m...|            39 pages|10.1007/s10955-01...|       1206.0508|                null|http://arxiv.org/...|                null|           Wang Zhou|Central limit the...| 2015-06-05|[{Mon, 4 Jun 2012...|         Bao Zhigang|         Bao Zhigang|                30|        0|math.PR math-ph m...|\n",
            "|  In this report ...|Daniel Bauer, Jam...|[[Bauer, Daniel, ...|hep-ph astro-ph.C...|Report prepared f...|10.1016/j.dark.20...|       1305.1605|Phys. Dark Univ. ...|http://arxiv.org/...|                null|  Konstantin Matchev|Dark Matter in th...| 2015-07-06|[{Tue, 7 May 2013...|        Bauer Daniel|        Bauer Daniel|                 9|        0|hep-ph astro-ph.C...|\n",
            "|  Scalar particle...|Martin Bauer (U. ...|[[Bauer, Martin, ...|              hep-ph|  6 pages, 2 figures|                null|      1607.01016|                null|http://arxiv.org/...|         MITP/16-067|    Matthias Neubert|The \"forgotten\" d...| 2016-07-06|[{Mon, 4 Jul 2016...|Bauer Martin  U. ...|Bauer Martin  U. ...|                 3|        0|              hep-ph|\n",
            "|  Let $A$ be a no...|        Charlie Beil| [[Beil, Charlie, ]]|             math.RA|20 pages. This pa...|                null|      1805.08047|Journal of Algebr...|http://arxiv.org/...|                null|        Charlie Beil|Noetherian criter...| 2021-09-13|[{Mon, 21 May 201...|        Beil Charlie|        Beil Charlie|                22|        0|             math.RA|\n",
            "|  The Large Scale...|David Bellamy and...|[[Bellamy, David,...|       cs.LG stat.ML|                null|                null|      2010.01149|                null|http://arxiv.org/...|                null|         Andrew Beam|Evaluating Progre...| 2020-10-06|[{Fri, 2 Oct 2020...|       Bellamy David|       Bellamy David|                 1|        0|       cs.LG stat.ML|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+------------------+---------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tXEp1kWiSMa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_map_dict = {}\n",
        "cat_map_dict['cs'] = 'Computer Science'\n",
        "cat_map_dict['econ'] = 'Economics'\n",
        "cat_map_dict['eess'] = 'Electrical Engineering and Systems Science'\n",
        "cat_map_dict['math'] =  'Mathematics'\n",
        "cat_map_dict['astro-ph'] = 'Astrophysics'\n",
        "cat_map_dict['cond-mat'] = 'Condensed Matter'\n",
        "cat_map_dict['gr-qc'] = 'General Relativity and Quantum Cosmology'\n",
        "cat_map_dict['hep-ex'] =  'High Energy Physics - Experiment'\n",
        "cat_map_dict['hep-lat'] = 'High Energy Physics - Lattice'\n",
        "cat_map_dict['hep-ph'] =  'High Energy Physics - Phenomenology'\n",
        "cat_map_dict['hep-th'] = 'High Energy Physics - Theory'\n",
        "cat_map_dict['math-ph'] = 'Mathematical Physics'\n",
        "cat_map_dict['nlin'] = 'Nonlinear Sciences'\n",
        "cat_map_dict['nucl-ex'] = 'Nuclear Experiment'\n",
        "cat_map_dict['nucl-th'] =  'Nuclear Theory'\n",
        "cat_map_dict['physics'] = 'Physics'\n",
        "cat_map_dict['quant-ph'] = 'Quantum Physics'\n",
        "cat_map_dict['q-bio'] = 'Quantitative Biology'\n",
        "cat_map_dict['q-fin'] = 'Quantitative Finance'\n",
        "cat_map_dict['stat'] = 'Statistics'"
      ],
      "metadata": {
        "id": "J4VO_gBkSF2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dzAmT3FeSHX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parsing version below"
      ],
      "metadata": {
        "id": "HZRQygl9SHtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from lxml import etree\n",
        "import json\n",
        "\n",
        "method_name = 'query'\n",
        "parameters = 'id:all'\n",
        "url = f\"http://export.arxiv.org/api/{method_name}?{parameters}\"\n",
        "\n",
        "import urllib.request as libreq\n",
        "with libreq.urlopen(url) as url:\n",
        "  r = url.readlines()\n",
        "print(r)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVSy3pQUcdbW",
        "outputId": "457c93f6-5f96-47c1-ab80-3b5c7f0b90ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n', b'<feed xmlns=\"http://www.w3.org/2005/Atom\">\\n', b'  <link href=\"http://arxiv.org/api/query?search_query%3D%26id_list%3D%26start%3D0%26max_results%3D10\" rel=\"self\" type=\"application/atom+xml\"/>\\n', b'  <title type=\"html\">ArXiv Query: search_query=&amp;id_list=&amp;start=0&amp;max_results=10</title>\\n', b'  <id>http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM</id>\\n', b'  <updated>2023-04-15T00:00:00-04:00</updated>\\n', b'  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:totalResults>\\n', b'  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\\n', b'  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">10</opensearch:itemsPerPage>\\n', b'</feed>\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from lxml import etree\n",
        "\n",
        "url = \"https://arxiv.org/category_taxonomy\"\n",
        "\n",
        "response = requests.get(url)\n",
        "# print(response)\n",
        "categories = pd.DataFrame(columns=['cat_id', 'main_category','sub_category'])\n",
        "if response.status_code == 200:\n",
        "    parser = etree.HTMLParser()\n",
        "    tree = etree.fromstring(response.content, parser=parser)\n",
        "\n",
        "    for x, y in zip(tree.xpath(\"//*[@id='category_taxonomy_list']//h4/text()\"), tree.xpath(\"//*[@id='category_taxonomy_list']//h4/span/text()\")):\n",
        "      cat_id = x.strip()\n",
        "      sub_cat = y.strip(\"()\").strip()\n",
        "      big_cat = cat_id.split(\".\")[0]\n",
        "      categories = pd.concat([categories, pd.DataFrame({'cat_id': [cat_id], 'main_category' : [big_cat], 'sub_category': [sub_cat]})], ignore_index=True)\n",
        "    \n",
        "    big_category = tree.xpath(\"//*[@id='category_taxonomy_list']/h2/text()\") + tree.xpath(\"//*[@id='category_taxonomy_list']//h3/text()\")\n",
        "categories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "Eyp4RTsS61Qb",
        "outputId": "be8216f3-2580-42a6-bcc6-0f6eaed1423b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [cat_id, main_category, sub_category]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc161247-8aeb-45ce-bb18-bf4ca0e05c74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat_id</th>\n",
              "      <th>main_category</th>\n",
              "      <th>sub_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc161247-8aeb-45ce-bb18-bf4ca0e05c74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc161247-8aeb-45ce-bb18-bf4ca0e05c74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc161247-8aeb-45ce-bb18-bf4ca0e05c74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request as libreq\n",
        "import feedparser\n",
        "\n",
        "\n",
        "# Base api query url\n",
        "base_url = 'http://export.arxiv.org/api/query?';\n",
        "search_query = 'search_query=all:electron' # search for electron in all fields\n",
        "\n",
        "# perform a GET request using the base_url and query\n",
        "response = libreq.urlopen(base_url+search_query).read()\n",
        "\n",
        "# parse the response using feedparser\n",
        "feed = feedparser.parse(response)\n",
        "\n",
        "# print out feed information\n",
        "print('Feed title: %s' % feed.feed.title)\n",
        "print('Feed last updated: %s' % feed.feed.updated)\n",
        "for entry in feed.entries:\n",
        "  print('Primary Category: %s' % entry.tags[0]['term'])\n",
        "  \n",
        "  # Lets get all the categories\n",
        "  all_categories = [t['term'] for t in entry.tags]\n",
        "  print(all_categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jewzYEXBfSik",
        "outputId": "3c4c6e69-f7a4-43b9-c8cd-1dbfea210d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feed title: ArXiv Query: search_query=all:electron&amp;id_list=&amp;start=0&amp;max_results=10\n",
            "Feed last updated: 2023-04-15T00:00:00-04:00\n",
            "Primary Category: cond-mat.str-el\n",
            "['cond-mat.str-el']\n",
            "Primary Category: astro-ph\n",
            "['astro-ph']\n",
            "Primary Category: cond-mat.str-el\n",
            "['cond-mat.str-el']\n",
            "Primary Category: physics.space-ph\n",
            "['physics.space-ph']\n",
            "Primary Category: cond-mat.supr-con\n",
            "['cond-mat.supr-con', 'cond-mat.mes-hall']\n",
            "Primary Category: astro-ph\n",
            "['astro-ph']\n",
            "Primary Category: astro-ph\n",
            "['astro-ph']\n",
            "Primary Category: cond-mat.str-el\n",
            "['cond-mat.str-el']\n",
            "Primary Category: cond-mat.quant-gas\n",
            "['cond-mat.quant-gas', 'cond-mat.mtrl-sci', 'cond-mat.str-el']\n",
            "Primary Category: cond-mat.str-el\n",
            "['cond-mat.str-el']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reference\n",
        "\n",
        "import urllib\n",
        "import feedparser\n",
        "\n",
        "# Base api query url\n",
        "base_url = 'http://export.arxiv.org/api/query?';\n",
        "\n",
        "# Search parameters\n",
        "search_query = 'id:704.000' # search for electron in all fields\n",
        "start = 0                     # retreive the first 5 results\n",
        "max_results = 5\n",
        "\n",
        "query = 'search_query=%s&start=%i&max_results=%i' % (search_query,\n",
        "                                                     start,\n",
        "                                                     max_results)\n",
        "\n",
        "# Opensearch metadata such as totalResults, startIndex, \n",
        "# and itemsPerPage live in the opensearch namespase.\n",
        "# Some entry metadata lives in the arXiv namespace.\n",
        "# This is a hack to expose both of these namespaces in\n",
        "# feedparser v4.1\n",
        "feedparser._FeedParserMixin.namespaces['http://a9.com/-/spec/opensearch/1.1/'] = 'opensearch'\n",
        "feedparser._FeedParserMixin.namespaces['http://arxiv.org/schemas/atom'] = 'arxiv'\n",
        "\n",
        "# perform a GET request using the base_url and query\n",
        "response = urllib.urlopen(base_url+query).read()\n",
        "\n",
        "# parse the response using feedparser\n",
        "feed = feedparser.parse(response)\n",
        "\n",
        "# print out feed information\n",
        "print 'Feed title: %s' % feed.feed.title\n",
        "print 'Feed last updated: %s' % feed.feed.updated\n",
        "\n",
        "# print opensearch metadata\n",
        "print 'totalResults for this query: %s' % feed.feed.opensearch_totalresults\n",
        "print 'itemsPerPage for this query: %s' % feed.feed.opensearch_itemsperpage\n",
        "print 'startIndex for this query: %s'   % feed.feed.opensearch_startindex\n",
        "\n",
        "# Run through each entry, and print out information\n",
        "for entry in feed.entries:\n",
        "    print 'e-print metadata'\n",
        "    print 'arxiv-id: %s' % entry.id.split('/abs/')[-1]\n",
        "    print 'Published: %s' % entry.published\n",
        "    print 'Title:  %s' % entry.title\n",
        "    \n",
        "    # feedparser v4.1 only grabs the first author\n",
        "    author_string = entry.author\n",
        "    \n",
        "    # grab the affiliation in <arxiv:affiliation> if present\n",
        "    # - this will only grab the first affiliation encountered\n",
        "    #   (the first affiliation for the first author)\n",
        "    # Please email the list with a way to get all of this information!\n",
        "    try:\n",
        "        author_string += ' (%s)' % entry.arxiv_affiliation\n",
        "    except AttributeError:\n",
        "        pass\n",
        "    \n",
        "    print 'Last Author:  %s' % author_string\n",
        "    \n",
        "    # feedparser v5.0.1 correctly handles multiple authors, print them all\n",
        "    try:\n",
        "        print 'Authors:  %s' % ', '.join(author.name for author in entry.authors)\n",
        "    except AttributeError:\n",
        "        pass\n",
        "\n",
        "    # get the links to the abs page and pdf for this e-print\n",
        "    for link in entry.links:\n",
        "        if link.rel == 'alternate':\n",
        "            print 'abs page link: %s' % link.href\n",
        "        elif link.title == 'pdf':\n",
        "            print 'pdf link: %s' % link.href\n",
        "    \n",
        "    # The journal reference, comments and primary_category sections live under \n",
        "    # the arxiv namespace\n",
        "    try:\n",
        "        journal_ref = entry.arxiv_journal_ref\n",
        "    except AttributeError:\n",
        "        journal_ref = 'No journal ref found'\n",
        "    print 'Journal reference: %s' % journal_ref\n",
        "    \n",
        "    try:\n",
        "        comment = entry.arxiv_comment\n",
        "    except AttributeError:\n",
        "        comment = 'No comment found'\n",
        "    print 'Comments: %s' % comment\n",
        "    \n",
        "    # Since the <arxiv:primary_category> element has no data, only\n",
        "    # attributes, feedparser does not store anything inside\n",
        "    # entry.arxiv_primary_category\n",
        "    # This is a dirty hack to get the primary_category, just take the\n",
        "    # first element in entry.tags.  If anyone knows a better way to do\n",
        "    # this, please email the list!\n",
        "    print 'Primary Category: %s' % entry.tags[0]['term']\n",
        "    \n",
        "    # Lets get all the categories\n",
        "    all_categories = [t['term'] for t in entry.tags]\n",
        "    print 'All Categories: %s' % (', ').join(all_categories)\n",
        "    \n",
        "    # The abstract is in the <summary> element\n",
        "    print 'Abstract: %s' %  entry.summary"
      ],
      "metadata": {
        "id": "hrzduySRe7tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories['main_category'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04G3MgnLAjDt",
        "outputId": "2928076e-30e3-497c-df08-70f2e24566bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "big_category"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-aK4FqyD8KW",
        "outputId": "c6400174-1616-4ce1-def4-3e57887e9d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Computer Science',\n",
              " 'Economics',\n",
              " 'Electrical Engineering and Systems Science',\n",
              " 'Mathematics',\n",
              " 'Physics',\n",
              " 'Quantitative Biology',\n",
              " 'Quantitative Finance',\n",
              " 'Statistics',\n",
              " 'Astrophysics',\n",
              " 'Condensed Matter',\n",
              " 'General Relativity and Quantum Cosmology',\n",
              " 'High Energy Physics - Experiment',\n",
              " 'High Energy Physics - Lattice',\n",
              " 'High Energy Physics - Phenomenology',\n",
              " 'High Energy Physics - Theory',\n",
              " 'Mathematical Physics',\n",
              " 'Nonlinear Sciences',\n",
              " 'Nuclear Experiment',\n",
              " 'Nuclear Theory',\n",
              " 'Physics',\n",
              " 'Quantum Physics']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_map_dict = {}\n",
        "cat_map_dict['cs'] = 'Computer Science'\n",
        "cat_map_dict['econ'] = 'Economics'\n",
        "cat_map_dict['eess'] = 'Electrical Engineering and Systems Science'\n",
        "cat_map_dict['math'] =  'Mathematics'\n",
        "cat_map_dict['astro-ph'] = 'Astrophysics'\n",
        "cat_map_dict['cond-mat'] = 'Condensed Matter'\n",
        "cat_map_dict['gr-qc'] = 'General Relativity and Quantum Cosmology'\n",
        "cat_map_dict['hep-ex'] =  'High Energy Physics - Experiment'\n",
        "cat_map_dict['hep-lat'] = 'High Energy Physics - Lattice'\n",
        "cat_map_dict['hep-ph'] =  'High Energy Physics - Phenomenology'\n",
        "cat_map_dict['hep-th'] = 'High Energy Physics - Theory'\n",
        "cat_map_dict['math-ph'] = 'Mathematical Physics'\n",
        "cat_map_dict['nlin'] = 'Nonlinear Sciences'\n",
        "cat_map_dict['nucl-ex'] = 'Nuclear Experiment'\n",
        "cat_map_dict['nucl-th'] =  'Nuclear Theory'\n",
        "cat_map_dict['physics'] = 'Physics'\n",
        "cat_map_dict['quant-ph'] = 'Quantum Physics'\n",
        "cat_map_dict['q-bio'] = 'Quantitative Biology'\n",
        "cat_map_dict['q-fin'] = 'Quantitative Finance'\n",
        "cat_map_dict['stat'] = 'Statistics'"
      ],
      "metadata": {
        "id": "el6MiJDQ_qMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories['main_category'] = categories['main_category'].apply(lambda x : cat_map_dict[x])"
      ],
      "metadata": {
        "id": "vyH0IMkVC-Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories.set_index('cat_id', inplace = True)"
      ],
      "metadata": {
        "id": "THhDWKEaEExb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories_dict = categories.to_dict(orient='index')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEfwQNhco7qd",
        "outputId": "e0ab1c8e-6988-432c-95db-a39938c7c3d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cs.AI': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Artificial Intelligence'},\n",
              " 'cs.AR': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Hardware Architecture'},\n",
              " 'cs.CC': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Computational Complexity'},\n",
              " 'cs.CE': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Computational Engineering, Finance, and Science'},\n",
              " 'cs.CG': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Computational Geometry'},\n",
              " 'cs.CL': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Computation and Language'},\n",
              " 'cs.CR': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Cryptography and Security'},\n",
              " 'cs.CV': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Computer Vision and Pattern Recognition'},\n",
              " 'cs.CY': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Computers and Society'},\n",
              " 'cs.DB': {'main_category': 'Computer Science', 'sub_category': 'Databases'},\n",
              " 'cs.DC': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Distributed, Parallel, and Cluster Computing'},\n",
              " 'cs.DL': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Digital Libraries'},\n",
              " 'cs.DM': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Discrete Mathematics'},\n",
              " 'cs.DS': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Data Structures and Algorithms'},\n",
              " 'cs.ET': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Emerging Technologies'},\n",
              " 'cs.FL': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Formal Languages and Automata Theory'},\n",
              " 'cs.GL': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'General Literature'},\n",
              " 'cs.GR': {'main_category': 'Computer Science', 'sub_category': 'Graphics'},\n",
              " 'cs.GT': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Computer Science and Game Theory'},\n",
              " 'cs.HC': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Human-Computer Interaction'},\n",
              " 'cs.IR': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Information Retrieval'},\n",
              " 'cs.IT': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Information Theory'},\n",
              " 'cs.LG': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Machine Learning'},\n",
              " 'cs.LO': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Logic in Computer Science'},\n",
              " 'cs.MA': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Multiagent Systems'},\n",
              " 'cs.MM': {'main_category': 'Computer Science', 'sub_category': 'Multimedia'},\n",
              " 'cs.MS': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Mathematical Software'},\n",
              " 'cs.NA': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Numerical Analysis'},\n",
              " 'cs.NE': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Neural and Evolutionary Computing'},\n",
              " 'cs.NI': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Networking and Internet Architecture'},\n",
              " 'cs.OH': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Other Computer Science'},\n",
              " 'cs.OS': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Operating Systems'},\n",
              " 'cs.PF': {'main_category': 'Computer Science', 'sub_category': 'Performance'},\n",
              " 'cs.PL': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Programming Languages'},\n",
              " 'cs.RO': {'main_category': 'Computer Science', 'sub_category': 'Robotics'},\n",
              " 'cs.SC': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Symbolic Computation'},\n",
              " 'cs.SD': {'main_category': 'Computer Science', 'sub_category': 'Sound'},\n",
              " 'cs.SE': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Software Engineering'},\n",
              " 'cs.SI': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Social and Information Networks'},\n",
              " 'cs.SY': {'main_category': 'Computer Science',\n",
              "  'sub_category': 'Systems and Control'},\n",
              " 'econ.EM': {'main_category': 'Economics', 'sub_category': 'Econometrics'},\n",
              " 'econ.GN': {'main_category': 'Economics',\n",
              "  'sub_category': 'General Economics'},\n",
              " 'econ.TH': {'main_category': 'Economics',\n",
              "  'sub_category': 'Theoretical Economics'},\n",
              " 'eess.AS': {'main_category': 'Electrical Engineering and Systems Science',\n",
              "  'sub_category': 'Audio and Speech Processing'},\n",
              " 'eess.IV': {'main_category': 'Electrical Engineering and Systems Science',\n",
              "  'sub_category': 'Image and Video Processing'},\n",
              " 'eess.SP': {'main_category': 'Electrical Engineering and Systems Science',\n",
              "  'sub_category': 'Signal Processing'},\n",
              " 'eess.SY': {'main_category': 'Electrical Engineering and Systems Science',\n",
              "  'sub_category': 'Systems and Control'},\n",
              " 'math.AC': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Commutative Algebra'},\n",
              " 'math.AG': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Algebraic Geometry'},\n",
              " 'math.AP': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Analysis of PDEs'},\n",
              " 'math.AT': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Algebraic Topology'},\n",
              " 'math.CA': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Classical Analysis and ODEs'},\n",
              " 'math.CO': {'main_category': 'Mathematics', 'sub_category': 'Combinatorics'},\n",
              " 'math.CT': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Category Theory'},\n",
              " 'math.CV': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Complex Variables'},\n",
              " 'math.DG': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Differential Geometry'},\n",
              " 'math.DS': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Dynamical Systems'},\n",
              " 'math.FA': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Functional Analysis'},\n",
              " 'math.GM': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'General Mathematics'},\n",
              " 'math.GN': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'General Topology'},\n",
              " 'math.GR': {'main_category': 'Mathematics', 'sub_category': 'Group Theory'},\n",
              " 'math.GT': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Geometric Topology'},\n",
              " 'math.HO': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'History and Overview'},\n",
              " 'math.IT': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Information Theory'},\n",
              " 'math.KT': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'K-Theory and Homology'},\n",
              " 'math.LO': {'main_category': 'Mathematics', 'sub_category': 'Logic'},\n",
              " 'math.MG': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Metric Geometry'},\n",
              " 'math.MP': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Mathematical Physics'},\n",
              " 'math.NA': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Numerical Analysis'},\n",
              " 'math.NT': {'main_category': 'Mathematics', 'sub_category': 'Number Theory'},\n",
              " 'math.OA': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Operator Algebras'},\n",
              " 'math.OC': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Optimization and Control'},\n",
              " 'math.PR': {'main_category': 'Mathematics', 'sub_category': 'Probability'},\n",
              " 'math.QA': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Quantum Algebra'},\n",
              " 'math.RA': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Rings and Algebras'},\n",
              " 'math.RT': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Representation Theory'},\n",
              " 'math.SG': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Symplectic Geometry'},\n",
              " 'math.SP': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Spectral Theory'},\n",
              " 'math.ST': {'main_category': 'Mathematics',\n",
              "  'sub_category': 'Statistics Theory'},\n",
              " 'astro-ph.CO': {'main_category': 'Astrophysics',\n",
              "  'sub_category': 'Cosmology and Nongalactic Astrophysics'},\n",
              " 'astro-ph.EP': {'main_category': 'Astrophysics',\n",
              "  'sub_category': 'Earth and Planetary Astrophysics'},\n",
              " 'astro-ph.GA': {'main_category': 'Astrophysics',\n",
              "  'sub_category': 'Astrophysics of Galaxies'},\n",
              " 'astro-ph.HE': {'main_category': 'Astrophysics',\n",
              "  'sub_category': 'High Energy Astrophysical Phenomena'},\n",
              " 'astro-ph.IM': {'main_category': 'Astrophysics',\n",
              "  'sub_category': 'Instrumentation and Methods for Astrophysics'},\n",
              " 'astro-ph.SR': {'main_category': 'Astrophysics',\n",
              "  'sub_category': 'Solar and Stellar Astrophysics'},\n",
              " 'cond-mat.dis-nn': {'main_category': 'Condensed Matter',\n",
              "  'sub_category': 'Disordered Systems and Neural Networks'},\n",
              " 'cond-mat.mes-hall': {'main_category': 'Condensed Matter',\n",
              "  'sub_category': 'Mesoscale and Nanoscale Physics'},\n",
              " 'cond-mat.mtrl-sci': {'main_category': 'Condensed Matter',\n",
              "  'sub_category': 'Materials Science'},\n",
              " 'cond-mat.other': {'main_category': 'Condensed Matter',\n",
              "  'sub_category': 'Other Condensed Matter'},\n",
              " 'cond-mat.quant-gas': {'main_category': 'Condensed Matter',\n",
              "  'sub_category': 'Quantum Gases'},\n",
              " 'cond-mat.soft': {'main_category': 'Condensed Matter',\n",
              "  'sub_category': 'Soft Condensed Matter'},\n",
              " 'cond-mat.stat-mech': {'main_category': 'Condensed Matter',\n",
              "  'sub_category': 'Statistical Mechanics'},\n",
              " 'cond-mat.str-el': {'main_category': 'Condensed Matter',\n",
              "  'sub_category': 'Strongly Correlated Electrons'},\n",
              " 'cond-mat.supr-con': {'main_category': 'Condensed Matter',\n",
              "  'sub_category': 'Superconductivity'},\n",
              " 'gr-qc': {'main_category': 'General Relativity and Quantum Cosmology',\n",
              "  'sub_category': 'General Relativity and Quantum Cosmology'},\n",
              " 'hep-ex': {'main_category': 'High Energy Physics - Experiment',\n",
              "  'sub_category': 'High Energy Physics - Experiment'},\n",
              " 'hep-lat': {'main_category': 'High Energy Physics - Lattice',\n",
              "  'sub_category': 'High Energy Physics - Lattice'},\n",
              " 'hep-ph': {'main_category': 'High Energy Physics - Phenomenology',\n",
              "  'sub_category': 'High Energy Physics - Phenomenology'},\n",
              " 'hep-th': {'main_category': 'High Energy Physics - Theory',\n",
              "  'sub_category': 'High Energy Physics - Theory'},\n",
              " 'math-ph': {'main_category': 'Mathematical Physics',\n",
              "  'sub_category': 'Mathematical Physics'},\n",
              " 'nlin.AO': {'main_category': 'Nonlinear Sciences',\n",
              "  'sub_category': 'Adaptation and Self-Organizing Systems'},\n",
              " 'nlin.CD': {'main_category': 'Nonlinear Sciences',\n",
              "  'sub_category': 'Chaotic Dynamics'},\n",
              " 'nlin.CG': {'main_category': 'Nonlinear Sciences',\n",
              "  'sub_category': 'Cellular Automata and Lattice Gases'},\n",
              " 'nlin.PS': {'main_category': 'Nonlinear Sciences',\n",
              "  'sub_category': 'Pattern Formation and Solitons'},\n",
              " 'nlin.SI': {'main_category': 'Nonlinear Sciences',\n",
              "  'sub_category': 'Exactly Solvable and Integrable Systems'},\n",
              " 'nucl-ex': {'main_category': 'Nuclear Experiment',\n",
              "  'sub_category': 'Nuclear Experiment'},\n",
              " 'nucl-th': {'main_category': 'Nuclear Theory',\n",
              "  'sub_category': 'Nuclear Theory'},\n",
              " 'physics.acc-ph': {'main_category': 'Physics',\n",
              "  'sub_category': 'Accelerator Physics'},\n",
              " 'physics.ao-ph': {'main_category': 'Physics',\n",
              "  'sub_category': 'Atmospheric and Oceanic Physics'},\n",
              " 'physics.app-ph': {'main_category': 'Physics',\n",
              "  'sub_category': 'Applied Physics'},\n",
              " 'physics.atm-clus': {'main_category': 'Physics',\n",
              "  'sub_category': 'Atomic and Molecular Clusters'},\n",
              " 'physics.atom-ph': {'main_category': 'Physics',\n",
              "  'sub_category': 'Atomic Physics'},\n",
              " 'physics.bio-ph': {'main_category': 'Physics',\n",
              "  'sub_category': 'Biological Physics'},\n",
              " 'physics.chem-ph': {'main_category': 'Physics',\n",
              "  'sub_category': 'Chemical Physics'},\n",
              " 'physics.class-ph': {'main_category': 'Physics',\n",
              "  'sub_category': 'Classical Physics'},\n",
              " 'physics.comp-ph': {'main_category': 'Physics',\n",
              "  'sub_category': 'Computational Physics'},\n",
              " 'physics.data-an': {'main_category': 'Physics',\n",
              "  'sub_category': 'Data Analysis, Statistics and Probability'},\n",
              " 'physics.ed-ph': {'main_category': 'Physics',\n",
              "  'sub_category': 'Physics Education'},\n",
              " 'physics.flu-dyn': {'main_category': 'Physics',\n",
              "  'sub_category': 'Fluid Dynamics'},\n",
              " 'physics.gen-ph': {'main_category': 'Physics',\n",
              "  'sub_category': 'General Physics'},\n",
              " 'physics.geo-ph': {'main_category': 'Physics', 'sub_category': 'Geophysics'},\n",
              " 'physics.hist-ph': {'main_category': 'Physics',\n",
              "  'sub_category': 'History and Philosophy of Physics'},\n",
              " 'physics.ins-det': {'main_category': 'Physics',\n",
              "  'sub_category': 'Instrumentation and Detectors'},\n",
              " 'physics.med-ph': {'main_category': 'Physics',\n",
              "  'sub_category': 'Medical Physics'},\n",
              " 'physics.optics': {'main_category': 'Physics', 'sub_category': 'Optics'},\n",
              " 'physics.plasm-ph': {'main_category': 'Physics',\n",
              "  'sub_category': 'Plasma Physics'},\n",
              " 'physics.pop-ph': {'main_category': 'Physics',\n",
              "  'sub_category': 'Popular Physics'},\n",
              " 'physics.soc-ph': {'main_category': 'Physics',\n",
              "  'sub_category': 'Physics and Society'},\n",
              " 'physics.space-ph': {'main_category': 'Physics',\n",
              "  'sub_category': 'Space Physics'},\n",
              " 'quant-ph': {'main_category': 'Quantum Physics',\n",
              "  'sub_category': 'Quantum Physics'},\n",
              " 'q-bio.BM': {'main_category': 'Quantitative Biology',\n",
              "  'sub_category': 'Biomolecules'},\n",
              " 'q-bio.CB': {'main_category': 'Quantitative Biology',\n",
              "  'sub_category': 'Cell Behavior'},\n",
              " 'q-bio.GN': {'main_category': 'Quantitative Biology',\n",
              "  'sub_category': 'Genomics'},\n",
              " 'q-bio.MN': {'main_category': 'Quantitative Biology',\n",
              "  'sub_category': 'Molecular Networks'},\n",
              " 'q-bio.NC': {'main_category': 'Quantitative Biology',\n",
              "  'sub_category': 'Neurons and Cognition'},\n",
              " 'q-bio.OT': {'main_category': 'Quantitative Biology',\n",
              "  'sub_category': 'Other Quantitative Biology'},\n",
              " 'q-bio.PE': {'main_category': 'Quantitative Biology',\n",
              "  'sub_category': 'Populations and Evolution'},\n",
              " 'q-bio.QM': {'main_category': 'Quantitative Biology',\n",
              "  'sub_category': 'Quantitative Methods'},\n",
              " 'q-bio.SC': {'main_category': 'Quantitative Biology',\n",
              "  'sub_category': 'Subcellular Processes'},\n",
              " 'q-bio.TO': {'main_category': 'Quantitative Biology',\n",
              "  'sub_category': 'Tissues and Organs'},\n",
              " 'q-fin.CP': {'main_category': 'Quantitative Finance',\n",
              "  'sub_category': 'Computational Finance'},\n",
              " 'q-fin.EC': {'main_category': 'Quantitative Finance',\n",
              "  'sub_category': 'Economics'},\n",
              " 'q-fin.GN': {'main_category': 'Quantitative Finance',\n",
              "  'sub_category': 'General Finance'},\n",
              " 'q-fin.MF': {'main_category': 'Quantitative Finance',\n",
              "  'sub_category': 'Mathematical Finance'},\n",
              " 'q-fin.PM': {'main_category': 'Quantitative Finance',\n",
              "  'sub_category': 'Portfolio Management'},\n",
              " 'q-fin.PR': {'main_category': 'Quantitative Finance',\n",
              "  'sub_category': 'Pricing of Securities'},\n",
              " 'q-fin.RM': {'main_category': 'Quantitative Finance',\n",
              "  'sub_category': 'Risk Management'},\n",
              " 'q-fin.ST': {'main_category': 'Quantitative Finance',\n",
              "  'sub_category': 'Statistical Finance'},\n",
              " 'q-fin.TR': {'main_category': 'Quantitative Finance',\n",
              "  'sub_category': 'Trading and Market Microstructure'},\n",
              " 'stat.AP': {'main_category': 'Statistics', 'sub_category': 'Applications'},\n",
              " 'stat.CO': {'main_category': 'Statistics', 'sub_category': 'Computation'},\n",
              " 'stat.ME': {'main_category': 'Statistics', 'sub_category': 'Methodology'},\n",
              " 'stat.ML': {'main_category': 'Statistics',\n",
              "  'sub_category': 'Machine Learning'},\n",
              " 'stat.OT': {'main_category': 'Statistics',\n",
              "  'sub_category': 'Other Statistics'},\n",
              " 'stat.TH': {'main_category': 'Statistics',\n",
              "  'sub_category': 'Statistics Theory'}}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make categories list first\n",
        "arxiv_df['categories_parsed'] = arxiv_df['categories'].apply(lambda x: x.split(' '))"
      ],
      "metadata": {
        "id": "usy8GBvCEMoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cat_main_name(list_x):\n",
        "  out_list = []\n",
        "  for a in list_x:\n",
        "    try:\n",
        "      if categories_dict[a]['main_category'] not in out_list:\n",
        "        out_list.append(categories_dict[a]['main_category'])\n",
        "    except:\n",
        "      out_list.append(a)\n",
        "  return out_list\n",
        "\n",
        "def cat_sub_name(list_x):\n",
        "  out_list = []\n",
        "  for a in list_x:\n",
        "    try:\n",
        "      if categories_dict[a]['sub_category'] not in out_list:\n",
        "        out_list.append(categories_dict[a]['sub_category'])\n",
        "    except:\n",
        "      out_list.append(a)\n",
        "  return out_list"
      ],
      "metadata": {
        "id": "GzhYz7zArD6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_df['cat_main_name'] = arxiv_df['categories_parsed'].apply(lambda x: cat_main_name(x))\n",
        "arxiv_df['cat_sub_name'] = arxiv_df['categories_parsed'].apply(lambda x: cat_sub_name(x))"
      ],
      "metadata": {
        "id": "vuQTki_so544"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### d. Title & Abstract Key-Word Extraction\n",
        "* by NLP"
      ],
      "metadata": {
        "id": "C4ujwYreUWox"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cUKfxQ0hUdtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Patent Data - Liam"
      ],
      "metadata": {
        "id": "4Pqz9L0BU9uk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the data\n",
        "The kaggle dataset is split into multiple frames, we'll use a glob pattern on the loader to load from train/train"
      ],
      "metadata": {
        "id": "CJmWphn0gBxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d jackchungchiehyu/big-patent\n",
        "!unzip -o /content/big-patent.zip \n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbttEc4_gekY",
        "outputId": "8b9b1017-82e9-4ea5-a828-402c7ecf6fff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "big-patent.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  /content/big-patent.zip\n",
            "  inflating: train/train/a/data000000000000  \n",
            "  inflating: train/train/a/data000000000001  \n",
            "  inflating: train/train/a/data000000000002  \n",
            "  inflating: train/train/a/data000000000003  \n",
            "  inflating: train/train/a/data000000000004  \n",
            "  inflating: train/train/a/data000000000005  \n",
            "  inflating: train/train/a/data000000000006  \n",
            "  inflating: train/train/a/data000000000007  \n",
            "  inflating: train/train/a/data000000000008  \n",
            "  inflating: train/train/a/data000000000009  \n",
            "  inflating: train/train/a/data000000000010  \n",
            "  inflating: train/train/a/data000000000011  \n",
            "  inflating: train/train/a/data000000000012  \n",
            "  inflating: train/train/a/data000000000013  \n",
            "  inflating: train/train/a/data000000000014  \n",
            "  inflating: train/train/a/data000000000015  \n",
            "  inflating: train/train/a/data000000000016  \n",
            "  inflating: train/train/a/data000000000017  \n",
            "  inflating: train/train/a/data000000000018  \n",
            "  inflating: train/train/a/data000000000019  \n",
            "  inflating: train/train/a/data000000000020  \n",
            "  inflating: train/train/a/data000000000021  \n",
            "  inflating: train/train/a/data000000000022  \n",
            "  inflating: train/train/a/data000000000023  \n",
            "  inflating: train/train/a/data000000000024  \n",
            "  inflating: train/train/a/data000000000025  \n",
            "  inflating: train/train/a/data000000000026  \n",
            "  inflating: train/train/a/data000000000027  \n",
            "  inflating: train/train/a/data000000000028  \n",
            "  inflating: train/train/a/data000000000029  \n",
            "  inflating: train/train/a/data000000000030  \n",
            "  inflating: train/train/a/data000000000031  \n",
            "  inflating: train/train/a/data000000000032  \n",
            "  inflating: train/train/a/data000000000033  \n",
            "  inflating: train/train/a/data000000000034  \n",
            "  inflating: train/train/a/data000000000035  \n",
            "  inflating: train/train/a/data000000000036  \n",
            "  inflating: train/train/a/data000000000037  \n",
            "  inflating: train/train/a/data000000000038  \n",
            "  inflating: train/train/a/data000000000039  \n",
            "  inflating: train/train/a/data000000000040  \n",
            "  inflating: train/train/a/data000000000041  \n",
            "  inflating: train/train/a/data000000000042  \n",
            "  inflating: train/train/a/data000000000043  \n",
            "  inflating: train/train/a/data000000000044  \n",
            "  inflating: train/train/a/data000000000045  \n",
            "  inflating: train/train/a/data000000000046  \n",
            "  inflating: train/train/a/data000000000047  \n",
            "  inflating: train/train/a/data000000000048  \n",
            "  inflating: train/train/a/data000000000049  \n",
            "  inflating: train/train/a/data000000000050  \n",
            "  inflating: train/train/a/data000000000051  \n",
            "  inflating: train/train/a/data000000000052  \n",
            "  inflating: train/train/a/data000000000053  \n",
            "  inflating: train/train/a/data000000000054  \n",
            "  inflating: train/train/a/data000000000055  \n",
            "  inflating: train/train/a/data000000000056  \n",
            "  inflating: train/train/a/data000000000057  \n",
            "  inflating: train/train/a/data000000000058  \n",
            "  inflating: train/train/a/data000000000059  \n",
            "  inflating: train/train/a/data000000000060  \n",
            "  inflating: train/train/a/data000000000061  \n",
            "  inflating: train/train/a/data000000000062  \n",
            "  inflating: train/train/a/data000000000063  \n",
            "  inflating: train/train/a/data000000000064  \n",
            "  inflating: train/train/a/data000000000065  \n",
            "  inflating: train/train/a/data000000000066  \n",
            "  inflating: train/train/a/data000000000067  \n",
            "  inflating: train/train/a/data000000000068  \n",
            "  inflating: train/train/a/data000000000069  \n",
            "  inflating: train/train/a/data000000000070  \n",
            "  inflating: train/train/a/data000000000071  \n",
            "  inflating: train/train/a/data000000000072  \n",
            "  inflating: train/train/a/data000000000073  \n",
            "  inflating: train/train/a/data000000000074  \n",
            "  inflating: train/train/a/data000000000075  \n",
            "  inflating: train/train/a/data000000000076  \n",
            "  inflating: train/train/a/data000000000077  \n",
            "  inflating: train/train/a/data000000000078  \n",
            "  inflating: train/train/a/data000000000079  \n",
            "  inflating: train/train/a/data000000000080  \n",
            "  inflating: train/train/a/data000000000081  \n",
            "  inflating: train/train/a/data000000000082  \n",
            "  inflating: train/train/a/data000000000083  \n",
            "  inflating: train/train/a/data000000000084  \n",
            "  inflating: train/train/a/data000000000085  \n",
            "  inflating: train/train/a/data000000000086  \n",
            "  inflating: train/train/a/data000000000087  \n",
            "  inflating: train/train/a/data000000000088  \n",
            "  inflating: train/train/a/data000000000089  \n",
            "  inflating: train/train/a/data000000000090  \n",
            "  inflating: train/train/a/data000000000091  \n",
            "  inflating: train/train/a/data000000000092  \n",
            "  inflating: train/train/a/data000000000093  \n",
            "  inflating: train/train/a/data000000000094  \n",
            "  inflating: train/train/a/data000000000095  \n",
            "  inflating: train/train/a/data000000000096  \n",
            "  inflating: train/train/a/data000000000097  \n",
            "  inflating: train/train/a/data000000000098  \n",
            "  inflating: train/train/a/data000000000099  \n",
            "  inflating: train/train/a/data000000000100  \n",
            "  inflating: train/train/a/data000000000101  \n",
            "  inflating: train/train/a/data000000000102  \n",
            "  inflating: train/train/a/data000000000103  \n",
            "  inflating: train/train/a/data000000000104  \n",
            "  inflating: train/train/a/data000000000105  \n",
            "  inflating: train/train/a/data000000000106  \n",
            "  inflating: train/train/a/data000000000107  \n",
            "  inflating: train/train/a/data000000000108  \n",
            "  inflating: train/train/a/data000000000109  \n",
            "  inflating: train/train/a/data000000000110  \n",
            "  inflating: train/train/a/data000000000111  \n",
            "  inflating: train/train/a/data000000000112  \n",
            "  inflating: train/train/a/data000000000113  \n",
            "  inflating: train/train/a/data000000000114  \n",
            "  inflating: train/train/a/data000000000115  \n",
            "  inflating: train/train/a/data000000000116  \n",
            "  inflating: train/train/a/data000000000117  \n",
            "  inflating: train/train/a/data000000000118  \n",
            "  inflating: train/train/a/data000000000119  \n",
            "  inflating: train/train/a/data000000000120  \n",
            "  inflating: train/train/a/data000000000121  \n",
            "  inflating: train/train/a/data000000000122  \n",
            "  inflating: train/train/a/data000000000123  \n",
            "  inflating: train/train/a/data000000000124  \n",
            "  inflating: train/train/a/data000000000125  \n",
            "  inflating: train/train/a/data000000000126  \n",
            "  inflating: train/train/a/data000000000127  \n",
            "  inflating: train/train/a/data000000000128  \n",
            "  inflating: train/train/a/data000000000129  \n",
            "  inflating: train/train/a/data000000000130  \n",
            "  inflating: train/train/a/data000000000131  \n",
            "  inflating: train/train/a/data000000000132  \n",
            "  inflating: train/train/a/data000000000133  \n",
            "  inflating: train/train/a/data000000000134  \n",
            "  inflating: train/train/a/data000000000135  \n",
            "  inflating: train/train/a/data000000000136  \n",
            "  inflating: train/train/a/data000000000137  \n",
            "  inflating: train/train/a/data000000000138  \n",
            "  inflating: train/train/a/data000000000139  \n",
            "  inflating: train/train/a/data000000000140  \n",
            "  inflating: train/train/a/data000000000141  \n",
            "  inflating: train/train/a/data000000000142  \n",
            "  inflating: train/train/a/data000000000143  \n",
            "  inflating: train/train/a/data000000000144  \n",
            "  inflating: train/train/a/data000000000145  \n",
            "  inflating: train/train/a/data000000000146  \n",
            "  inflating: train/train/a/data000000000147  \n",
            "  inflating: train/train/a/data000000000148  \n",
            "  inflating: train/train/a/data000000000149  \n",
            "  inflating: train/train/a/data000000000150  \n",
            "  inflating: train/train/a/data000000000151  \n",
            "  inflating: train/train/a/data000000000152  \n",
            "  inflating: train/train/a/data000000000153  \n",
            "  inflating: train/train/a/data000000000154  \n",
            "  inflating: train/train/a/data000000000155  \n",
            "  inflating: train/train/a/data000000000156  \n",
            "  inflating: train/train/a/data000000000157  \n",
            "  inflating: train/train/a/data000000000158  \n",
            "  inflating: train/train/a/data000000000159  \n",
            "  inflating: train/train/a/data000000000160  \n",
            "  inflating: train/train/a/data000000000161  \n",
            "  inflating: train/train/a/data000000000162  \n",
            "  inflating: train/train/a/data000000000163  \n",
            "  inflating: train/train/a/data000000000164  \n",
            "  inflating: train/train/a/data000000000165  \n",
            "  inflating: train/train/a/data000000000166  \n",
            "  inflating: train/train/b/data000000000000  \n",
            "  inflating: train/train/b/data000000000001  \n",
            "  inflating: train/train/b/data000000000002  \n",
            "  inflating: train/train/b/data000000000003  \n",
            "  inflating: train/train/b/data000000000004  \n",
            "  inflating: train/train/b/data000000000005  \n",
            "  inflating: train/train/b/data000000000006  \n",
            "  inflating: train/train/b/data000000000007  \n",
            "  inflating: train/train/b/data000000000008  \n",
            "  inflating: train/train/b/data000000000009  \n",
            "  inflating: train/train/b/data000000000010  \n",
            "  inflating: train/train/b/data000000000011  \n",
            "  inflating: train/train/b/data000000000012  \n",
            "  inflating: train/train/b/data000000000013  \n",
            "  inflating: train/train/b/data000000000014  \n",
            "  inflating: train/train/b/data000000000015  \n",
            "  inflating: train/train/b/data000000000016  \n",
            "  inflating: train/train/b/data000000000017  \n",
            "  inflating: train/train/b/data000000000018  \n",
            "  inflating: train/train/b/data000000000019  \n",
            "  inflating: train/train/b/data000000000020  \n",
            "  inflating: train/train/b/data000000000021  \n",
            "  inflating: train/train/b/data000000000022  \n",
            "  inflating: train/train/b/data000000000023  \n",
            "  inflating: train/train/b/data000000000024  \n",
            "  inflating: train/train/b/data000000000025  \n",
            "  inflating: train/train/b/data000000000026  \n",
            "  inflating: train/train/b/data000000000027  \n",
            "  inflating: train/train/b/data000000000028  \n",
            "  inflating: train/train/b/data000000000029  \n",
            "  inflating: train/train/b/data000000000030  \n",
            "  inflating: train/train/b/data000000000031  \n",
            "  inflating: train/train/b/data000000000032  \n",
            "  inflating: train/train/b/data000000000033  \n",
            "  inflating: train/train/b/data000000000034  \n",
            "  inflating: train/train/b/data000000000035  \n",
            "  inflating: train/train/b/data000000000036  \n",
            "  inflating: train/train/b/data000000000037  \n",
            "  inflating: train/train/b/data000000000038  \n",
            "  inflating: train/train/b/data000000000039  \n",
            "  inflating: train/train/b/data000000000040  \n",
            "  inflating: train/train/b/data000000000041  \n",
            "  inflating: train/train/b/data000000000042  \n",
            "  inflating: train/train/b/data000000000043  \n",
            "  inflating: train/train/b/data000000000044  \n",
            "  inflating: train/train/b/data000000000045  \n",
            "  inflating: train/train/b/data000000000046  \n",
            "  inflating: train/train/b/data000000000047  \n",
            "  inflating: train/train/b/data000000000048  \n",
            "  inflating: train/train/b/data000000000049  \n",
            "  inflating: train/train/b/data000000000050  \n",
            "  inflating: train/train/b/data000000000051  \n",
            "  inflating: train/train/b/data000000000052  \n",
            "  inflating: train/train/b/data000000000053  \n",
            "  inflating: train/train/b/data000000000054  \n",
            "  inflating: train/train/b/data000000000055  \n",
            "  inflating: train/train/b/data000000000056  \n",
            "  inflating: train/train/b/data000000000057  \n",
            "  inflating: train/train/b/data000000000058  \n",
            "  inflating: train/train/b/data000000000059  \n",
            "  inflating: train/train/b/data000000000060  \n",
            "  inflating: train/train/b/data000000000061  \n",
            "  inflating: train/train/b/data000000000062  \n",
            "  inflating: train/train/b/data000000000063  \n",
            "  inflating: train/train/b/data000000000064  \n",
            "  inflating: train/train/b/data000000000065  \n",
            "  inflating: train/train/b/data000000000066  \n",
            "  inflating: train/train/b/data000000000067  \n",
            "  inflating: train/train/b/data000000000068  \n",
            "  inflating: train/train/b/data000000000069  \n",
            "  inflating: train/train/b/data000000000070  \n",
            "  inflating: train/train/b/data000000000071  \n",
            "  inflating: train/train/b/data000000000072  \n",
            "  inflating: train/train/b/data000000000073  \n",
            "  inflating: train/train/b/data000000000074  \n",
            "  inflating: train/train/b/data000000000075  \n",
            "  inflating: train/train/b/data000000000076  \n",
            "  inflating: train/train/b/data000000000077  \n",
            "  inflating: train/train/b/data000000000078  \n",
            "  inflating: train/train/b/data000000000079  \n",
            "  inflating: train/train/b/data000000000080  \n",
            "  inflating: train/train/b/data000000000081  \n",
            "  inflating: train/train/b/data000000000082  \n",
            "  inflating: train/train/b/data000000000083  \n",
            "  inflating: train/train/b/data000000000084  \n",
            "  inflating: train/train/b/data000000000085  \n",
            "  inflating: train/train/b/data000000000086  \n",
            "  inflating: train/train/b/data000000000087  \n",
            "  inflating: train/train/b/data000000000088  \n",
            "  inflating: train/train/b/data000000000089  \n",
            "  inflating: train/train/b/data000000000090  \n",
            "  inflating: train/train/b/data000000000091  \n",
            "  inflating: train/train/b/data000000000092  \n",
            "  inflating: train/train/b/data000000000093  \n",
            "  inflating: train/train/b/data000000000094  \n",
            "  inflating: train/train/b/data000000000095  \n",
            "  inflating: train/train/b/data000000000096  \n",
            "  inflating: train/train/b/data000000000097  \n",
            "  inflating: train/train/b/data000000000098  \n",
            "  inflating: train/train/b/data000000000099  \n",
            "  inflating: train/train/b/data000000000100  \n",
            "  inflating: train/train/b/data000000000101  \n",
            "  inflating: train/train/b/data000000000102  \n",
            "  inflating: train/train/b/data000000000103  \n",
            "  inflating: train/train/b/data000000000104  \n",
            "  inflating: train/train/b/data000000000105  \n",
            "  inflating: train/train/b/data000000000106  \n",
            "  inflating: train/train/b/data000000000107  \n",
            "  inflating: train/train/b/data000000000108  \n",
            "  inflating: train/train/b/data000000000109  \n",
            "  inflating: train/train/b/data000000000110  \n",
            "  inflating: train/train/b/data000000000111  \n",
            "  inflating: train/train/b/data000000000112  \n",
            "  inflating: train/train/c/data000000000000  \n",
            "  inflating: train/train/c/data000000000001  \n",
            "  inflating: train/train/c/data000000000002  \n",
            "  inflating: train/train/c/data000000000003  \n",
            "  inflating: train/train/c/data000000000004  \n",
            "  inflating: train/train/c/data000000000005  \n",
            "  inflating: train/train/c/data000000000006  \n",
            "  inflating: train/train/c/data000000000007  \n",
            "  inflating: train/train/c/data000000000008  \n",
            "  inflating: train/train/c/data000000000009  \n",
            "  inflating: train/train/c/data000000000010  \n",
            "  inflating: train/train/c/data000000000011  \n",
            "  inflating: train/train/c/data000000000012  \n",
            "  inflating: train/train/c/data000000000013  \n",
            "  inflating: train/train/c/data000000000014  \n",
            "  inflating: train/train/c/data000000000015  \n",
            "  inflating: train/train/c/data000000000016  \n",
            "  inflating: train/train/c/data000000000017  \n",
            "  inflating: train/train/c/data000000000018  \n",
            "  inflating: train/train/c/data000000000019  \n",
            "  inflating: train/train/c/data000000000020  \n",
            "  inflating: train/train/c/data000000000021  \n",
            "  inflating: train/train/c/data000000000022  \n",
            "  inflating: train/train/c/data000000000023  \n",
            "  inflating: train/train/c/data000000000024  \n",
            "  inflating: train/train/c/data000000000025  \n",
            "  inflating: train/train/c/data000000000026  \n",
            "  inflating: train/train/c/data000000000027  \n",
            "  inflating: train/train/c/data000000000028  \n",
            "  inflating: train/train/c/data000000000029  \n",
            "  inflating: train/train/c/data000000000030  \n",
            "  inflating: train/train/c/data000000000031  \n",
            "  inflating: train/train/c/data000000000032  \n",
            "  inflating: train/train/c/data000000000033  \n",
            "  inflating: train/train/c/data000000000034  \n",
            "  inflating: train/train/c/data000000000035  \n",
            "  inflating: train/train/c/data000000000036  \n",
            "  inflating: train/train/c/data000000000037  \n",
            "  inflating: train/train/c/data000000000038  \n",
            "  inflating: train/train/c/data000000000039  \n",
            "  inflating: train/train/c/data000000000040  \n",
            "  inflating: train/train/c/data000000000041  \n",
            "  inflating: train/train/c/data000000000042  \n",
            "  inflating: train/train/c/data000000000043  \n",
            "  inflating: train/train/c/data000000000044  \n",
            "  inflating: train/train/c/data000000000045  \n",
            "  inflating: train/train/c/data000000000046  \n",
            "  inflating: train/train/c/data000000000047  \n",
            "  inflating: train/train/c/data000000000048  \n",
            "  inflating: train/train/c/data000000000049  \n",
            "  inflating: train/train/c/data000000000050  \n",
            "  inflating: train/train/c/data000000000051  \n",
            "  inflating: train/train/c/data000000000052  \n",
            "  inflating: train/train/c/data000000000053  \n",
            "  inflating: train/train/c/data000000000054  \n",
            "  inflating: train/train/c/data000000000055  \n",
            "  inflating: train/train/c/data000000000056  \n",
            "  inflating: train/train/c/data000000000057  \n",
            "  inflating: train/train/c/data000000000058  \n",
            "  inflating: train/train/c/data000000000059  \n",
            "  inflating: train/train/c/data000000000060  \n",
            "  inflating: train/train/c/data000000000061  \n",
            "  inflating: train/train/c/data000000000062  \n",
            "  inflating: train/train/c/data000000000063  \n",
            "  inflating: train/train/c/data000000000064  \n",
            "  inflating: train/train/c/data000000000065  \n",
            "  inflating: train/train/c/data000000000066  \n",
            "  inflating: train/train/c/data000000000067  \n",
            "  inflating: train/train/c/data000000000068  \n",
            "  inflating: train/train/c/data000000000069  \n",
            "  inflating: train/train/c/data000000000070  \n",
            "  inflating: train/train/c/data000000000071  \n",
            "  inflating: train/train/c/data000000000072  \n",
            "  inflating: train/train/c/data000000000073  \n",
            "  inflating: train/train/c/data000000000074  \n",
            "  inflating: train/train/c/data000000000075  \n",
            "  inflating: train/train/c/data000000000076  \n",
            "  inflating: train/train/c/data000000000077  \n",
            "  inflating: train/train/c/data000000000078  \n",
            "  inflating: train/train/c/data000000000079  \n",
            "  inflating: train/train/c/data000000000080  \n",
            "  inflating: train/train/c/data000000000081  \n",
            "  inflating: train/train/c/data000000000082  \n",
            "  inflating: train/train/c/data000000000083  \n",
            "  inflating: train/train/c/data000000000084  \n",
            "  inflating: train/train/c/data000000000085  \n",
            "  inflating: train/train/c/data000000000086  \n",
            "  inflating: train/train/c/data000000000087  \n",
            "  inflating: train/train/c/data000000000088  \n",
            "  inflating: train/train/c/data000000000089  \n",
            "  inflating: train/train/c/data000000000090  \n",
            "  inflating: train/train/c/data000000000091  \n",
            "  inflating: train/train/c/data000000000092  \n",
            "  inflating: train/train/c/data000000000093  \n",
            "  inflating: train/train/c/data000000000094  \n",
            "  inflating: train/train/c/data000000000095  \n",
            "  inflating: train/train/c/data000000000096  \n",
            "  inflating: train/train/c/data000000000097  \n",
            "  inflating: train/train/c/data000000000098  \n",
            "  inflating: train/train/c/data000000000099  \n",
            "  inflating: train/train/c/data000000000100  \n",
            "  inflating: train/train/c/data000000000101  \n",
            "  inflating: train/train/c/data000000000102  \n",
            "  inflating: train/train/c/data000000000103  \n",
            "  inflating: train/train/c/data000000000104  \n",
            "  inflating: train/train/c/data000000000105  \n",
            "  inflating: train/train/c/data000000000106  \n",
            "  inflating: train/train/c/data000000000107  \n",
            "  inflating: train/train/c/data000000000108  \n",
            "  inflating: train/train/c/data000000000109  \n",
            "  inflating: train/train/c/data000000000110  \n",
            "  inflating: train/train/c/data000000000111  \n",
            "  inflating: train/train/c/data000000000112  \n",
            "  inflating: train/train/c/data000000000113  \n",
            "  inflating: train/train/c/data000000000114  \n",
            "  inflating: train/train/c/data000000000115  \n",
            "  inflating: train/train/c/data000000000116  \n",
            "  inflating: train/train/c/data000000000117  \n",
            "  inflating: train/train/c/data000000000118  \n",
            "  inflating: train/train/c/data000000000119  \n",
            "  inflating: train/train/c/data000000000120  \n",
            "  inflating: train/train/c/data000000000121  \n",
            "  inflating: train/train/c/data000000000122  \n",
            "  inflating: train/train/c/data000000000123  \n",
            "  inflating: train/train/c/data000000000124  \n",
            "  inflating: train/train/c/data000000000125  \n",
            "  inflating: train/train/c/data000000000126  \n",
            "  inflating: train/train/c/data000000000127  \n",
            "  inflating: train/train/c/data000000000128  \n",
            "  inflating: train/train/c/data000000000129  \n",
            "  inflating: train/train/c/data000000000130  \n",
            "  inflating: train/train/c/data000000000131  \n",
            "  inflating: train/train/c/data000000000132  \n",
            "  inflating: train/train/c/data000000000133  \n",
            "  inflating: train/train/c/data000000000134  \n",
            "  inflating: train/train/c/data000000000135  \n",
            "  inflating: train/train/c/data000000000136  \n",
            "  inflating: train/train/c/data000000000137  \n",
            "  inflating: train/train/c/data000000000138  \n",
            "  inflating: train/train/c/data000000000139  \n",
            "  inflating: train/train/c/data000000000140  \n",
            "  inflating: train/train/c/data000000000141  \n",
            "  inflating: train/train/c/data000000000142  \n",
            "  inflating: train/train/c/data000000000143  \n",
            "  inflating: train/train/c/data000000000144  \n",
            "  inflating: train/train/c/data000000000145  \n",
            "  inflating: train/train/c/data000000000146  \n",
            "  inflating: train/train/c/data000000000147  \n",
            "  inflating: train/train/c/data000000000148  \n",
            "  inflating: train/train/c/data000000000149  \n",
            "  inflating: train/train/c/data000000000150  \n",
            "  inflating: train/train/c/data000000000151  \n",
            "  inflating: train/train/c/data000000000152  \n",
            "  inflating: train/train/c/data000000000153  \n",
            "  inflating: train/train/c/data000000000154  \n",
            "  inflating: train/train/c/data000000000155  \n",
            "  inflating: train/train/c/data000000000156  \n",
            "  inflating: train/train/c/data000000000157  \n",
            "  inflating: train/train/c/data000000000158  \n",
            "  inflating: train/train/c/data000000000159  \n",
            "  inflating: train/train/c/data000000000160  \n",
            "  inflating: train/train/c/data000000000161  \n",
            "  inflating: train/train/c/data000000000162  \n",
            "  inflating: train/train/c/data000000000163  \n",
            "  inflating: train/train/c/data000000000164  \n",
            "  inflating: train/train/c/data000000000165  \n",
            "  inflating: train/train/c/data000000000166  \n",
            "  inflating: train/train/d/data000000000000  \n",
            "  inflating: train/train/d/data000000000001  \n",
            "  inflating: train/train/d/data000000000002  \n",
            "  inflating: train/train/d/data000000000003  \n",
            "  inflating: train/train/d/data000000000004  \n",
            "  inflating: train/train/d/data000000000005  \n",
            "  inflating: train/train/d/data000000000006  \n",
            "  inflating: train/train/e/data000000000000  \n",
            "  inflating: train/train/e/data000000000001  \n",
            "  inflating: train/train/e/data000000000002  \n",
            "  inflating: train/train/e/data000000000003  \n",
            "  inflating: train/train/e/data000000000004  \n",
            "  inflating: train/train/e/data000000000005  \n",
            "  inflating: train/train/e/data000000000006  \n",
            "  inflating: train/train/e/data000000000007  \n",
            "  inflating: train/train/e/data000000000008  \n",
            "  inflating: train/train/e/data000000000009  \n",
            "  inflating: train/train/e/data000000000010  \n",
            "  inflating: train/train/e/data000000000011  \n",
            "  inflating: train/train/e/data000000000012  \n",
            "  inflating: train/train/e/data000000000013  \n",
            "  inflating: train/train/e/data000000000014  \n",
            "  inflating: train/train/e/data000000000015  \n",
            "  inflating: train/train/e/data000000000016  \n",
            "  inflating: train/train/e/data000000000017  \n",
            "  inflating: train/train/e/data000000000018  \n",
            "  inflating: train/train/f/data000000000000  \n",
            "  inflating: train/train/f/data000000000001  \n",
            "  inflating: train/train/f/data000000000002  \n",
            "  inflating: train/train/f/data000000000003  \n",
            "  inflating: train/train/f/data000000000004  \n",
            "  inflating: train/train/f/data000000000005  \n",
            "  inflating: train/train/f/data000000000006  \n",
            "  inflating: train/train/f/data000000000007  \n",
            "  inflating: train/train/f/data000000000008  \n",
            "  inflating: train/train/f/data000000000009  \n",
            "  inflating: train/train/f/data000000000010  \n",
            "  inflating: train/train/f/data000000000011  \n",
            "  inflating: train/train/f/data000000000012  \n",
            "  inflating: train/train/f/data000000000013  \n",
            "  inflating: train/train/f/data000000000014  \n",
            "  inflating: train/train/f/data000000000015  \n",
            "  inflating: train/train/f/data000000000016  \n",
            "  inflating: train/train/f/data000000000017  \n",
            "  inflating: train/train/f/data000000000018  \n",
            "  inflating: train/train/f/data000000000019  \n",
            "  inflating: train/train/f/data000000000020  \n",
            "  inflating: train/train/f/data000000000021  \n",
            "  inflating: train/train/f/data000000000022  \n",
            "  inflating: train/train/f/data000000000023  \n",
            "  inflating: train/train/f/data000000000024  \n",
            "  inflating: train/train/f/data000000000025  \n",
            "  inflating: train/train/f/data000000000026  \n",
            "  inflating: train/train/f/data000000000027  \n",
            "  inflating: train/train/f/data000000000028  \n",
            "  inflating: train/train/f/data000000000029  \n",
            "  inflating: train/train/f/data000000000030  \n",
            "  inflating: train/train/f/data000000000031  \n",
            "  inflating: train/train/f/data000000000032  \n",
            "  inflating: train/train/f/data000000000033  \n",
            "  inflating: train/train/f/data000000000034  \n",
            "  inflating: train/train/f/data000000000035  \n",
            "  inflating: train/train/f/data000000000036  \n",
            "  inflating: train/train/f/data000000000037  \n",
            "  inflating: train/train/f/data000000000038  \n",
            "  inflating: train/train/f/data000000000039  \n",
            "  inflating: train/train/f/data000000000040  \n",
            "  inflating: train/train/f/data000000000041  \n",
            "  inflating: train/train/f/data000000000042  \n",
            "  inflating: train/train/f/data000000000043  \n",
            "  inflating: train/train/f/data000000000044  \n",
            "  inflating: train/train/f/data000000000045  \n",
            "  inflating: train/train/f/data000000000046  \n",
            "  inflating: train/train/f/data000000000047  \n",
            "  inflating: train/train/f/data000000000048  \n",
            "  inflating: train/train/f/data000000000049  \n",
            "  inflating: train/train/f/data000000000050  \n",
            "  inflating: train/train/g/data000000000000  \n",
            "  inflating: train/train/g/data000000000001  \n",
            "  inflating: train/train/g/data000000000002  \n",
            "  inflating: train/train/g/data000000000003  \n",
            "  inflating: train/train/g/data000000000004  \n",
            "  inflating: train/train/g/data000000000005  \n",
            "  inflating: train/train/g/data000000000006  \n",
            "  inflating: train/train/g/data000000000007  \n",
            "  inflating: train/train/g/data000000000008  \n",
            "  inflating: train/train/g/data000000000009  \n",
            "  inflating: train/train/g/data000000000010  \n",
            "  inflating: train/train/g/data000000000011  \n",
            "  inflating: train/train/g/data000000000012  \n",
            "  inflating: train/train/g/data000000000013  \n",
            "  inflating: train/train/g/data000000000014  \n",
            "  inflating: train/train/g/data000000000015  \n",
            "  inflating: train/train/g/data000000000016  \n",
            "  inflating: train/train/g/data000000000017  \n",
            "  inflating: train/train/g/data000000000019  \n",
            "  inflating: train/train/g/data000000000020  \n",
            "  inflating: train/train/g/data000000000021  \n",
            "  inflating: train/train/g/data000000000022  \n",
            "  inflating: train/train/g/data000000000023  \n",
            "  inflating: train/train/g/data000000000024  \n",
            "  inflating: train/train/g/data000000000025  \n",
            "  inflating: train/train/g/data000000000026  \n",
            "  inflating: train/train/g/data000000000027  \n",
            "  inflating: train/train/g/data000000000028  \n",
            "  inflating: train/train/g/data000000000029  \n",
            "  inflating: train/train/g/data000000000030  \n",
            "  inflating: train/train/g/data000000000033  \n",
            "  inflating: train/train/g/data000000000034  \n",
            "  inflating: train/train/g/data000000000035  \n",
            "  inflating: train/train/g/data000000000036  \n",
            "  inflating: train/train/g/data000000000037  \n",
            "  inflating: train/train/g/data000000000038  \n",
            "  inflating: train/train/g/data000000000039  \n",
            "  inflating: train/train/g/data000000000040  \n",
            "  inflating: train/train/g/data000000000041  \n",
            "  inflating: train/train/g/data000000000042  \n",
            "  inflating: train/train/g/data000000000043  \n",
            "  inflating: train/train/g/data000000000044  \n",
            "  inflating: train/train/g/data000000000045  \n",
            "  inflating: train/train/g/data000000000046  \n",
            "  inflating: train/train/g/data000000000047  \n",
            "  inflating: train/train/g/data000000000048  \n",
            "  inflating: train/train/g/data000000000049  \n",
            "  inflating: train/train/g/data000000000050  \n",
            "  inflating: train/train/g/data000000000051  \n",
            "  inflating: train/train/g/data000000000052  \n",
            "  inflating: train/train/g/data000000000053  \n",
            "  inflating: train/train/g/data000000000054  \n",
            "  inflating: train/train/g/data000000000055  \n",
            "  inflating: train/train/g/data000000000056  \n",
            "  inflating: train/train/g/data000000000057  \n",
            "  inflating: train/train/g/data000000000058  \n",
            "  inflating: train/train/g/data000000000060  \n",
            "  inflating: train/train/g/data000000000061  \n",
            "  inflating: train/train/g/data000000000062  \n",
            "  inflating: train/train/g/data000000000063  \n",
            "  inflating: train/train/g/data000000000064  \n",
            "  inflating: train/train/g/data000000000065  \n",
            "  inflating: train/train/g/data000000000066  \n",
            "  inflating: train/train/g/data000000000067  \n",
            "  inflating: train/train/g/data000000000068  \n",
            "  inflating: train/train/g/data000000000069  \n",
            "  inflating: train/train/g/data000000000070  \n",
            "  inflating: train/train/g/data000000000071  \n",
            "  inflating: train/train/g/data000000000072  \n",
            "  inflating: train/train/g/data000000000073  \n",
            "  inflating: train/train/g/data000000000074  \n",
            "  inflating: train/train/g/data000000000075  \n",
            "  inflating: train/train/g/data000000000076  \n",
            "  inflating: train/train/g/data000000000077  \n",
            "  inflating: train/train/g/data000000000078  \n",
            "  inflating: train/train/g/data000000000079  \n",
            "  inflating: train/train/g/data000000000080  \n",
            "  inflating: train/train/g/data000000000081  \n",
            "  inflating: train/train/g/data000000000082  \n",
            "  inflating: train/train/g/data000000000083  \n",
            "  inflating: train/train/g/data000000000084  \n",
            "  inflating: train/train/g/data000000000085  \n",
            "  inflating: train/train/g/data000000000086  \n",
            "  inflating: train/train/g/data000000000087  \n",
            "  inflating: train/train/g/data000000000088  \n",
            "  inflating: train/train/g/data000000000090  \n",
            "  inflating: train/train/g/data000000000091  \n",
            "  inflating: train/train/g/data000000000092  \n",
            "  inflating: train/train/g/data000000000093  \n",
            "  inflating: train/train/g/data000000000094  \n",
            "  inflating: train/train/g/data000000000095  \n",
            "  inflating: train/train/g/data000000000096  \n",
            "  inflating: train/train/g/data000000000097  \n",
            "  inflating: train/train/g/data000000000098  \n",
            "  inflating: train/train/g/data000000000099  \n",
            "  inflating: train/train/g/data000000000100  \n",
            "  inflating: train/train/g/data000000000101  \n",
            "  inflating: train/train/g/data000000000102  \n",
            "  inflating: train/train/g/data000000000103  \n",
            "  inflating: train/train/g/data000000000105  \n",
            "  inflating: train/train/g/data000000000106  \n",
            "  inflating: train/train/g/data000000000107  \n",
            "  inflating: train/train/g/data000000000108  \n",
            "  inflating: train/train/g/data000000000109  \n",
            "  inflating: train/train/g/data000000000110  \n",
            "  inflating: train/train/g/data000000000111  \n",
            "  inflating: train/train/g/data000000000113  \n",
            "  inflating: train/train/g/data000000000114  \n",
            "  inflating: train/train/g/data000000000115  \n",
            "  inflating: train/train/g/data000000000116  \n",
            "  inflating: train/train/g/data000000000117  \n",
            "  inflating: train/train/g/data000000000118  \n",
            "  inflating: train/train/g/data000000000119  \n",
            "  inflating: train/train/g/data000000000120  \n",
            "  inflating: train/train/g/data000000000121  \n",
            "  inflating: train/train/g/data000000000122  \n",
            "  inflating: train/train/g/data000000000123  \n",
            "  inflating: train/train/g/data000000000124  \n",
            "  inflating: train/train/g/data000000000125  \n",
            "  inflating: train/train/g/data000000000126  \n",
            "  inflating: train/train/g/data000000000127  \n",
            "  inflating: train/train/g/data000000000128  \n",
            "  inflating: train/train/g/data000000000129  \n",
            "  inflating: train/train/g/data000000000130  \n",
            "  inflating: train/train/g/data000000000131  \n",
            "  inflating: train/train/g/data000000000133  \n",
            "  inflating: train/train/g/data000000000134  \n",
            "  inflating: train/train/g/data000000000135  \n",
            "  inflating: train/train/g/data000000000136  \n",
            "  inflating: train/train/g/data000000000137  \n",
            "  inflating: train/train/g/data000000000138  \n",
            "  inflating: train/train/g/data000000000139  \n",
            "  inflating: train/train/g/data000000000141  \n",
            "  inflating: train/train/g/data000000000142  \n",
            "  inflating: train/train/g/data000000000143  \n",
            "  inflating: train/train/g/data000000000144  \n",
            "  inflating: train/train/g/data000000000145  \n",
            "  inflating: train/train/g/data000000000146  \n",
            "  inflating: train/train/g/data000000000147  \n",
            "  inflating: train/train/g/data000000000148  \n",
            "  inflating: train/train/g/data000000000150  \n",
            "  inflating: train/train/g/data000000000151  \n",
            "  inflating: train/train/g/data000000000152  \n",
            "  inflating: train/train/g/data000000000153  \n",
            "  inflating: train/train/g/data000000000154  \n",
            "  inflating: train/train/g/data000000000155  \n",
            "  inflating: train/train/g/data000000000157  \n",
            "  inflating: train/train/g/data000000000158  \n",
            "  inflating: train/train/g/data000000000159  \n",
            "  inflating: train/train/g/data000000000160  \n",
            "  inflating: train/train/g/data000000000161  \n",
            "  inflating: train/train/g/data000000000163  \n",
            "  inflating: train/train/g/data000000000164  \n",
            "  inflating: train/train/g/data000000000165  \n",
            "  inflating: train/train/g/data000000000166  \n",
            "  inflating: train/train/h/data000000000000  \n",
            "  inflating: train/train/h/data000000000001  \n",
            "  inflating: train/train/h/data000000000002  \n",
            "  inflating: train/train/h/data000000000003  \n",
            "  inflating: train/train/h/data000000000004  \n",
            "  inflating: train/train/h/data000000000005  \n",
            "  inflating: train/train/h/data000000000006  \n",
            "  inflating: train/train/h/data000000000007  \n",
            "  inflating: train/train/h/data000000000008  \n",
            "  inflating: train/train/h/data000000000009  \n",
            "  inflating: train/train/h/data000000000010  \n",
            "  inflating: train/train/h/data000000000011  \n",
            "  inflating: train/train/h/data000000000012  \n",
            "  inflating: train/train/h/data000000000013  \n",
            "  inflating: train/train/h/data000000000014  \n",
            "  inflating: train/train/h/data000000000015  \n",
            "  inflating: train/train/h/data000000000016  \n",
            "  inflating: train/train/h/data000000000017  \n",
            "  inflating: train/train/h/data000000000018  \n",
            "  inflating: train/train/h/data000000000019  \n",
            "  inflating: train/train/h/data000000000020  \n",
            "  inflating: train/train/h/data000000000021  \n",
            "  inflating: train/train/h/data000000000022  \n",
            "  inflating: train/train/h/data000000000023  \n",
            "  inflating: train/train/h/data000000000024  \n",
            "  inflating: train/train/h/data000000000025  \n",
            "  inflating: train/train/h/data000000000026  \n",
            "  inflating: train/train/h/data000000000027  \n",
            "  inflating: train/train/h/data000000000028  \n",
            "  inflating: train/train/h/data000000000029  \n",
            "  inflating: train/train/h/data000000000030  \n",
            "  inflating: train/train/h/data000000000031  \n",
            "  inflating: train/train/h/data000000000032  \n",
            "  inflating: train/train/h/data000000000033  \n",
            "  inflating: train/train/h/data000000000034  \n",
            "  inflating: train/train/h/data000000000035  \n",
            "  inflating: train/train/h/data000000000036  \n",
            "  inflating: train/train/h/data000000000037  \n",
            "  inflating: train/train/h/data000000000038  \n",
            "  inflating: train/train/h/data000000000039  \n",
            "  inflating: train/train/h/data000000000040  \n",
            "  inflating: train/train/h/data000000000041  \n",
            "  inflating: train/train/h/data000000000042  \n",
            "  inflating: train/train/h/data000000000043  \n",
            "  inflating: train/train/h/data000000000044  \n",
            "  inflating: train/train/h/data000000000045  \n",
            "  inflating: train/train/h/data000000000046  \n",
            "  inflating: train/train/h/data000000000047  \n",
            "  inflating: train/train/h/data000000000048  \n",
            "  inflating: train/train/h/data000000000049  \n",
            "  inflating: train/train/h/data000000000050  \n",
            "  inflating: train/train/h/data000000000051  \n",
            "  inflating: train/train/h/data000000000052  \n",
            "  inflating: train/train/h/data000000000053  \n",
            "  inflating: train/train/h/data000000000054  \n",
            "  inflating: train/train/h/data000000000055  \n",
            "  inflating: train/train/h/data000000000056  \n",
            "  inflating: train/train/h/data000000000057  \n",
            "  inflating: train/train/h/data000000000058  \n",
            "  inflating: train/train/h/data000000000059  \n",
            "  inflating: train/train/h/data000000000060  \n",
            "  inflating: train/train/h/data000000000061  \n",
            "  inflating: train/train/h/data000000000062  \n",
            "  inflating: train/train/h/data000000000063  \n",
            "  inflating: train/train/h/data000000000064  \n",
            "  inflating: train/train/h/data000000000065  \n",
            "  inflating: train/train/h/data000000000066  \n",
            "  inflating: train/train/h/data000000000067  \n",
            "  inflating: train/train/h/data000000000068  \n",
            "  inflating: train/train/h/data000000000069  \n",
            "  inflating: train/train/h/data000000000070  \n",
            "  inflating: train/train/h/data000000000071  \n",
            "  inflating: train/train/h/data000000000072  \n",
            "  inflating: train/train/h/data000000000073  \n",
            "  inflating: train/train/h/data000000000074  \n",
            "  inflating: train/train/h/data000000000075  \n",
            "  inflating: train/train/h/data000000000076  \n",
            "  inflating: train/train/h/data000000000077  \n",
            "  inflating: train/train/h/data000000000078  \n",
            "  inflating: train/train/h/data000000000079  \n",
            "  inflating: train/train/h/data000000000080  \n",
            "  inflating: train/train/h/data000000000081  \n",
            "  inflating: train/train/h/data000000000082  \n",
            "  inflating: train/train/h/data000000000083  \n",
            "  inflating: train/train/h/data000000000084  \n",
            "  inflating: train/train/h/data000000000085  \n",
            "  inflating: train/train/h/data000000000086  \n",
            "  inflating: train/train/h/data000000000087  \n",
            "  inflating: train/train/h/data000000000088  \n",
            "  inflating: train/train/h/data000000000089  \n",
            "  inflating: train/train/h/data000000000090  \n",
            "  inflating: train/train/h/data000000000091  \n",
            "  inflating: train/train/h/data000000000092  \n",
            "  inflating: train/train/h/data000000000093  \n",
            "  inflating: train/train/h/data000000000094  \n",
            "  inflating: train/train/h/data000000000095  \n",
            "  inflating: train/train/h/data000000000096  \n",
            "  inflating: train/train/h/data000000000097  \n",
            "  inflating: train/train/h/data000000000098  \n",
            "  inflating: train/train/h/data000000000099  \n",
            "  inflating: train/train/h/data000000000100  \n",
            "  inflating: train/train/h/data000000000101  \n",
            "  inflating: train/train/h/data000000000102  \n",
            "  inflating: train/train/h/data000000000103  \n",
            "  inflating: train/train/h/data000000000104  \n",
            "  inflating: train/train/h/data000000000105  \n",
            "  inflating: train/train/h/data000000000106  \n",
            "  inflating: train/train/h/data000000000107  \n",
            "  inflating: train/train/h/data000000000108  \n",
            "  inflating: train/train/h/data000000000109  \n",
            "  inflating: train/train/h/data000000000110  \n",
            "  inflating: train/train/h/data000000000111  \n",
            "  inflating: train/train/h/data000000000112  \n",
            "  inflating: train/train/h/data000000000113  \n",
            "  inflating: train/train/h/data000000000114  \n",
            "  inflating: train/train/h/data000000000115  \n",
            "  inflating: train/train/h/data000000000116  \n",
            "  inflating: train/train/h/data000000000117  \n",
            "  inflating: train/train/h/data000000000118  \n",
            "  inflating: train/train/h/data000000000119  \n",
            "  inflating: train/train/h/data000000000120  \n",
            "  inflating: train/train/h/data000000000121  \n",
            "  inflating: train/train/h/data000000000122  \n",
            "  inflating: train/train/h/data000000000123  \n",
            "  inflating: train/train/h/data000000000124  \n",
            "  inflating: train/train/h/data000000000125  \n",
            "  inflating: train/train/h/data000000000126  \n",
            "  inflating: train/train/h/data000000000127  \n",
            "  inflating: train/train/h/data000000000128  \n",
            "  inflating: train/train/h/data000000000129  \n",
            "  inflating: train/train/h/data000000000130  \n",
            "  inflating: train/train/h/data000000000131  \n",
            "  inflating: train/train/h/data000000000132  \n",
            "  inflating: train/train/h/data000000000133  \n",
            "  inflating: train/train/h/data000000000134  \n",
            "  inflating: train/train/h/data000000000135  \n",
            "  inflating: train/train/h/data000000000136  \n",
            "  inflating: train/train/h/data000000000137  \n",
            "  inflating: train/train/h/data000000000138  \n",
            "  inflating: train/train/h/data000000000139  \n",
            "  inflating: train/train/h/data000000000140  \n",
            "  inflating: train/train/h/data000000000141  \n",
            "  inflating: train/train/h/data000000000142  \n",
            "  inflating: train/train/h/data000000000143  \n",
            "  inflating: train/train/h/data000000000144  \n",
            "  inflating: train/train/h/data000000000145  \n",
            "  inflating: train/train/h/data000000000146  \n",
            "  inflating: train/train/h/data000000000147  \n",
            "  inflating: train/train/h/data000000000148  \n",
            "  inflating: train/train/h/data000000000149  \n",
            "  inflating: train/train/h/data000000000150  \n",
            "  inflating: train/train/h/data000000000151  \n",
            "  inflating: train/train/h/data000000000152  \n",
            "  inflating: train/train/h/data000000000153  \n",
            "  inflating: train/train/h/data000000000154  \n",
            "  inflating: train/train/h/data000000000155  \n",
            "  inflating: train/train/h/data000000000156  \n",
            "  inflating: train/train/h/data000000000157  \n",
            "  inflating: train/train/h/data000000000158  \n",
            "  inflating: train/train/h/data000000000159  \n",
            "  inflating: train/train/h/data000000000160  \n",
            "  inflating: train/train/h/data000000000161  \n",
            "  inflating: train/train/h/data000000000162  \n",
            "  inflating: train/train/h/data000000000163  \n",
            "  inflating: train/train/h/data000000000164  \n",
            "  inflating: train/train/h/data000000000165  \n",
            "  inflating: train/train/h/data000000000166  \n",
            "  inflating: train/train/y/data000000000000  \n",
            "  inflating: train/train/y/data000000000001  \n",
            "  inflating: train/train/y/data000000000002  \n",
            "  inflating: train/train/y/data000000000003  \n",
            "  inflating: train/train/y/data000000000004  \n",
            "  inflating: train/train/y/data000000000005  \n",
            "  inflating: train/train/y/data000000000006  \n",
            "  inflating: train/train/y/data000000000007  \n",
            "  inflating: train/train/y/data000000000008  \n",
            "  inflating: train/train/y/data000000000009  \n",
            "  inflating: train/train/y/data000000000010  \n",
            "  inflating: train/train/y/data000000000011  \n",
            "  inflating: train/train/y/data000000000012  \n",
            "  inflating: train/train/y/data000000000013  \n",
            "  inflating: train/train/y/data000000000014  \n",
            "  inflating: train/train/y/data000000000015  \n",
            "  inflating: train/train/y/data000000000016  \n",
            "  inflating: train/train/y/data000000000017  \n",
            "  inflating: train/train/y/data000000000018  \n",
            "  inflating: train/train/y/data000000000019  \n",
            "  inflating: train/train/y/data000000000020  \n",
            "  inflating: train/train/y/data000000000021  \n",
            "  inflating: train/train/y/data000000000022  \n",
            "  inflating: train/train/y/data000000000023  \n",
            "  inflating: train/train/y/data000000000024  \n",
            "  inflating: train/train/y/data000000000025  \n",
            "  inflating: train/train/y/data000000000026  \n",
            "  inflating: train/train/y/data000000000027  \n",
            "  inflating: train/train/y/data000000000028  \n",
            "  inflating: train/train/y/data000000000029  \n",
            "  inflating: train/train/y/data000000000030  \n",
            "  inflating: train/train/y/data000000000031  \n",
            "  inflating: train/train/y/data000000000032  \n",
            "  inflating: train/train/y/data000000000033  \n",
            "  inflating: train/train/y/data000000000034  \n",
            "  inflating: train/train/y/data000000000035  \n",
            "  inflating: train/train/y/data000000000036  \n",
            "  inflating: train/train/y/data000000000037  \n",
            "  inflating: train/train/y/data000000000038  \n",
            "  inflating: train/train/y/data000000000039  \n",
            "  inflating: train/train/y/data000000000040  \n",
            "  inflating: train/train/y/data000000000041  \n",
            "  inflating: train/train/y/data000000000042  \n",
            "  inflating: train/train/y/data000000000043  \n",
            "  inflating: train/train/y/data000000000044  \n",
            "  inflating: train/train/y/data000000000045  \n",
            "  inflating: train/train/y/data000000000046  \n",
            "  inflating: train/train/y/data000000000047  \n",
            "  inflating: train/train/y/data000000000048  \n",
            "  inflating: train/train/y/data000000000049  \n",
            "  inflating: train/train/y/data000000000050  \n",
            "  inflating: train/train/y/data000000000051  \n",
            "  inflating: train/train/y/data000000000052  \n",
            "  inflating: train/train/y/data000000000053  \n",
            "  inflating: train/train/y/data000000000054  \n",
            "  inflating: train/train/y/data000000000055  \n",
            "  inflating: train/train/y/data000000000056  \n",
            "  inflating: train/train/y/data000000000057  \n",
            "  inflating: train/train/y/data000000000058  \n",
            "  inflating: train/train/y/data000000000059  \n",
            "  inflating: train/train/y/data000000000060  \n",
            "  inflating: train/train/y/data000000000061  \n",
            "  inflating: train/train/y/data000000000062  \n",
            "  inflating: train/train/y/data000000000063  \n",
            "  inflating: train/train/y/data000000000064  \n",
            "  inflating: train/train/y/data000000000065  \n",
            "  inflating: train/train/y/data000000000066  \n",
            "  inflating: train/train/y/data000000000067  \n",
            "  inflating: train/train/y/data000000000068  \n",
            "  inflating: train/train/y/data000000000069  \n",
            "  inflating: train/train/y/data000000000070  \n",
            "  inflating: train/train/y/data000000000071  \n",
            "  inflating: train/train/y/data000000000072  \n",
            "  inflating: train/train/y/data000000000073  \n",
            "  inflating: train/train/y/data000000000074  \n",
            "  inflating: train/train/y/data000000000075  \n",
            "  inflating: train/train/y/data000000000076  \n",
            "  inflating: train/train/y/data000000000077  \n",
            "  inflating: train/train/y/data000000000078  \n",
            "  inflating: train/train/y/data000000000079  \n",
            "  inflating: train/train/y/data000000000080  \n",
            "  inflating: train/train/y/data000000000081  \n",
            "  inflating: train/train/y/data000000000082  \n",
            "  inflating: train/train/y/data000000000083  \n",
            "  inflating: train/train/y/data000000000084  \n",
            "  inflating: train/train/y/data000000000085  \n",
            "  inflating: train/train/y/data000000000086  \n",
            "  inflating: train/train/y/data000000000087  \n",
            "  inflating: train/train/y/data000000000088  \n",
            "  inflating: train/train/y/data000000000089  \n",
            "  inflating: train/train/y/data000000000090  \n",
            "  inflating: train/train/y/data000000000091  \n",
            "  inflating: train/train/y/data000000000092  \n",
            "  inflating: train/train/y/data000000000093  \n",
            "  inflating: train/train/y/data000000000094  \n",
            "  inflating: train/train/y/data000000000095  \n",
            "  inflating: train/train/y/data000000000096  \n",
            "  inflating: train/train/y/data000000000097  \n",
            "  inflating: train/train/y/data000000000098  \n",
            "  inflating: train/train/y/data000000000099  \n",
            "  inflating: train/train/y/data000000000100  \n",
            "  inflating: train/train/y/data000000000101  \n",
            "  inflating: train/train/y/data000000000102  \n",
            "  inflating: train/train/y/data000000000103  \n",
            "  inflating: train/train/y/data000000000104  \n",
            "  inflating: train/train/y/data000000000105  \n",
            "  inflating: val/val/a/data000000000000  \n",
            "  inflating: val/val/a/data000000000001  \n",
            "  inflating: val/val/a/data000000000002  \n",
            "  inflating: val/val/a/data000000000003  \n",
            "  inflating: val/val/a/data000000000004  \n",
            "  inflating: val/val/a/data000000000005  \n",
            "  inflating: val/val/a/data000000000006  \n",
            "  inflating: val/val/a/data000000000007  \n",
            "  inflating: val/val/a/data000000000008  \n",
            "  inflating: val/val/a/data000000000009  \n",
            "  inflating: val/val/a/data000000000010  \n",
            "  inflating: val/val/a/data000000000011  \n",
            "  inflating: val/val/a/data000000000012  \n",
            "  inflating: val/val/a/data000000000013  \n",
            "  inflating: val/val/a/data000000000014  \n",
            "  inflating: val/val/a/data000000000015  \n",
            "  inflating: val/val/a/data000000000016  \n",
            "  inflating: val/val/a/data000000000017  \n",
            "  inflating: val/val/a/data000000000018  \n",
            "  inflating: val/val/a/data000000000019  \n",
            "  inflating: val/val/a/data000000000020  \n",
            "  inflating: val/val/a/data000000000021  \n",
            "  inflating: val/val/a/data000000000022  \n",
            "  inflating: val/val/a/data000000000023  \n",
            "  inflating: val/val/a/data000000000024  \n",
            "  inflating: val/val/a/data000000000025  \n",
            "  inflating: val/val/a/data000000000026  \n",
            "  inflating: val/val/a/data000000000027  \n",
            "  inflating: val/val/a/data000000000028  \n",
            "  inflating: val/val/a/data000000000029  \n",
            "  inflating: val/val/a/data000000000030  \n",
            "  inflating: val/val/a/data000000000031  \n",
            "  inflating: val/val/a/data000000000032  \n",
            "  inflating: val/val/a/data000000000033  \n",
            "  inflating: val/val/a/data000000000034  \n",
            "  inflating: val/val/a/data000000000035  \n",
            "  inflating: val/val/a/data000000000036  \n",
            "  inflating: val/val/a/data000000000037  \n",
            "  inflating: val/val/a/data000000000038  \n",
            "  inflating: val/val/a/data000000000039  \n",
            "  inflating: val/val/a/data000000000040  \n",
            "  inflating: val/val/a/data000000000041  \n",
            "  inflating: val/val/a/data000000000042  \n",
            "  inflating: val/val/a/data000000000043  \n",
            "  inflating: val/val/a/data000000000044  \n",
            "  inflating: val/val/a/data000000000045  \n",
            "  inflating: val/val/a/data000000000046  \n",
            "  inflating: val/val/a/data000000000047  \n",
            "  inflating: val/val/a/data000000000048  \n",
            "  inflating: val/val/a/data000000000049  \n",
            "  inflating: val/val/a/data000000000050  \n",
            "  inflating: val/val/a/data000000000051  \n",
            "  inflating: val/val/a/data000000000052  \n",
            "  inflating: val/val/a/data000000000053  \n",
            "  inflating: val/val/a/data000000000054  \n",
            "  inflating: val/val/a/data000000000055  \n",
            "  inflating: val/val/a/data000000000056  \n",
            "  inflating: val/val/a/data000000000057  \n",
            "  inflating: val/val/a/data000000000058  \n",
            "  inflating: val/val/a/data000000000059  \n",
            "  inflating: val/val/a/data000000000060  \n",
            "  inflating: val/val/a/data000000000061  \n",
            "  inflating: val/val/a/data000000000062  \n",
            "  inflating: val/val/a/data000000000063  \n",
            "  inflating: val/val/a/data000000000064  \n",
            "  inflating: val/val/a/data000000000065  \n",
            "  inflating: val/val/a/data000000000066  \n",
            "  inflating: val/val/a/data000000000067  \n",
            "  inflating: val/val/a/data000000000068  \n",
            "  inflating: val/val/a/data000000000069  \n",
            "  inflating: val/val/a/data000000000070  \n",
            "  inflating: val/val/a/data000000000071  \n",
            "  inflating: val/val/a/data000000000072  \n",
            "  inflating: val/val/a/data000000000073  \n",
            "  inflating: val/val/a/data000000000074  \n",
            "  inflating: val/val/a/data000000000075  \n",
            "  inflating: val/val/a/data000000000076  \n",
            "  inflating: val/val/a/data000000000077  \n",
            "  inflating: val/val/a/data000000000078  \n",
            "  inflating: val/val/a/data000000000079  \n",
            "  inflating: val/val/a/data000000000080  \n",
            "  inflating: val/val/a/data000000000081  \n",
            "  inflating: val/val/a/data000000000082  \n",
            "  inflating: val/val/a/data000000000083  \n",
            "  inflating: val/val/a/data000000000084  \n",
            "  inflating: val/val/a/data000000000085  \n",
            "  inflating: val/val/a/data000000000086  \n",
            "  inflating: val/val/a/data000000000087  \n",
            "  inflating: val/val/a/data000000000088  \n",
            "  inflating: val/val/a/data000000000089  \n",
            "  inflating: val/val/a/data000000000090  \n",
            "  inflating: val/val/a/data000000000091  \n",
            "  inflating: val/val/a/data000000000092  \n",
            "  inflating: val/val/a/data000000000093  \n",
            "  inflating: val/val/a/data000000000094  \n",
            "  inflating: val/val/a/data000000000095  \n",
            "  inflating: val/val/a/data000000000096  \n",
            "  inflating: val/val/a/data000000000097  \n",
            "  inflating: val/val/a/data000000000098  \n",
            "  inflating: val/val/a/data000000000099  \n",
            "  inflating: val/val/a/data000000000100  \n",
            "  inflating: val/val/a/data000000000101  \n",
            "  inflating: val/val/a/data000000000102  \n",
            "  inflating: val/val/a/data000000000103  \n",
            "  inflating: val/val/a/data000000000104  \n",
            "  inflating: val/val/a/data000000000105  \n",
            "  inflating: val/val/a/data000000000106  \n",
            "  inflating: val/val/a/data000000000107  \n",
            "  inflating: val/val/a/data000000000108  \n",
            "  inflating: val/val/a/data000000000109  \n",
            "  inflating: val/val/a/data000000000110  \n",
            "  inflating: val/val/a/data000000000111  \n",
            "  inflating: val/val/a/data000000000112  \n",
            "  inflating: val/val/a/data000000000113  \n",
            "  inflating: val/val/a/data000000000114  \n",
            "  inflating: val/val/a/data000000000115  \n",
            "  inflating: val/val/a/data000000000116  \n",
            "  inflating: val/val/a/data000000000117  \n",
            "  inflating: val/val/a/data000000000118  \n",
            "  inflating: val/val/a/data000000000119  \n",
            "  inflating: val/val/a/data000000000120  \n",
            "  inflating: val/val/a/data000000000121  \n",
            "  inflating: val/val/a/data000000000122  \n",
            "  inflating: val/val/a/data000000000123  \n",
            "  inflating: val/val/a/data000000000124  \n",
            "  inflating: val/val/a/data000000000125  \n",
            "  inflating: val/val/a/data000000000126  \n",
            "  inflating: val/val/a/data000000000127  \n",
            "  inflating: val/val/a/data000000000128  \n",
            "  inflating: val/val/a/data000000000129  \n",
            "  inflating: val/val/a/data000000000130  \n",
            "  inflating: val/val/a/data000000000131  \n",
            "  inflating: val/val/a/data000000000132  \n",
            "  inflating: val/val/a/data000000000133  \n",
            "  inflating: val/val/a/data000000000134  \n",
            "  inflating: val/val/a/data000000000135  \n",
            "  inflating: val/val/a/data000000000136  \n",
            "  inflating: val/val/a/data000000000137  \n",
            "  inflating: val/val/a/data000000000138  \n",
            "  inflating: val/val/a/data000000000139  \n",
            "  inflating: val/val/a/data000000000140  \n",
            "  inflating: val/val/a/data000000000141  \n",
            "  inflating: val/val/a/data000000000142  \n",
            "  inflating: val/val/a/data000000000143  \n",
            "  inflating: val/val/a/data000000000144  \n",
            "  inflating: val/val/a/data000000000145  \n",
            "  inflating: val/val/a/data000000000146  \n",
            "  inflating: val/val/a/data000000000147  \n",
            "  inflating: val/val/a/data000000000148  \n",
            "  inflating: val/val/a/data000000000149  \n",
            "  inflating: val/val/a/data000000000150  \n",
            "  inflating: val/val/a/data000000000151  \n",
            "  inflating: val/val/a/data000000000152  \n",
            "  inflating: val/val/a/data000000000153  \n",
            "  inflating: val/val/a/data000000000154  \n",
            "  inflating: val/val/a/data000000000155  \n",
            "  inflating: val/val/a/data000000000156  \n",
            "  inflating: val/val/a/data000000000157  \n",
            "  inflating: val/val/a/data000000000158  \n",
            "  inflating: val/val/a/data000000000159  \n",
            "  inflating: val/val/a/data000000000160  \n",
            "  inflating: val/val/a/data000000000161  \n",
            "  inflating: val/val/a/data000000000162  \n",
            "  inflating: val/val/a/data000000000163  \n",
            "  inflating: val/val/a/data000000000164  \n",
            "  inflating: val/val/a/data000000000165  \n",
            "  inflating: val/val/a/data000000000166  \n",
            "  inflating: val/val/b/data000000000000  \n",
            "  inflating: val/val/b/data000000000001  \n",
            "  inflating: val/val/b/data000000000002  \n",
            "  inflating: val/val/b/data000000000003  \n",
            "  inflating: val/val/b/data000000000004  \n",
            "  inflating: val/val/b/data000000000005  \n",
            "  inflating: val/val/b/data000000000006  \n",
            "  inflating: val/val/b/data000000000007  \n",
            "  inflating: val/val/b/data000000000008  \n",
            "  inflating: val/val/b/data000000000009  \n",
            "  inflating: val/val/b/data000000000010  \n",
            "  inflating: val/val/b/data000000000011  \n",
            "  inflating: val/val/b/data000000000012  \n",
            "  inflating: val/val/b/data000000000013  \n",
            "  inflating: val/val/b/data000000000014  \n",
            "  inflating: val/val/b/data000000000015  \n",
            "  inflating: val/val/b/data000000000016  \n",
            "  inflating: val/val/b/data000000000017  \n",
            "  inflating: val/val/b/data000000000018  \n",
            "  inflating: val/val/b/data000000000019  \n",
            "  inflating: val/val/b/data000000000020  \n",
            "  inflating: val/val/b/data000000000021  \n",
            "  inflating: val/val/b/data000000000022  \n",
            "  inflating: val/val/b/data000000000023  \n",
            "  inflating: val/val/b/data000000000024  \n",
            "  inflating: val/val/b/data000000000025  \n",
            "  inflating: val/val/b/data000000000026  \n",
            "  inflating: val/val/b/data000000000027  \n",
            "  inflating: val/val/b/data000000000028  \n",
            "  inflating: val/val/b/data000000000029  \n",
            "  inflating: val/val/b/data000000000030  \n",
            "  inflating: val/val/b/data000000000031  \n",
            "  inflating: val/val/b/data000000000032  \n",
            "  inflating: val/val/b/data000000000033  \n",
            "  inflating: val/val/b/data000000000034  \n",
            "  inflating: val/val/b/data000000000035  \n",
            "  inflating: val/val/b/data000000000036  \n",
            "  inflating: val/val/b/data000000000037  \n",
            "  inflating: val/val/b/data000000000038  \n",
            "  inflating: val/val/b/data000000000039  \n",
            "  inflating: val/val/b/data000000000040  \n",
            "  inflating: val/val/b/data000000000041  \n",
            "  inflating: val/val/b/data000000000042  \n",
            "  inflating: val/val/b/data000000000043  \n",
            "  inflating: val/val/b/data000000000044  \n",
            "  inflating: val/val/b/data000000000045  \n",
            "  inflating: val/val/b/data000000000046  \n",
            "  inflating: val/val/b/data000000000047  \n",
            "  inflating: val/val/b/data000000000048  \n",
            "  inflating: val/val/b/data000000000049  \n",
            "  inflating: val/val/b/data000000000050  \n",
            "  inflating: val/val/b/data000000000051  \n",
            "  inflating: val/val/b/data000000000052  \n",
            "  inflating: val/val/b/data000000000053  \n",
            "  inflating: val/val/b/data000000000054  \n",
            "  inflating: val/val/b/data000000000055  \n",
            "  inflating: val/val/b/data000000000056  \n",
            "  inflating: val/val/b/data000000000057  \n",
            "  inflating: val/val/b/data000000000058  \n",
            "  inflating: val/val/b/data000000000059  \n",
            "  inflating: val/val/b/data000000000060  \n",
            "  inflating: val/val/b/data000000000061  \n",
            "  inflating: val/val/b/data000000000062  \n",
            "  inflating: val/val/b/data000000000063  \n",
            "  inflating: val/val/b/data000000000064  \n",
            "  inflating: val/val/b/data000000000065  \n",
            "  inflating: val/val/b/data000000000066  \n",
            "  inflating: val/val/b/data000000000067  \n",
            "  inflating: val/val/b/data000000000068  \n",
            "  inflating: val/val/b/data000000000069  \n",
            "  inflating: val/val/b/data000000000070  \n",
            "  inflating: val/val/b/data000000000071  \n",
            "  inflating: val/val/b/data000000000072  \n",
            "  inflating: val/val/b/data000000000073  \n",
            "  inflating: val/val/b/data000000000074  \n",
            "  inflating: val/val/b/data000000000075  \n",
            "  inflating: val/val/b/data000000000076  \n",
            "  inflating: val/val/b/data000000000077  \n",
            "  inflating: val/val/b/data000000000078  \n",
            "  inflating: val/val/b/data000000000079  \n",
            "  inflating: val/val/b/data000000000080  \n",
            "  inflating: val/val/b/data000000000081  \n",
            "  inflating: val/val/b/data000000000082  \n",
            "  inflating: val/val/b/data000000000083  \n",
            "  inflating: val/val/b/data000000000084  \n",
            "  inflating: val/val/b/data000000000085  \n",
            "  inflating: val/val/b/data000000000086  \n",
            "  inflating: val/val/b/data000000000087  \n",
            "  inflating: val/val/b/data000000000088  \n",
            "  inflating: val/val/b/data000000000089  \n",
            "  inflating: val/val/b/data000000000090  \n",
            "  inflating: val/val/b/data000000000091  \n",
            "  inflating: val/val/b/data000000000092  \n",
            "  inflating: val/val/b/data000000000093  \n",
            "  inflating: val/val/b/data000000000094  \n",
            "  inflating: val/val/b/data000000000095  \n",
            "  inflating: val/val/b/data000000000096  \n",
            "  inflating: val/val/b/data000000000097  \n",
            "  inflating: val/val/b/data000000000098  \n",
            "  inflating: val/val/b/data000000000099  \n",
            "  inflating: val/val/b/data000000000100  \n",
            "  inflating: val/val/b/data000000000101  \n",
            "  inflating: val/val/b/data000000000102  \n",
            "  inflating: val/val/b/data000000000103  \n",
            "  inflating: val/val/b/data000000000104  \n",
            "  inflating: val/val/b/data000000000105  \n",
            "  inflating: val/val/b/data000000000106  \n",
            "  inflating: val/val/b/data000000000107  \n",
            "  inflating: val/val/b/data000000000108  \n",
            "  inflating: val/val/b/data000000000109  \n",
            "  inflating: val/val/b/data000000000110  \n",
            "  inflating: val/val/b/data000000000111  \n",
            "  inflating: val/val/b/data000000000112  \n",
            "  inflating: val/val/c/data000000000000  \n",
            "  inflating: val/val/c/data000000000001  \n",
            "  inflating: val/val/c/data000000000002  \n",
            "  inflating: val/val/c/data000000000003  \n",
            "  inflating: val/val/c/data000000000004  \n",
            "  inflating: val/val/c/data000000000005  \n",
            "  inflating: val/val/c/data000000000006  \n",
            "  inflating: val/val/c/data000000000007  \n",
            "  inflating: val/val/c/data000000000008  \n",
            "  inflating: val/val/c/data000000000009  \n",
            "  inflating: val/val/c/data000000000010  \n",
            "  inflating: val/val/c/data000000000011  \n",
            "  inflating: val/val/c/data000000000012  \n",
            "  inflating: val/val/c/data000000000013  \n",
            "  inflating: val/val/c/data000000000014  \n",
            "  inflating: val/val/c/data000000000015  \n",
            "  inflating: val/val/c/data000000000016  \n",
            "  inflating: val/val/c/data000000000017  \n",
            "  inflating: val/val/c/data000000000018  \n",
            "  inflating: val/val/c/data000000000019  \n",
            "  inflating: val/val/c/data000000000020  \n",
            "  inflating: val/val/c/data000000000021  \n",
            "  inflating: val/val/c/data000000000022  \n",
            "  inflating: val/val/c/data000000000023  \n",
            "  inflating: val/val/c/data000000000024  \n",
            "  inflating: val/val/c/data000000000025  \n",
            "  inflating: val/val/c/data000000000026  \n",
            "  inflating: val/val/c/data000000000027  \n",
            "  inflating: val/val/c/data000000000028  \n",
            "  inflating: val/val/c/data000000000029  \n",
            "  inflating: val/val/c/data000000000030  \n",
            "  inflating: val/val/c/data000000000031  \n",
            "  inflating: val/val/c/data000000000032  \n",
            "  inflating: val/val/c/data000000000033  \n",
            "  inflating: val/val/c/data000000000034  \n",
            "  inflating: val/val/c/data000000000035  \n",
            "  inflating: val/val/c/data000000000036  \n",
            "  inflating: val/val/c/data000000000037  \n",
            "  inflating: val/val/c/data000000000038  \n",
            "  inflating: val/val/c/data000000000039  \n",
            "  inflating: val/val/c/data000000000040  \n",
            "  inflating: val/val/c/data000000000041  \n",
            "  inflating: val/val/c/data000000000042  \n",
            "  inflating: val/val/c/data000000000043  \n",
            "  inflating: val/val/c/data000000000044  \n",
            "  inflating: val/val/c/data000000000045  \n",
            "  inflating: val/val/c/data000000000046  \n",
            "  inflating: val/val/c/data000000000047  \n",
            "  inflating: val/val/c/data000000000048  \n",
            "  inflating: val/val/c/data000000000049  \n",
            "  inflating: val/val/c/data000000000050  \n",
            "  inflating: val/val/c/data000000000051  \n",
            "  inflating: val/val/c/data000000000052  \n",
            "  inflating: val/val/c/data000000000053  \n",
            "  inflating: val/val/c/data000000000054  \n",
            "  inflating: val/val/c/data000000000055  \n",
            "  inflating: val/val/c/data000000000056  \n",
            "  inflating: val/val/c/data000000000057  \n",
            "  inflating: val/val/c/data000000000058  \n",
            "  inflating: val/val/c/data000000000059  \n",
            "  inflating: val/val/c/data000000000060  \n",
            "  inflating: val/val/c/data000000000061  \n",
            "  inflating: val/val/c/data000000000062  \n",
            "  inflating: val/val/c/data000000000063  \n",
            "  inflating: val/val/c/data000000000064  \n",
            "  inflating: val/val/c/data000000000065  \n",
            "  inflating: val/val/c/data000000000066  \n",
            "  inflating: val/val/c/data000000000067  \n",
            "  inflating: val/val/c/data000000000068  \n",
            "  inflating: val/val/c/data000000000069  \n",
            "  inflating: val/val/c/data000000000070  \n",
            "  inflating: val/val/c/data000000000071  \n",
            "  inflating: val/val/c/data000000000072  \n",
            "  inflating: val/val/c/data000000000073  \n",
            "  inflating: val/val/c/data000000000074  \n",
            "  inflating: val/val/c/data000000000075  \n",
            "  inflating: val/val/c/data000000000076  \n",
            "  inflating: val/val/c/data000000000077  \n",
            "  inflating: val/val/c/data000000000078  \n",
            "  inflating: val/val/c/data000000000079  \n",
            "  inflating: val/val/c/data000000000080  \n",
            "  inflating: val/val/c/data000000000081  \n",
            "  inflating: val/val/c/data000000000082  \n",
            "  inflating: val/val/c/data000000000083  \n",
            "  inflating: val/val/c/data000000000084  \n",
            "  inflating: val/val/c/data000000000085  \n",
            "  inflating: val/val/c/data000000000086  \n",
            "  inflating: val/val/c/data000000000087  \n",
            "  inflating: val/val/c/data000000000088  \n",
            "  inflating: val/val/c/data000000000089  \n",
            "  inflating: val/val/c/data000000000090  \n",
            "  inflating: val/val/c/data000000000091  \n",
            "  inflating: val/val/c/data000000000092  \n",
            "  inflating: val/val/c/data000000000093  \n",
            "  inflating: val/val/c/data000000000094  \n",
            "  inflating: val/val/c/data000000000095  \n",
            "  inflating: val/val/c/data000000000096  \n",
            "  inflating: val/val/c/data000000000097  \n",
            "  inflating: val/val/c/data000000000098  \n",
            "  inflating: val/val/c/data000000000099  \n",
            "  inflating: val/val/c/data000000000100  \n",
            "  inflating: val/val/c/data000000000101  \n",
            "  inflating: val/val/c/data000000000102  \n",
            "  inflating: val/val/c/data000000000103  \n",
            "  inflating: val/val/c/data000000000104  \n",
            "  inflating: val/val/c/data000000000105  \n",
            "  inflating: val/val/c/data000000000106  \n",
            "  inflating: val/val/c/data000000000107  \n",
            "  inflating: val/val/c/data000000000108  \n",
            "  inflating: val/val/c/data000000000109  \n",
            "  inflating: val/val/c/data000000000110  \n",
            "  inflating: val/val/c/data000000000111  \n",
            "  inflating: val/val/c/data000000000112  \n",
            "  inflating: val/val/c/data000000000113  \n",
            "  inflating: val/val/c/data000000000114  \n",
            "  inflating: val/val/c/data000000000115  \n",
            "  inflating: val/val/c/data000000000116  \n",
            "  inflating: val/val/c/data000000000117  \n",
            "  inflating: val/val/c/data000000000118  \n",
            "  inflating: val/val/c/data000000000119  \n",
            "  inflating: val/val/c/data000000000120  \n",
            "  inflating: val/val/c/data000000000121  \n",
            "  inflating: val/val/c/data000000000122  \n",
            "  inflating: val/val/c/data000000000123  \n",
            "  inflating: val/val/c/data000000000124  \n",
            "  inflating: val/val/c/data000000000125  \n",
            "  inflating: val/val/c/data000000000126  \n",
            "  inflating: val/val/c/data000000000127  \n",
            "  inflating: val/val/c/data000000000128  \n",
            "  inflating: val/val/c/data000000000129  \n",
            "  inflating: val/val/c/data000000000130  \n",
            "  inflating: val/val/c/data000000000131  \n",
            "  inflating: val/val/c/data000000000132  \n",
            "  inflating: val/val/c/data000000000133  \n",
            "  inflating: val/val/c/data000000000134  \n",
            "  inflating: val/val/c/data000000000135  \n",
            "  inflating: val/val/c/data000000000136  \n",
            "  inflating: val/val/c/data000000000137  \n",
            "  inflating: val/val/c/data000000000138  \n",
            "  inflating: val/val/c/data000000000139  \n",
            "  inflating: val/val/c/data000000000140  \n",
            "  inflating: val/val/c/data000000000141  \n",
            "  inflating: val/val/c/data000000000142  \n",
            "  inflating: val/val/c/data000000000143  \n",
            "  inflating: val/val/c/data000000000144  \n",
            "  inflating: val/val/c/data000000000145  \n",
            "  inflating: val/val/c/data000000000146  \n",
            "  inflating: val/val/c/data000000000147  \n",
            "  inflating: val/val/c/data000000000148  \n",
            "  inflating: val/val/c/data000000000149  \n",
            "  inflating: val/val/c/data000000000150  \n",
            "  inflating: val/val/c/data000000000151  \n",
            "  inflating: val/val/c/data000000000152  \n",
            "  inflating: val/val/c/data000000000153  \n",
            "  inflating: val/val/c/data000000000154  \n",
            "  inflating: val/val/c/data000000000155  \n",
            "  inflating: val/val/c/data000000000156  \n",
            "  inflating: val/val/c/data000000000157  \n",
            "  inflating: val/val/c/data000000000158  \n",
            "  inflating: val/val/c/data000000000159  \n",
            "  inflating: val/val/c/data000000000160  \n",
            "  inflating: val/val/c/data000000000161  \n",
            "  inflating: val/val/c/data000000000162  \n",
            "  inflating: val/val/c/data000000000163  \n",
            "  inflating: val/val/c/data000000000164  \n",
            "  inflating: val/val/c/data000000000165  \n",
            "  inflating: val/val/c/data000000000166  \n",
            "  inflating: val/val/d/data000000000000  \n",
            "  inflating: val/val/d/data000000000001  \n",
            "  inflating: val/val/d/data000000000002  \n",
            "  inflating: val/val/d/data000000000003  \n",
            "  inflating: val/val/d/data000000000004  \n",
            "  inflating: val/val/d/data000000000005  \n",
            "  inflating: val/val/d/data000000000006  \n",
            "  inflating: val/val/e/data000000000000  \n",
            "  inflating: val/val/e/data000000000001  \n",
            "  inflating: val/val/e/data000000000002  \n",
            "  inflating: val/val/e/data000000000003  \n",
            "  inflating: val/val/e/data000000000004  \n",
            "  inflating: val/val/e/data000000000005  \n",
            "  inflating: val/val/e/data000000000006  \n",
            "  inflating: val/val/e/data000000000007  \n",
            "  inflating: val/val/e/data000000000008  \n",
            "  inflating: val/val/e/data000000000009  \n",
            "  inflating: val/val/e/data000000000010  \n",
            "  inflating: val/val/e/data000000000011  \n",
            "  inflating: val/val/e/data000000000012  \n",
            "  inflating: val/val/e/data000000000013  \n",
            "  inflating: val/val/e/data000000000014  \n",
            "  inflating: val/val/e/data000000000015  \n",
            "  inflating: val/val/e/data000000000016  \n",
            "  inflating: val/val/e/data000000000017  \n",
            "  inflating: val/val/e/data000000000018  \n",
            "  inflating: val/val/f/data000000000000  \n",
            "  inflating: val/val/f/data000000000001  \n",
            "  inflating: val/val/f/data000000000002  \n",
            "  inflating: val/val/f/data000000000003  \n",
            "  inflating: val/val/f/data000000000004  \n",
            "  inflating: val/val/f/data000000000005  \n",
            "  inflating: val/val/f/data000000000006  \n",
            "  inflating: val/val/f/data000000000007  \n",
            "  inflating: val/val/f/data000000000008  \n",
            "  inflating: val/val/f/data000000000009  \n",
            "  inflating: val/val/f/data000000000010  \n",
            "  inflating: val/val/f/data000000000011  \n",
            "  inflating: val/val/f/data000000000012  \n",
            "  inflating: val/val/f/data000000000013  \n",
            "  inflating: val/val/f/data000000000014  \n",
            "  inflating: val/val/f/data000000000015  \n",
            "  inflating: val/val/f/data000000000016  \n",
            "  inflating: val/val/f/data000000000017  \n",
            "  inflating: val/val/f/data000000000018  \n",
            "  inflating: val/val/f/data000000000019  \n",
            "  inflating: val/val/f/data000000000020  \n",
            "  inflating: val/val/f/data000000000021  \n",
            "  inflating: val/val/f/data000000000022  \n",
            "  inflating: val/val/f/data000000000023  \n",
            "  inflating: val/val/f/data000000000024  \n",
            "  inflating: val/val/f/data000000000025  \n",
            "  inflating: val/val/f/data000000000026  \n",
            "  inflating: val/val/f/data000000000027  \n",
            "  inflating: val/val/f/data000000000028  \n",
            "  inflating: val/val/f/data000000000029  \n",
            "  inflating: val/val/f/data000000000030  \n",
            "  inflating: val/val/f/data000000000031  \n",
            "  inflating: val/val/f/data000000000032  \n",
            "  inflating: val/val/f/data000000000033  \n",
            "  inflating: val/val/f/data000000000034  \n",
            "  inflating: val/val/f/data000000000035  \n",
            "  inflating: val/val/f/data000000000036  \n",
            "  inflating: val/val/f/data000000000037  \n",
            "  inflating: val/val/f/data000000000038  \n",
            "  inflating: val/val/f/data000000000039  \n",
            "  inflating: val/val/f/data000000000040  \n",
            "  inflating: val/val/f/data000000000041  \n",
            "  inflating: val/val/f/data000000000042  \n",
            "  inflating: val/val/f/data000000000043  \n",
            "  inflating: val/val/f/data000000000044  \n",
            "  inflating: val/val/f/data000000000045  \n",
            "  inflating: val/val/f/data000000000046  \n",
            "  inflating: val/val/f/data000000000047  \n",
            "  inflating: val/val/f/data000000000048  \n",
            "  inflating: val/val/f/data000000000049  \n",
            "  inflating: val/val/f/data000000000050  \n",
            "  inflating: val/val/g/data000000000000  \n",
            "  inflating: val/val/g/data000000000001  \n",
            "  inflating: val/val/g/data000000000002  \n",
            "  inflating: val/val/g/data000000000003  \n",
            "  inflating: val/val/g/data000000000004  \n",
            "  inflating: val/val/g/data000000000005  \n",
            "  inflating: val/val/g/data000000000006  \n",
            "  inflating: val/val/g/data000000000007  \n",
            "  inflating: val/val/g/data000000000008  \n",
            "  inflating: val/val/g/data000000000009  \n",
            "  inflating: val/val/g/data000000000010  \n",
            "  inflating: val/val/g/data000000000011  \n",
            "  inflating: val/val/g/data000000000012  \n",
            "  inflating: val/val/g/data000000000013  \n",
            "  inflating: val/val/g/data000000000014  \n",
            "  inflating: val/val/g/data000000000015  \n",
            "  inflating: val/val/g/data000000000016  \n",
            "  inflating: val/val/g/data000000000017  \n",
            "  inflating: val/val/g/data000000000019  \n",
            "  inflating: val/val/g/data000000000020  \n",
            "  inflating: val/val/g/data000000000021  \n",
            "  inflating: val/val/g/data000000000022  \n",
            "  inflating: val/val/g/data000000000023  \n",
            "  inflating: val/val/g/data000000000024  \n",
            "  inflating: val/val/g/data000000000025  \n",
            "  inflating: val/val/g/data000000000026  \n",
            "  inflating: val/val/g/data000000000027  \n",
            "  inflating: val/val/g/data000000000028  \n",
            "  inflating: val/val/g/data000000000029  \n",
            "  inflating: val/val/g/data000000000030  \n",
            "  inflating: val/val/g/data000000000033  \n",
            "  inflating: val/val/g/data000000000034  \n",
            "  inflating: val/val/g/data000000000035  \n",
            "  inflating: val/val/g/data000000000036  \n",
            "  inflating: val/val/g/data000000000037  \n",
            "  inflating: val/val/g/data000000000038  \n",
            "  inflating: val/val/g/data000000000039  \n",
            "  inflating: val/val/g/data000000000040  \n",
            "  inflating: val/val/g/data000000000041  \n",
            "  inflating: val/val/g/data000000000042  \n",
            "  inflating: val/val/g/data000000000043  \n",
            "  inflating: val/val/g/data000000000044  \n",
            "  inflating: val/val/g/data000000000045  \n",
            "  inflating: val/val/g/data000000000046  \n",
            "  inflating: val/val/g/data000000000047  \n",
            "  inflating: val/val/g/data000000000048  \n",
            "  inflating: val/val/g/data000000000049  \n",
            "  inflating: val/val/g/data000000000050  \n",
            "  inflating: val/val/g/data000000000051  \n",
            "  inflating: val/val/g/data000000000052  \n",
            "  inflating: val/val/g/data000000000053  \n",
            "  inflating: val/val/g/data000000000054  \n",
            "  inflating: val/val/g/data000000000055  \n",
            "  inflating: val/val/g/data000000000056  \n",
            "  inflating: val/val/g/data000000000057  \n",
            "  inflating: val/val/g/data000000000058  \n",
            "  inflating: val/val/g/data000000000060  \n",
            "  inflating: val/val/g/data000000000061  \n",
            "  inflating: val/val/g/data000000000062  \n",
            "  inflating: val/val/g/data000000000063  \n",
            "  inflating: val/val/g/data000000000064  \n",
            "  inflating: val/val/g/data000000000065  \n",
            "  inflating: val/val/g/data000000000066  \n",
            "  inflating: val/val/g/data000000000067  \n",
            "  inflating: val/val/g/data000000000068  \n",
            "  inflating: val/val/g/data000000000069  \n",
            "  inflating: val/val/g/data000000000070  \n",
            "  inflating: val/val/g/data000000000071  \n",
            "  inflating: val/val/g/data000000000072  \n",
            "  inflating: val/val/g/data000000000073  \n",
            "  inflating: val/val/g/data000000000074  \n",
            "  inflating: val/val/g/data000000000075  \n",
            "  inflating: val/val/g/data000000000076  \n",
            "  inflating: val/val/g/data000000000077  \n",
            "  inflating: val/val/g/data000000000078  \n",
            "  inflating: val/val/g/data000000000079  \n",
            "  inflating: val/val/g/data000000000080  \n",
            "  inflating: val/val/g/data000000000081  \n",
            "  inflating: val/val/g/data000000000082  \n",
            "  inflating: val/val/g/data000000000083  \n",
            "  inflating: val/val/g/data000000000084  \n",
            "  inflating: val/val/g/data000000000085  \n",
            "  inflating: val/val/g/data000000000086  \n",
            "  inflating: val/val/g/data000000000087  \n",
            "  inflating: val/val/g/data000000000088  \n",
            "  inflating: val/val/g/data000000000090  \n",
            "  inflating: val/val/g/data000000000091  \n",
            "  inflating: val/val/g/data000000000092  \n",
            "  inflating: val/val/g/data000000000093  \n",
            "  inflating: val/val/g/data000000000094  \n",
            "  inflating: val/val/g/data000000000095  \n",
            "  inflating: val/val/g/data000000000096  \n",
            "  inflating: val/val/g/data000000000097  \n",
            "  inflating: val/val/g/data000000000098  \n",
            "  inflating: val/val/g/data000000000099  \n",
            "  inflating: val/val/g/data000000000100  \n",
            "  inflating: val/val/g/data000000000101  \n",
            "  inflating: val/val/g/data000000000102  \n",
            "  inflating: val/val/g/data000000000103  \n",
            "  inflating: val/val/g/data000000000105  \n",
            "  inflating: val/val/g/data000000000106  \n",
            "  inflating: val/val/g/data000000000107  \n",
            "  inflating: val/val/g/data000000000108  \n",
            "  inflating: val/val/g/data000000000109  \n",
            "  inflating: val/val/g/data000000000110  \n",
            "  inflating: val/val/g/data000000000111  \n",
            "  inflating: val/val/g/data000000000113  \n",
            "  inflating: val/val/g/data000000000114  \n",
            "  inflating: val/val/g/data000000000115  \n",
            "  inflating: val/val/g/data000000000116  \n",
            "  inflating: val/val/g/data000000000117  \n",
            "  inflating: val/val/g/data000000000118  \n",
            "  inflating: val/val/g/data000000000119  \n",
            "  inflating: val/val/g/data000000000120  \n",
            "  inflating: val/val/g/data000000000121  \n",
            "  inflating: val/val/g/data000000000122  \n",
            "  inflating: val/val/g/data000000000123  \n",
            "  inflating: val/val/g/data000000000124  \n",
            "  inflating: val/val/g/data000000000125  \n",
            "  inflating: val/val/g/data000000000126  \n",
            "  inflating: val/val/g/data000000000127  \n",
            "  inflating: val/val/g/data000000000128  \n",
            "  inflating: val/val/g/data000000000129  \n",
            "  inflating: val/val/g/data000000000130  \n",
            "  inflating: val/val/g/data000000000131  \n",
            "  inflating: val/val/g/data000000000133  \n",
            "  inflating: val/val/g/data000000000134  \n",
            "  inflating: val/val/g/data000000000135  \n",
            "  inflating: val/val/g/data000000000136  \n",
            "  inflating: val/val/g/data000000000137  \n",
            "  inflating: val/val/g/data000000000138  \n",
            "  inflating: val/val/g/data000000000139  \n",
            "  inflating: val/val/g/data000000000141  \n",
            "  inflating: val/val/g/data000000000142  \n",
            "  inflating: val/val/g/data000000000143  \n",
            "  inflating: val/val/g/data000000000144  \n",
            "  inflating: val/val/g/data000000000145  \n",
            "  inflating: val/val/g/data000000000146  \n",
            "  inflating: val/val/g/data000000000147  \n",
            "  inflating: val/val/g/data000000000148  \n",
            "  inflating: val/val/g/data000000000150  \n",
            "  inflating: val/val/g/data000000000151  \n",
            "  inflating: val/val/g/data000000000152  \n",
            "  inflating: val/val/g/data000000000153  \n",
            "  inflating: val/val/g/data000000000154  \n",
            "  inflating: val/val/g/data000000000155  \n",
            "  inflating: val/val/g/data000000000157  \n",
            "  inflating: val/val/g/data000000000158  \n",
            "  inflating: val/val/g/data000000000159  \n",
            "  inflating: val/val/g/data000000000160  \n",
            "  inflating: val/val/g/data000000000161  \n",
            "  inflating: val/val/g/data000000000163  \n",
            "  inflating: val/val/g/data000000000164  \n",
            "  inflating: val/val/g/data000000000165  \n",
            "  inflating: val/val/g/data000000000166  \n",
            "  inflating: val/val/h/data000000000000  \n",
            "  inflating: val/val/h/data000000000001  \n",
            "  inflating: val/val/h/data000000000002  \n",
            "  inflating: val/val/h/data000000000003  \n",
            "  inflating: val/val/h/data000000000004  \n",
            "  inflating: val/val/h/data000000000005  \n",
            "  inflating: val/val/h/data000000000006  \n",
            "  inflating: val/val/h/data000000000007  \n",
            "  inflating: val/val/h/data000000000008  \n",
            "  inflating: val/val/h/data000000000009  \n",
            "  inflating: val/val/h/data000000000010  \n",
            "  inflating: val/val/h/data000000000011  \n",
            "  inflating: val/val/h/data000000000012  \n",
            "  inflating: val/val/h/data000000000013  \n",
            "  inflating: val/val/h/data000000000014  \n",
            "  inflating: val/val/h/data000000000015  \n",
            "  inflating: val/val/h/data000000000016  \n",
            "  inflating: val/val/h/data000000000017  \n",
            "  inflating: val/val/h/data000000000018  \n",
            "  inflating: val/val/h/data000000000019  \n",
            "  inflating: val/val/h/data000000000020  \n",
            "  inflating: val/val/h/data000000000021  \n",
            "  inflating: val/val/h/data000000000022  \n",
            "  inflating: val/val/h/data000000000023  \n",
            "  inflating: val/val/h/data000000000024  \n",
            "  inflating: val/val/h/data000000000025  \n",
            "  inflating: val/val/h/data000000000026  \n",
            "  inflating: val/val/h/data000000000027  \n",
            "  inflating: val/val/h/data000000000028  \n",
            "  inflating: val/val/h/data000000000029  \n",
            "  inflating: val/val/h/data000000000030  \n",
            "  inflating: val/val/h/data000000000031  \n",
            "  inflating: val/val/h/data000000000032  \n",
            "  inflating: val/val/h/data000000000033  \n",
            "  inflating: val/val/h/data000000000034  \n",
            "  inflating: val/val/h/data000000000035  \n",
            "  inflating: val/val/h/data000000000036  \n",
            "  inflating: val/val/h/data000000000037  \n",
            "  inflating: val/val/h/data000000000038  \n",
            "  inflating: val/val/h/data000000000039  \n",
            "  inflating: val/val/h/data000000000040  \n",
            "  inflating: val/val/h/data000000000041  \n",
            "  inflating: val/val/h/data000000000042  \n",
            "  inflating: val/val/h/data000000000043  \n",
            "  inflating: val/val/h/data000000000044  \n",
            "  inflating: val/val/h/data000000000045  \n",
            "  inflating: val/val/h/data000000000046  \n",
            "  inflating: val/val/h/data000000000047  \n",
            "  inflating: val/val/h/data000000000048  \n",
            "  inflating: val/val/h/data000000000049  \n",
            "  inflating: val/val/h/data000000000050  \n",
            "  inflating: val/val/h/data000000000051  \n",
            "  inflating: val/val/h/data000000000052  \n",
            "  inflating: val/val/h/data000000000053  \n",
            "  inflating: val/val/h/data000000000054  \n",
            "  inflating: val/val/h/data000000000055  \n",
            "  inflating: val/val/h/data000000000056  \n",
            "  inflating: val/val/h/data000000000057  \n",
            "  inflating: val/val/h/data000000000058  \n",
            "  inflating: val/val/h/data000000000059  \n",
            "  inflating: val/val/h/data000000000060  \n",
            "  inflating: val/val/h/data000000000061  \n",
            "  inflating: val/val/h/data000000000062  \n",
            "  inflating: val/val/h/data000000000063  \n",
            "  inflating: val/val/h/data000000000064  \n",
            "  inflating: val/val/h/data000000000065  \n",
            "  inflating: val/val/h/data000000000066  \n",
            "  inflating: val/val/h/data000000000067  \n",
            "  inflating: val/val/h/data000000000068  \n",
            "  inflating: val/val/h/data000000000069  \n",
            "  inflating: val/val/h/data000000000070  \n",
            "  inflating: val/val/h/data000000000071  \n",
            "  inflating: val/val/h/data000000000072  \n",
            "  inflating: val/val/h/data000000000073  \n",
            "  inflating: val/val/h/data000000000074  \n",
            "  inflating: val/val/h/data000000000075  \n",
            "  inflating: val/val/h/data000000000076  \n",
            "  inflating: val/val/h/data000000000077  \n",
            "  inflating: val/val/h/data000000000078  \n",
            "  inflating: val/val/h/data000000000079  \n",
            "  inflating: val/val/h/data000000000080  \n",
            "  inflating: val/val/h/data000000000081  \n",
            "  inflating: val/val/h/data000000000082  \n",
            "  inflating: val/val/h/data000000000083  \n",
            "  inflating: val/val/h/data000000000084  \n",
            "  inflating: val/val/h/data000000000085  \n",
            "  inflating: val/val/h/data000000000086  \n",
            "  inflating: val/val/h/data000000000087  \n",
            "  inflating: val/val/h/data000000000088  \n",
            "  inflating: val/val/h/data000000000089  \n",
            "  inflating: val/val/h/data000000000090  \n",
            "  inflating: val/val/h/data000000000091  \n",
            "  inflating: val/val/h/data000000000092  \n",
            "  inflating: val/val/h/data000000000093  \n",
            "  inflating: val/val/h/data000000000094  \n",
            "  inflating: val/val/h/data000000000095  \n",
            "  inflating: val/val/h/data000000000096  \n",
            "  inflating: val/val/h/data000000000097  \n",
            "  inflating: val/val/h/data000000000098  \n",
            "  inflating: val/val/h/data000000000099  \n",
            "  inflating: val/val/h/data000000000100  \n",
            "  inflating: val/val/h/data000000000101  \n",
            "  inflating: val/val/h/data000000000102  \n",
            "  inflating: val/val/h/data000000000103  \n",
            "  inflating: val/val/h/data000000000104  \n",
            "  inflating: val/val/h/data000000000105  \n",
            "  inflating: val/val/h/data000000000106  \n",
            "  inflating: val/val/h/data000000000107  \n",
            "  inflating: val/val/h/data000000000108  \n",
            "  inflating: val/val/h/data000000000109  \n",
            "  inflating: val/val/h/data000000000110  \n",
            "  inflating: val/val/h/data000000000111  \n",
            "  inflating: val/val/h/data000000000112  \n",
            "  inflating: val/val/h/data000000000113  \n",
            "  inflating: val/val/h/data000000000114  \n",
            "  inflating: val/val/h/data000000000115  \n",
            "  inflating: val/val/h/data000000000116  \n",
            "  inflating: val/val/h/data000000000117  \n",
            "  inflating: val/val/h/data000000000118  \n",
            "  inflating: val/val/h/data000000000119  \n",
            "  inflating: val/val/h/data000000000120  \n",
            "  inflating: val/val/h/data000000000121  \n",
            "  inflating: val/val/h/data000000000122  \n",
            "  inflating: val/val/h/data000000000123  \n",
            "  inflating: val/val/h/data000000000124  \n",
            "  inflating: val/val/h/data000000000125  \n",
            "  inflating: val/val/h/data000000000126  \n",
            "  inflating: val/val/h/data000000000127  \n",
            "  inflating: val/val/h/data000000000128  \n",
            "  inflating: val/val/h/data000000000129  \n",
            "  inflating: val/val/h/data000000000130  \n",
            "  inflating: val/val/h/data000000000131  \n",
            "  inflating: val/val/h/data000000000132  \n",
            "  inflating: val/val/h/data000000000133  \n",
            "  inflating: val/val/h/data000000000134  \n",
            "  inflating: val/val/h/data000000000135  \n",
            "  inflating: val/val/h/data000000000136  \n",
            "  inflating: val/val/h/data000000000137  \n",
            "  inflating: val/val/h/data000000000138  \n",
            "  inflating: val/val/h/data000000000139  \n",
            "  inflating: val/val/h/data000000000140  \n",
            "  inflating: val/val/h/data000000000141  \n",
            "  inflating: val/val/h/data000000000142  \n",
            "  inflating: val/val/h/data000000000143  \n",
            "  inflating: val/val/h/data000000000144  \n",
            "  inflating: val/val/h/data000000000145  \n",
            "  inflating: val/val/h/data000000000146  \n",
            "  inflating: val/val/h/data000000000147  \n",
            "  inflating: val/val/h/data000000000148  \n",
            "  inflating: val/val/h/data000000000149  \n",
            "  inflating: val/val/h/data000000000150  \n",
            "  inflating: val/val/h/data000000000151  \n",
            "  inflating: val/val/h/data000000000152  \n",
            "  inflating: val/val/h/data000000000153  \n",
            "  inflating: val/val/h/data000000000154  \n",
            "  inflating: val/val/h/data000000000155  \n",
            "  inflating: val/val/h/data000000000156  \n",
            "  inflating: val/val/h/data000000000157  \n",
            "  inflating: val/val/h/data000000000158  \n",
            "  inflating: val/val/h/data000000000159  \n",
            "  inflating: val/val/h/data000000000160  \n",
            "  inflating: val/val/h/data000000000161  \n",
            "  inflating: val/val/h/data000000000162  \n",
            "  inflating: val/val/h/data000000000163  \n",
            "  inflating: val/val/h/data000000000164  \n",
            "  inflating: val/val/h/data000000000165  \n",
            "  inflating: val/val/h/data000000000166  \n",
            "  inflating: val/val/y/data000000000000  \n",
            "  inflating: val/val/y/data000000000001  \n",
            "  inflating: val/val/y/data000000000002  \n",
            "  inflating: val/val/y/data000000000003  \n",
            "  inflating: val/val/y/data000000000004  \n",
            "  inflating: val/val/y/data000000000005  \n",
            "  inflating: val/val/y/data000000000006  \n",
            "  inflating: val/val/y/data000000000007  \n",
            "  inflating: val/val/y/data000000000008  \n",
            "  inflating: val/val/y/data000000000009  \n",
            "  inflating: val/val/y/data000000000010  \n",
            "  inflating: val/val/y/data000000000011  \n",
            "  inflating: val/val/y/data000000000012  \n",
            "  inflating: val/val/y/data000000000013  \n",
            "  inflating: val/val/y/data000000000014  \n",
            "  inflating: val/val/y/data000000000015  \n",
            "  inflating: val/val/y/data000000000016  \n",
            "  inflating: val/val/y/data000000000017  \n",
            "  inflating: val/val/y/data000000000018  \n",
            "  inflating: val/val/y/data000000000019  \n",
            "  inflating: val/val/y/data000000000020  \n",
            "  inflating: val/val/y/data000000000021  \n",
            "  inflating: val/val/y/data000000000022  \n",
            "  inflating: val/val/y/data000000000023  \n",
            "  inflating: val/val/y/data000000000024  \n",
            "  inflating: val/val/y/data000000000025  \n",
            "  inflating: val/val/y/data000000000026  \n",
            "  inflating: val/val/y/data000000000027  \n",
            "  inflating: val/val/y/data000000000028  \n",
            "  inflating: val/val/y/data000000000029  \n",
            "  inflating: val/val/y/data000000000030  \n",
            "  inflating: val/val/y/data000000000031  \n",
            "  inflating: val/val/y/data000000000032  \n",
            "  inflating: val/val/y/data000000000033  \n",
            "  inflating: val/val/y/data000000000034  \n",
            "  inflating: val/val/y/data000000000035  \n",
            "  inflating: val/val/y/data000000000036  \n",
            "  inflating: val/val/y/data000000000037  \n",
            "  inflating: val/val/y/data000000000038  \n",
            "  inflating: val/val/y/data000000000039  \n",
            "  inflating: val/val/y/data000000000040  \n",
            "  inflating: val/val/y/data000000000041  \n",
            "  inflating: val/val/y/data000000000042  \n",
            "  inflating: val/val/y/data000000000043  \n",
            "  inflating: val/val/y/data000000000044  \n",
            "  inflating: val/val/y/data000000000045  \n",
            "  inflating: val/val/y/data000000000046  \n",
            "  inflating: val/val/y/data000000000047  \n",
            "  inflating: val/val/y/data000000000048  \n",
            "  inflating: val/val/y/data000000000049  \n",
            "  inflating: val/val/y/data000000000050  \n",
            "  inflating: val/val/y/data000000000051  \n",
            "  inflating: val/val/y/data000000000052  \n",
            "  inflating: val/val/y/data000000000053  \n",
            "  inflating: val/val/y/data000000000054  \n",
            "  inflating: val/val/y/data000000000055  \n",
            "  inflating: val/val/y/data000000000056  \n",
            "  inflating: val/val/y/data000000000057  \n",
            "  inflating: val/val/y/data000000000058  \n",
            "  inflating: val/val/y/data000000000059  \n",
            "  inflating: val/val/y/data000000000060  \n",
            "  inflating: val/val/y/data000000000061  \n",
            "  inflating: val/val/y/data000000000062  \n",
            "  inflating: val/val/y/data000000000063  \n",
            "  inflating: val/val/y/data000000000064  \n",
            "  inflating: val/val/y/data000000000065  \n",
            "  inflating: val/val/y/data000000000066  \n",
            "  inflating: val/val/y/data000000000067  \n",
            "  inflating: val/val/y/data000000000068  \n",
            "  inflating: val/val/y/data000000000069  \n",
            "  inflating: val/val/y/data000000000070  \n",
            "  inflating: val/val/y/data000000000071  \n",
            "  inflating: val/val/y/data000000000072  \n",
            "  inflating: val/val/y/data000000000073  \n",
            "  inflating: val/val/y/data000000000074  \n",
            "  inflating: val/val/y/data000000000075  \n",
            "  inflating: val/val/y/data000000000076  \n",
            "  inflating: val/val/y/data000000000077  \n",
            "  inflating: val/val/y/data000000000078  \n",
            "  inflating: val/val/y/data000000000079  \n",
            "  inflating: val/val/y/data000000000080  \n",
            "  inflating: val/val/y/data000000000081  \n",
            "  inflating: val/val/y/data000000000082  \n",
            "  inflating: val/val/y/data000000000083  \n",
            "  inflating: val/val/y/data000000000084  \n",
            "  inflating: val/val/y/data000000000085  \n",
            "  inflating: val/val/y/data000000000086  \n",
            "  inflating: val/val/y/data000000000087  \n",
            "  inflating: val/val/y/data000000000088  \n",
            "  inflating: val/val/y/data000000000089  \n",
            "  inflating: val/val/y/data000000000090  \n",
            "  inflating: val/val/y/data000000000091  \n",
            "  inflating: val/val/y/data000000000092  \n",
            "  inflating: val/val/y/data000000000093  \n",
            "  inflating: val/val/y/data000000000094  \n",
            "  inflating: val/val/y/data000000000095  \n",
            "  inflating: val/val/y/data000000000096  \n",
            "  inflating: val/val/y/data000000000097  \n",
            "  inflating: val/val/y/data000000000098  \n",
            "  inflating: val/val/y/data000000000099  \n",
            "  inflating: val/val/y/data000000000100  \n",
            "  inflating: val/val/y/data000000000101  \n",
            "  inflating: val/val/y/data000000000102  \n",
            "  inflating: val/val/y/data000000000103  \n",
            "  inflating: val/val/y/data000000000104  \n",
            "  inflating: val/val/y/data000000000105  \n",
            "big-patent.zip\tdrive  sample_data  spark-warehouse  train  val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patents_df = spark.read.json(\"train/train/*/data*\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "g3dbh_h6gXE-",
        "outputId": "c068628a-9d83-4956-9dde-16a02915e7bd"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/usr/lib/python3.9/socket.py\", line 704, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-03e599f6a872>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpatents_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/train/*/data*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, path, schema, primitivesAsString, prefersDecimal, allowComments, allowUnquotedFieldNames, allowSingleQuotes, allowNumericLeadingZero, allowBackslashEscapingAnyCharacter, mode, columnNameOfCorruptRecord, dateFormat, timestampFormat, multiLine, allowUnquotedControlChars, lineSep, samplingRatio, dropFieldIfAllNull, encoding, locale, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, allowNonNumericNumbers)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data structure\n",
        "The data has four columns `abstract`, `publication_number`, `description`. They are all strings."
      ],
      "metadata": {
        "id": "uTxZZOMnhIVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patents_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPG6UpzQhUDm",
        "outputId": "d57dd53e-ee37-407a-a5ba-65b56b2c5867"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+--------------------+------------------+\n",
            "|            abstract|application_number|         description|publication_number|\n",
            "+--------------------+------------------+--------------------+------------------+\n",
            "|a probe for detec...|     US-76085585-A|referring now to ...|      US-4680475-A|\n",
            "|an image forming ...|     US-32365908-A|in describing emb...|  US-2009136245-A1|\n",
            "|a vibrating trans...|     US-92269486-A|referring now to ...|      US-4872335-A|\n",
            "|the present inven...|     US-26698508-A|as used herein a ...|  US-2009176244-A1|\n",
            "|an imaging record...|     US-40116089-A|referring now to ...|      US-4978974-A|\n",
            "|apparatus for obt...|     US-18070180-A|the invention rev...|      US-4329043-A|\n",
            "|liquid developers...|     US-82413577-A|liquid electrogra...|      US-4170563-A|\n",
            "|an apparatus for ...|     US-34700903-A|the present inven...|     US-7246255-B1|\n",
            "|apparatus for con...| US-201514979602-A|in the detailed d...|  US-2017188019-A1|\n",
            "|a thread has a co...|     US-80130907-A|a worker thread u...|  US-2008282111-A1|\n",
            "|apparatus and met...| US-201213475953-A|the following des...|  US-2012303195-A1|\n",
            "|an image - formin...|     US-67908376-A|typical examples ...|      US-4073651-A|\n",
            "|to provide smooth...|     US-35568389-A|in fig1 there is ...|      US-4986919-A|\n",
            "|the method of pro...|     US-72218791-A|referring first t...|      US-5189467-A|\n",
            "|this invention is...|      US-3486879-A|the preferred fil...|      US-4203766-A|\n",
            "|a system and meth...|     US-16248993-A|referring now to ...|      US-5483651-A|\n",
            "|a sensor system f...|     US-65249710-A|the present inven...|  US-2010170788-A1|\n",
            "|a computer system...|     US-60307503-A|the present inven...|  US-2004059865-A1|\n",
            "|in a defect inspe...|     US-24935905-A|with reference to...|     US-7508526-B2|\n",
            "|a magnetic resona...|     US-84678304-A|fig1 shows an mri...|     US-7084631-B2|\n",
            "+--------------------+------------------+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenizing\n",
        "We'll start by getting non-stopwords and named entities."
      ],
      "metadata": {
        "id": "HNHjBW-dlqlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import StringType, ArrayType, FloatType\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "def tokenize_content(content):\n",
        "  tokens = nltk.word_tokenize(content)\n",
        "  words = [\n",
        "    token.lower() \n",
        "    for token in tokens \n",
        "      if token.isalpha() and token.lower() not in stopwords\n",
        "  ]\n",
        "  return words\n",
        "\n",
        "tokenize_content_udf = udf(tokenize_content, ArrayType(StringType()))\n",
        "\n",
        "def get_sentence_ne(sentence):\n",
        "  print(sentence)\n",
        "  chunked = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sentence)))\n",
        "  return [ \n",
        "      \" \".join(w for w, t in elt) \n",
        "      for elt in chunked if isinstance(elt, nltk.Tree) \n",
        "  ]\n",
        "\n",
        "def get_ne(content):\n",
        "  sentences = nltk.sent_tokenize(content)\n",
        "  for sentence in sentences:\n",
        "    print(sentence)\n",
        "  sentence_nes = [get_sentence_ne(sentence) for sentence in sentences]\n",
        "  return [ne for nes in sentence_nes for ne in nes]\n",
        "\n",
        "get_ne_udf = udf(get_ne, ArrayType(StringType()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVIPBDTOhgry",
        "outputId": "6a25efb4-ed17-4fb8-f1cf-ed65cbfbd6cb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Abstract\n",
        "We'll work over the abstract first because it is smaller."
      ],
      "metadata": {
        "id": "NzF7EddQmTeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patents_df = patents_df.withColumn(\"abstract_tokens\", tokenize_content_udf(\"abstract\"))\n",
        "patents_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAHGdmKujyb1",
        "outputId": "24277f5b-6f2c-4bea-82e9-36953c3c9e06"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+--------------------+------------------+--------------------+\n",
            "|            abstract|application_number|         description|publication_number|     abstract_tokens|\n",
            "+--------------------+------------------+--------------------+------------------+--------------------+\n",
            "|a probe for detec...|     US-76085585-A|referring now to ...|      US-4680475-A|[probe, detecting...|\n",
            "|an image forming ...|     US-32365908-A|in describing emb...|  US-2009136245-A1|[image, forming, ...|\n",
            "|a vibrating trans...|     US-92269486-A|referring now to ...|      US-4872335-A|[vibrating, trans...|\n",
            "|the present inven...|     US-26698508-A|as used herein a ...|  US-2009176244-A1|[present, inventi...|\n",
            "|an imaging record...|     US-40116089-A|referring now to ...|      US-4978974-A|[imaging, recorde...|\n",
            "|apparatus for obt...|     US-18070180-A|the invention rev...|      US-4329043-A|[apparatus, obtai...|\n",
            "|liquid developers...|     US-82413577-A|liquid electrogra...|      US-4170563-A|[liquid, develope...|\n",
            "|an apparatus for ...|     US-34700903-A|the present inven...|     US-7246255-B1|[apparatus, metho...|\n",
            "|apparatus for con...| US-201514979602-A|in the detailed d...|  US-2017188019-A1|[apparatus, contr...|\n",
            "|a thread has a co...|     US-80130907-A|a worker thread u...|  US-2008282111-A1|[thread, corrupti...|\n",
            "|apparatus and met...| US-201213475953-A|the following des...|  US-2012303195-A1|[apparatus, metho...|\n",
            "|an image - formin...|     US-67908376-A|typical examples ...|      US-4073651-A|[image, forming, ...|\n",
            "|to provide smooth...|     US-35568389-A|in fig1 there is ...|      US-4986919-A|[provide, smooth,...|\n",
            "|the method of pro...|     US-72218791-A|referring first t...|      US-5189467-A|[method, producin...|\n",
            "|this invention is...|      US-3486879-A|the preferred fil...|      US-4203766-A|[invention, conce...|\n",
            "|a system and meth...|     US-16248993-A|referring now to ...|      US-5483651-A|[system, method, ...|\n",
            "|a sensor system f...|     US-65249710-A|the present inven...|  US-2010170788-A1|[sensor, system, ...|\n",
            "|a computer system...|     US-60307503-A|the present inven...|  US-2004059865-A1|[computer, system...|\n",
            "|in a defect inspe...|     US-24935905-A|with reference to...|     US-7508526-B2|[defect, inspecti...|\n",
            "|a magnetic resona...|     US-84678304-A|fig1 shows an mri...|     US-7084631-B2|[magnetic, resona...|\n",
            "+--------------------+------------------+--------------------+------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patents_df = patents_df.withColumn(\"abstract_ne\", get_ne_udf(\"abstract\"))\n",
        "patents_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eToXfx2Wklt6",
        "outputId": "f3108903-87f6-4b95-bb07-41171b0c23bf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+\n",
            "|            abstract|application_number|         description|publication_number|     abstract_tokens|abstract_ne|\n",
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+\n",
            "|a probe for detec...|     US-76085585-A|referring now to ...|      US-4680475-A|[probe, detecting...|         []|\n",
            "|an image forming ...|     US-32365908-A|in describing emb...|  US-2009136245-A1|[image, forming, ...|         []|\n",
            "|a vibrating trans...|     US-92269486-A|referring now to ...|      US-4872335-A|[vibrating, trans...|         []|\n",
            "|the present inven...|     US-26698508-A|as used herein a ...|  US-2009176244-A1|[present, inventi...|         []|\n",
            "|an imaging record...|     US-40116089-A|referring now to ...|      US-4978974-A|[imaging, recorde...|         []|\n",
            "|apparatus for obt...|     US-18070180-A|the invention rev...|      US-4329043-A|[apparatus, obtai...|         []|\n",
            "|liquid developers...|     US-82413577-A|liquid electrogra...|      US-4170563-A|[liquid, develope...|         []|\n",
            "|an apparatus for ...|     US-34700903-A|the present inven...|     US-7246255-B1|[apparatus, metho...|         []|\n",
            "|apparatus for con...| US-201514979602-A|in the detailed d...|  US-2017188019-A1|[apparatus, contr...|         []|\n",
            "|a thread has a co...|     US-80130907-A|a worker thread u...|  US-2008282111-A1|[thread, corrupti...|         []|\n",
            "|apparatus and met...| US-201213475953-A|the following des...|  US-2012303195-A1|[apparatus, metho...|         []|\n",
            "|an image - formin...|     US-67908376-A|typical examples ...|      US-4073651-A|[image, forming, ...|         []|\n",
            "|to provide smooth...|     US-35568389-A|in fig1 there is ...|      US-4986919-A|[provide, smooth,...|         []|\n",
            "|the method of pro...|     US-72218791-A|referring first t...|      US-5189467-A|[method, producin...|         []|\n",
            "|this invention is...|      US-3486879-A|the preferred fil...|      US-4203766-A|[invention, conce...|         []|\n",
            "|a system and meth...|     US-16248993-A|referring now to ...|      US-5483651-A|[system, method, ...|         []|\n",
            "|a sensor system f...|     US-65249710-A|the present inven...|  US-2010170788-A1|[sensor, system, ...|         []|\n",
            "|a computer system...|     US-60307503-A|the present inven...|  US-2004059865-A1|[computer, system...|         []|\n",
            "|in a defect inspe...|     US-24935905-A|with reference to...|     US-7508526-B2|[defect, inspecti...|         []|\n",
            "|a magnetic resona...|     US-84678304-A|fig1 shows an mri...|     US-7084631-B2|[magnetic, resona...|         []|\n",
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Description\n",
        "The description is the body of the patent. It's a larger body of text, so we'll work on this."
      ],
      "metadata": {
        "id": "r1MCZeXmmbsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patents_df = patents_df.withColumn(\"description_tokens\", tokenize_content_udf(\"description\"))\n",
        "patents_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgYQ1nwAnwUk",
        "outputId": "53670966-a4bb-4fb6-826f-896b14a1ec13"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+--------------------+\n",
            "|            abstract|application_number|         description|publication_number|     abstract_tokens|abstract_ne|  description_tokens|\n",
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+--------------------+\n",
            "|a probe for detec...|     US-76085585-A|referring now to ...|      US-4680475-A|[probe, detecting...|         []|[referring, drawi...|\n",
            "|an image forming ...|     US-32365908-A|in describing emb...|  US-2009136245-A1|[image, forming, ...|         []|[describing, embo...|\n",
            "|a vibrating trans...|     US-92269486-A|referring now to ...|      US-4872335-A|[vibrating, trans...|         []|[referring, accom...|\n",
            "|the present inven...|     US-26698508-A|as used herein a ...|  US-2009176244-A1|[present, inventi...|         []|[used, herein, su...|\n",
            "|an imaging record...|     US-40116089-A|referring now to ...|      US-4978974-A|[imaging, recorde...|         []|[referring, drawi...|\n",
            "|apparatus for obt...|     US-18070180-A|the invention rev...|      US-4329043-A|[apparatus, obtai...|         []|[invention, revol...|\n",
            "|liquid developers...|     US-82413577-A|liquid electrogra...|      US-4170563-A|[liquid, develope...|         []|[liquid, electrog...|\n",
            "|an apparatus for ...|     US-34700903-A|the present inven...|     US-7246255-B1|[apparatus, metho...|         []|[present, inventi...|\n",
            "|apparatus for con...| US-201514979602-A|in the detailed d...|  US-2017188019-A1|[apparatus, contr...|         []|[detailed, descri...|\n",
            "|a thread has a co...|     US-80130907-A|a worker thread u...|  US-2008282111-A1|[thread, corrupti...|         []|[worker, thread, ...|\n",
            "|apparatus and met...| US-201213475953-A|the following des...|  US-2012303195-A1|[apparatus, metho...|         []|[following, descr...|\n",
            "|an image - formin...|     US-67908376-A|typical examples ...|      US-4073651-A|[image, forming, ...|         []|[typical, example...|\n",
            "|to provide smooth...|     US-35568389-A|in fig1 there is ...|      US-4986919-A|[provide, smooth,...|         []|[shown, block, di...|\n",
            "|the method of pro...|     US-72218791-A|referring first t...|      US-5189467-A|[method, producin...|         []|[referring, first...|\n",
            "|this invention is...|      US-3486879-A|the preferred fil...|      US-4203766-A|[invention, conce...|         []|[preferred, film,...|\n",
            "|a system and meth...|     US-16248993-A|referring now to ...|      US-5483651-A|[system, method, ...|         []|[referring, shown...|\n",
            "|a sensor system f...|     US-65249710-A|the present inven...|  US-2010170788-A1|[sensor, system, ...|         []|[present, inventi...|\n",
            "|a computer system...|     US-60307503-A|the present inven...|  US-2004059865-A1|[computer, system...|         []|[present, inventi...|\n",
            "|in a defect inspe...|     US-24935905-A|with reference to...|     US-7508526-B2|[defect, inspecti...|         []|[reference, drawi...|\n",
            "|a magnetic resona...|     US-84678304-A|fig1 shows an mri...|     US-7084631-B2|[magnetic, resona...|         []|[shows, mri, arra...|\n",
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patents_df = patents_df.withColumn(\"description_ne\", get_ne_udf(\"description\"))\n",
        "patents_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFB-Vvppn7jA",
        "outputId": "b96c64e9-a24d-4849-cd89-0a0c4d28fc93"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+--------------------+--------------+\n",
            "|            abstract|application_number|         description|publication_number|     abstract_tokens|abstract_ne|  description_tokens|description_ne|\n",
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+--------------------+--------------+\n",
            "|a probe for detec...|     US-76085585-A|referring now to ...|      US-4680475-A|[probe, detecting...|         []|[referring, drawi...|            []|\n",
            "|an image forming ...|     US-32365908-A|in describing emb...|  US-2009136245-A1|[image, forming, ...|         []|[describing, embo...|            []|\n",
            "|a vibrating trans...|     US-92269486-A|referring now to ...|      US-4872335-A|[vibrating, trans...|         []|[referring, accom...|            []|\n",
            "|the present inven...|     US-26698508-A|as used herein a ...|  US-2009176244-A1|[present, inventi...|         []|[used, herein, su...|            []|\n",
            "|an imaging record...|     US-40116089-A|referring now to ...|      US-4978974-A|[imaging, recorde...|         []|[referring, drawi...|            []|\n",
            "|apparatus for obt...|     US-18070180-A|the invention rev...|      US-4329043-A|[apparatus, obtai...|         []|[invention, revol...|            []|\n",
            "|liquid developers...|     US-82413577-A|liquid electrogra...|      US-4170563-A|[liquid, develope...|         []|[liquid, electrog...|            []|\n",
            "|an apparatus for ...|     US-34700903-A|the present inven...|     US-7246255-B1|[apparatus, metho...|         []|[present, inventi...|            []|\n",
            "|apparatus for con...| US-201514979602-A|in the detailed d...|  US-2017188019-A1|[apparatus, contr...|         []|[detailed, descri...|            []|\n",
            "|a thread has a co...|     US-80130907-A|a worker thread u...|  US-2008282111-A1|[thread, corrupti...|         []|[worker, thread, ...|            []|\n",
            "|apparatus and met...| US-201213475953-A|the following des...|  US-2012303195-A1|[apparatus, metho...|         []|[following, descr...|            []|\n",
            "|an image - formin...|     US-67908376-A|typical examples ...|      US-4073651-A|[image, forming, ...|         []|[typical, example...|            []|\n",
            "|to provide smooth...|     US-35568389-A|in fig1 there is ...|      US-4986919-A|[provide, smooth,...|         []|[shown, block, di...|            []|\n",
            "|the method of pro...|     US-72218791-A|referring first t...|      US-5189467-A|[method, producin...|         []|[referring, first...|            []|\n",
            "|this invention is...|      US-3486879-A|the preferred fil...|      US-4203766-A|[invention, conce...|         []|[preferred, film,...|            []|\n",
            "|a system and meth...|     US-16248993-A|referring now to ...|      US-5483651-A|[system, method, ...|         []|[referring, shown...|            []|\n",
            "|a sensor system f...|     US-65249710-A|the present inven...|  US-2010170788-A1|[sensor, system, ...|         []|[present, inventi...|            []|\n",
            "|a computer system...|     US-60307503-A|the present inven...|  US-2004059865-A1|[computer, system...|         []|[present, inventi...|            []|\n",
            "|in a defect inspe...|     US-24935905-A|with reference to...|     US-7508526-B2|[defect, inspecti...|         []|[reference, drawi...|            []|\n",
            "|a magnetic resona...|     US-84678304-A|fig1 shows an mri...|     US-7084631-B2|[magnetic, resona...|         []|[shows, mri, arra...|            []|\n",
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+--------------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Counts\n",
        "We'll extract the top 10 terms from the abstract as a counts column."
      ],
      "metadata": {
        "id": "7O-6fY5PoOho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def get_top(tokens, *, num : int = 10):\n",
        "  return [\n",
        "      token\n",
        "      for token, _ in Counter(tokens).most_common(num)\n",
        "  ]\n",
        "\n",
        "get_top_10_udf = udf(get_top, ArrayType(StringType()))"
      ],
      "metadata": {
        "id": "qQWqfphIo9Xl"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patents_df = patents_df.withColumn(\"top_tokens\", get_top_10_udf(\"abstract_tokens\"))\n",
        "patents_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZePBDp7wo6Mt",
        "outputId": "cc77e1c1-5715-4dbc-d9b8-eeb2c6b325a3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+--------------------+--------------+--------------------+\n",
            "|            abstract|application_number|         description|publication_number|     abstract_tokens|abstract_ne|  description_tokens|description_ne|          top_tokens|\n",
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+--------------------+--------------+--------------------+\n",
            "|a probe for detec...|     US-76085585-A|referring now to ...|      US-4680475-A|[probe, detecting...|         []|[referring, drawi...|            []|[probe, phototran...|\n",
            "|an image forming ...|     US-32365908-A|in describing emb...|  US-2009136245-A1|[image, forming, ...|         []|[describing, embo...|            []|[unit, temperatur...|\n",
            "|a vibrating trans...|     US-92269486-A|referring now to ...|      US-4872335-A|[vibrating, trans...|         []|[referring, accom...|            []|[diaphragm, fluid...|\n",
            "|the present inven...|     US-26698508-A|as used herein a ...|  US-2009176244-A1|[present, inventi...|         []|[used, herein, su...|            []|[disease, methods...|\n",
            "|an imaging record...|     US-40116089-A|referring now to ...|      US-4978974-A|[imaging, recorde...|         []|[referring, drawi...|            []|[diodes, material...|\n",
            "|apparatus for obt...|     US-18070180-A|the invention rev...|      US-4329043-A|[apparatus, obtai...|         []|[invention, revol...|            []|[image, charge, c...|\n",
            "|liquid developers...|     US-82413577-A|liquid electrogra...|      US-4170563-A|[liquid, develope...|         []|[liquid, electrog...|            []|[phosphonate, moi...|\n",
            "|an apparatus for ...|     US-34700903-A|the present inven...|     US-7246255-B1|[apparatus, metho...|         []|[present, inventi...|            []|[cluster, system,...|\n",
            "|apparatus for con...| US-201514979602-A|in the detailed d...|  US-2017188019-A1|[apparatus, contr...|         []|[detailed, descri...|            []|[cameras, apparat...|\n",
            "|a thread has a co...|     US-80130907-A|a worker thread u...|  US-2008282111-A1|[thread, corrupti...|         []|[worker, thread, ...|            []|[thread, inconsis...|\n",
            "|apparatus and met...| US-201213475953-A|the following des...|  US-2012303195-A1|[apparatus, metho...|         []|[following, descr...|            []|[rider, generated...|\n",
            "|an image - formin...|     US-67908376-A|typical examples ...|      US-4073651-A|[image, forming, ...|         []|[typical, example...|            []|[group, atoms, ca...|\n",
            "|to provide smooth...|     US-35568389-A|in fig1 there is ...|      US-4986919-A|[provide, smooth,...|         []|[shown, block, di...|            []|[said, means, fee...|\n",
            "|the method of pro...|     US-72218791-A|referring first t...|      US-5189467-A|[method, producin...|         []|[referring, first...|            []|[film, template, ...|\n",
            "|this invention is...|      US-3486879-A|the preferred fil...|      US-4203766-A|[invention, conce...|         []|[preferred, film,...|            []|[invention, conce...|\n",
            "|a system and meth...|     US-16248993-A|referring now to ...|      US-5483651-A|[system, method, ...|         []|[referring, shown...|            []|[document, user, ...|\n",
            "|a sensor system f...|     US-65249710-A|the present inven...|  US-2010170788-A1|[sensor, system, ...|         []|[present, inventi...|            []|[electrodes, anti...|\n",
            "|a computer system...|     US-60307503-A|the present inven...|  US-2004059865-A1|[computer, system...|         []|[present, inventi...|            []|[system, memory, ...|\n",
            "|in a defect inspe...|     US-24935905-A|with reference to...|     US-7508526-B2|[defect, inspecti...|         []|[reference, drawi...|            []|[interference, di...|\n",
            "|a magnetic resona...|     US-84678304-A|fig1 shows an mri...|     US-7084631-B2|[magnetic, resona...|         []|[shows, mri, arra...|            []|[coil, portion, i...|\n",
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+--------------------+--------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sentence BERT\n",
        "Sentence BERT is like word2vec for sentences, we can use it to get embeddings for our abstracts."
      ],
      "metadata": {
        "id": "ep8xxD6esLlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install sentence-transformers\n",
        "!pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Xa8C1FYsYal",
        "outputId": "f1a0c4e8-e61c-48bc-b87c-27be77681d1c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.9/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (0.13.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (0.15.1+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (2.0.0+cu118)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (0.1.98)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (4.28.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (4.65.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def encode_abstract(content):\n",
        "\n",
        "  sentences = nltk.sent_tokenize(content)\n",
        "  encoding = sbert.encode(sentences)\n",
        "  return np.average(encoding, axis=0).tolist()\n",
        "\n",
        "encode_abstract_udf = udf(encode_abstract, ArrayType(FloatType()))"
      ],
      "metadata": {
        "id": "qPFuNNj5snwg"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patents_df = patents_df.withColumn(\"abstract_encoding\", encode_abstract_udf(\"abstract\"))\n",
        "patents_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVwo3KYLt7JA",
        "outputId": "a2bd4d94-d20c-43f7-8ed6-89a0c967788f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+--------------------+--------------+--------------------+--------------------+\n",
            "|            abstract|application_number|         description|publication_number|     abstract_tokens|abstract_ne|  description_tokens|description_ne|          top_tokens|   abstract_encoding|\n",
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+--------------------+--------------+--------------------+--------------------+\n",
            "|a probe for detec...|     US-76085585-A|referring now to ...|      US-4680475-A|[probe, detecting...|         []|[referring, drawi...|            []|[probe, phototran...|[0.012063969, -0....|\n",
            "|an image forming ...|     US-32365908-A|in describing emb...|  US-2009136245-A1|[image, forming, ...|         []|[describing, embo...|            []|[unit, temperatur...|[-0.061958365, -0...|\n",
            "|a vibrating trans...|     US-92269486-A|referring now to ...|      US-4872335-A|[vibrating, trans...|         []|[referring, accom...|            []|[diaphragm, fluid...|[0.0011588277, 0....|\n",
            "|the present inven...|     US-26698508-A|as used herein a ...|  US-2009176244-A1|[present, inventi...|         []|[used, herein, su...|            []|[disease, methods...|[-0.004811875, 0....|\n",
            "|an imaging record...|     US-40116089-A|referring now to ...|      US-4978974-A|[imaging, recorde...|         []|[referring, drawi...|            []|[diodes, material...|[-0.026733583, -0...|\n",
            "|apparatus for obt...|     US-18070180-A|the invention rev...|      US-4329043-A|[apparatus, obtai...|         []|[invention, revol...|            []|[image, charge, c...|[-0.051734112, -0...|\n",
            "|liquid developers...|     US-82413577-A|liquid electrogra...|      US-4170563-A|[liquid, develope...|         []|[liquid, electrog...|            []|[phosphonate, moi...|[-0.060174484, 0....|\n",
            "|an apparatus for ...|     US-34700903-A|the present inven...|     US-7246255-B1|[apparatus, metho...|         []|[present, inventi...|            []|[cluster, system,...|[-0.022635242, -0...|\n",
            "|apparatus for con...| US-201514979602-A|in the detailed d...|  US-2017188019-A1|[apparatus, contr...|         []|[detailed, descri...|            []|[cameras, apparat...|[-0.034652118, 0....|\n",
            "|a thread has a co...|     US-80130907-A|a worker thread u...|  US-2008282111-A1|[thread, corrupti...|         []|[worker, thread, ...|            []|[thread, inconsis...|[-0.058705226, 5....|\n",
            "|apparatus and met...| US-201213475953-A|the following des...|  US-2012303195-A1|[apparatus, metho...|         []|[following, descr...|            []|[rider, generated...|[-0.06763188, 0.0...|\n",
            "|an image - formin...|     US-67908376-A|typical examples ...|      US-4073651-A|[image, forming, ...|         []|[typical, example...|            []|[group, atoms, ca...|[-0.054127328, -0...|\n",
            "|to provide smooth...|     US-35568389-A|in fig1 there is ...|      US-4986919-A|[provide, smooth,...|         []|[shown, block, di...|            []|[said, means, fee...|[-0.097065106, 0....|\n",
            "|the method of pro...|     US-72218791-A|referring first t...|      US-5189467-A|[method, producin...|         []|[referring, first...|            []|[film, template, ...|[-0.047505815, 0....|\n",
            "|this invention is...|      US-3486879-A|the preferred fil...|      US-4203766-A|[invention, conce...|         []|[preferred, film,...|            []|[invention, conce...|[-0.031724524, -0...|\n",
            "|a system and meth...|     US-16248993-A|referring now to ...|      US-5483651-A|[system, method, ...|         []|[referring, shown...|            []|[document, user, ...|[-0.002999541, 0....|\n",
            "|a sensor system f...|     US-65249710-A|the present inven...|  US-2010170788-A1|[sensor, system, ...|         []|[present, inventi...|            []|[electrodes, anti...|[-0.010014094, 0....|\n",
            "|a computer system...|     US-60307503-A|the present inven...|  US-2004059865-A1|[computer, system...|         []|[present, inventi...|            []|[system, memory, ...|[-0.023403551, 0....|\n",
            "|in a defect inspe...|     US-24935905-A|with reference to...|     US-7508526-B2|[defect, inspecti...|         []|[reference, drawi...|            []|[interference, di...|[-0.048645094, -0...|\n",
            "|a magnetic resona...|     US-84678304-A|fig1 shows an mri...|     US-7084631-B2|[magnetic, resona...|         []|[shows, mri, arra...|            []|[coil, portion, i...|[0.0054146834, 0....|\n",
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+--------------------+--------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll try the same thing with just the top tokens as if they were a setences.\n"
      ],
      "metadata": {
        "id": "z6xk3vzCt-mW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_top(top_tokens):\n",
        "\n",
        "  return sbert.encode(\" \".join(top_tokens)).tolist()\n",
        "\n",
        "encode_top_udf = udf(encode_top, FloatType())"
      ],
      "metadata": {
        "id": "TkBDlM49uuLG"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patents_df = patents_df.withColumn(\"top_encoding\", encode_top_udf(\"top_tokens\"))\n",
        "patents_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi9FB2VouJTx",
        "outputId": "fc2fd783-57b1-4fc4-bde0-21c5baa7f755"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+--------------------+--------------+--------------------+--------------------+-------------+\n",
            "|            abstract|application_number|         description|publication_number|     abstract_tokens|abstract_ne|  description_tokens|description_ne|          top_tokens|   abstract_encoding| top_encoding|\n",
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+--------------------+--------------+--------------------+--------------------+-------------+\n",
            "|a probe for detec...|     US-76085585-A|referring now to ...|      US-4680475-A|[probe, detecting...|         []|[referring, drawi...|            []|[probe, phototran...|[0.012063969, -0....|  0.054035015|\n",
            "|an image forming ...|     US-32365908-A|in describing emb...|  US-2009136245-A1|[image, forming, ...|         []|[describing, embo...|            []|[unit, temperatur...|[-0.061958365, -0...| -0.060131695|\n",
            "|a vibrating trans...|     US-92269486-A|referring now to ...|      US-4872335-A|[vibrating, trans...|         []|[referring, accom...|            []|[diaphragm, fluid...|[0.0011588277, 0....|  0.060508445|\n",
            "|the present inven...|     US-26698508-A|as used herein a ...|  US-2009176244-A1|[present, inventi...|         []|[used, herein, su...|            []|[disease, methods...|[-0.004811875, 0....| -0.042503767|\n",
            "|an imaging record...|     US-40116089-A|referring now to ...|      US-4978974-A|[imaging, recorde...|         []|[referring, drawi...|            []|[diodes, material...|[-0.026733583, -0...| 0.0034499236|\n",
            "|apparatus for obt...|     US-18070180-A|the invention rev...|      US-4329043-A|[apparatus, obtai...|         []|[invention, revol...|            []|[image, charge, c...|[-0.051734112, -0...| -0.018895587|\n",
            "|liquid developers...|     US-82413577-A|liquid electrogra...|      US-4170563-A|[liquid, develope...|         []|[liquid, electrog...|            []|[phosphonate, moi...|[-0.060174484, 0....| -0.076578684|\n",
            "|an apparatus for ...|     US-34700903-A|the present inven...|     US-7246255-B1|[apparatus, metho...|         []|[present, inventi...|            []|[cluster, system,...|[-0.022635242, -0...|  -0.02280694|\n",
            "|apparatus for con...| US-201514979602-A|in the detailed d...|  US-2017188019-A1|[apparatus, contr...|         []|[detailed, descri...|            []|[cameras, apparat...|[-0.034652118, 0....| -0.024125606|\n",
            "|a thread has a co...|     US-80130907-A|a worker thread u...|  US-2008282111-A1|[thread, corrupti...|         []|[worker, thread, ...|            []|[thread, inconsis...|[-0.058705226, 5....| -0.068043336|\n",
            "|apparatus and met...| US-201213475953-A|the following des...|  US-2012303195-A1|[apparatus, metho...|         []|[following, descr...|            []|[rider, generated...|[-0.06763188, 0.0...| -0.060166094|\n",
            "|an image - formin...|     US-67908376-A|typical examples ...|      US-4073651-A|[image, forming, ...|         []|[typical, example...|            []|[group, atoms, ca...|[-0.054127328, -0...| -0.020622108|\n",
            "|to provide smooth...|     US-35568389-A|in fig1 there is ...|      US-4986919-A|[provide, smooth,...|         []|[shown, block, di...|            []|[said, means, fee...|[-0.097065106, 0....|  -0.05588253|\n",
            "|the method of pro...|     US-72218791-A|referring first t...|      US-5189467-A|[method, producin...|         []|[referring, first...|            []|[film, template, ...|[-0.047505815, 0....| -0.037167996|\n",
            "|this invention is...|      US-3486879-A|the preferred fil...|      US-4203766-A|[invention, conce...|         []|[preferred, film,...|            []|[invention, conce...|[-0.031724524, -0...| -0.037854355|\n",
            "|a system and meth...|     US-16248993-A|referring now to ...|      US-5483651-A|[system, method, ...|         []|[referring, shown...|            []|[document, user, ...|[-0.002999541, 0....|   0.00932066|\n",
            "|a sensor system f...|     US-65249710-A|the present inven...|  US-2010170788-A1|[sensor, system, ...|         []|[present, inventi...|            []|[electrodes, anti...|[-0.010014094, 0....| -0.013887621|\n",
            "|a computer system...|     US-60307503-A|the present inven...|  US-2004059865-A1|[computer, system...|         []|[present, inventi...|            []|[system, memory, ...|[-0.023403551, 0....| -0.007779897|\n",
            "|in a defect inspe...|     US-24935905-A|with reference to...|     US-7508526-B2|[defect, inspecti...|         []|[reference, drawi...|            []|[interference, di...|[-0.048645094, -0...|-0.0023377105|\n",
            "|a magnetic resona...|     US-84678304-A|fig1 shows an mri...|     US-7084631-B2|[magnetic, resona...|         []|[shows, mri, arra...|            []|[coil, portion, i...|[0.0054146834, 0....|   0.01695041|\n",
            "+--------------------+------------------+--------------------+------------------+--------------------+-----------+--------------------+--------------+--------------------+--------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Queries\n",
        "We're now going use the BERT sentence encodings to run a query. Each of the below are factories for a query."
      ],
      "metadata": {
        "id": "N-S2n3fy89ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_df = patents_df.select([\"application_number\", \"top_tokens\", \"top_encoding\", \"abstract_encoding\"])\n",
        "\n",
        "def cosine(a, b):\n",
        "  return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
        "\n",
        "def cosine_factory(left):\n",
        "  \n",
        "  def cosine_inner(right):\n",
        "\n",
        "    return cosine(left, right)\n",
        "\n",
        "  return cosine_inner\n",
        "\n",
        "def avg_cosine_factory(left_a, left_b):\n",
        "\n",
        "  left_avg = np.average([left_a, left_b], axis=0)\n",
        "\n",
        "  def avg_cosine(right_a, right_b):\n",
        "\n",
        "    right_avg = np.average([right_a, right_b], axis=0)\n",
        "\n",
        "    return cosine(left_avg, right_avg)\n",
        "  \n",
        "  return avg_cosine\n",
        "\n",
        "\n",
        "def query_by_abstract(application_number, *, df = patents_df):\n",
        "  encoding = df.where(patents_df[\"application_number\"] == application_number).collect()[0][\"abstract_encoding\"]\n",
        "  query_udf = udf(cosine_factory(encoding), ArrayType(FloatType()))\n",
        "  return df.withColumn(\"query_sim\", query_udf(\"abstract_encoding\")).orderBy(\n",
        "      ['query_sim'], \n",
        "      ascending=[False]\n",
        "  )\n",
        "\n",
        "def query_by_description(application_number, *, df = patents_df):\n",
        "  encoding = df.where(patents_df[\"application_number\"] == application_number).collect()[0][\"description_encoding\"]\n",
        "  query_udf = udf(cosine_factory(encoding), ArrayType(FloatType()))\n",
        "  return df.withColumn(\"query_sim\", query_udf(\"description_encoding\")).orderBy(\n",
        "      ['query_sim'], \n",
        "      ascending=[False]\n",
        "  )\n",
        "\n",
        "def query_by_avg(application_number, *, df = patents_df):\n",
        "  encoding = df.where(patents_df[\"application_number\"] == application_number).collect()[0][[\n",
        "      \"abstract_encoding\",\n",
        "      \"description_encoding\"\n",
        "  ]]\n",
        "  query_udf = udf(cosine_factory(encoding), ArrayType(FloatType()))\n",
        "  return df.withColumn(\"query_sim\", query_udf(\"description_encoding\")).orderBy(\n",
        "      ['query_sim'], \n",
        "      ascending=[False]\n",
        "  )\n",
        "\n",
        "# encoding_left = patents_df.where(patents_df[\"application_number\"] == \"US-76085585-A\").collect()[0][\"abstract_encoding\"]\n",
        "# encoding_right = patents_df.where(patents_df[\"application_number\"] == \"US-76085585-A\").collect()[0][\"abstract_encoding\"]\n",
        "# cosine_factory(encoding_left)(encoding_right)\n",
        "\n",
        "query_by_abstract(\"US-76085585-A\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v-JdjNvk9Dg7",
        "outputId": "b55c3151-daeb-439b-a1a2-c946e89b8a38"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-93a5ee78aba5>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# cosine_factory(encoding_left)(encoding_right)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mquery_by_abstract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"US-76085585-A\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o571.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 48.0 failed 1 times, most recent failure: Lost task 1.0 in stage 48.0 (TID 6970) (18a12fe96108 executor driver): net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for numpy.dtype). This happens when an unsupported/unregistered class is being unpickled that requires construction arguments. Fix it by registering a custom IObjectConstructor for this class.\n\tat net.razorvine.pickle.objects.ClassDictConstructor.construct(ClassDictConstructor.java:23)\n\tat net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:759)\n\tat net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:199)\n\tat net.razorvine.pickle.Unpickler.load(Unpickler.java:109)\n\tat net.razorvine.pickle.Unpickler.loads(Unpickler.java:122)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.$anonfun$evaluate$6(BatchEvalPythonExec.scala:95)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator.isEmpty(Iterator.scala:387)\n\tat scala.collection.Iterator.isEmpty$(Iterator.scala:387)\n\tat scala.collection.AbstractIterator.isEmpty(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.nonEmpty(TraversableOnce.scala:143)\n\tat scala.collection.TraversableOnce.nonEmpty$(TraversableOnce.scala:143)\n\tat scala.collection.AbstractIterator.nonEmpty(Iterator.scala:1431)\n\tat org.apache.spark.rdd.RDD.$anonfun$takeOrdered$2(RDD.scala:1529)\n\tat org.apache.spark.rdd.RDD.$anonfun$takeOrdered$2$adapted(RDD.scala:1528)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:905)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:905)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:971)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2358)\n\tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1109)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:405)\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1091)\n\tat org.apache.spark.rdd.RDD.$anonfun$takeOrdered$1(RDD.scala:1538)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:405)\n\tat org.apache.spark.rdd.RDD.takeOrdered(RDD.scala:1525)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:291)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4177)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3161)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4167)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:526)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4165)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4165)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3161)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3382)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:284)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:323)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for numpy.dtype). This happens when an unsupported/unregistered class is being unpickled that requires construction arguments. Fix it by registering a custom IObjectConstructor for this class.\n\tat net.razorvine.pickle.objects.ClassDictConstructor.construct(ClassDictConstructor.java:23)\n\tat net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:759)\n\tat net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:199)\n\tat net.razorvine.pickle.Unpickler.load(Unpickler.java:109)\n\tat net.razorvine.pickle.Unpickler.loads(Unpickler.java:122)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.$anonfun$evaluate$6(BatchEvalPythonExec.scala:95)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator.isEmpty(Iterator.scala:387)\n\tat scala.collection.Iterator.isEmpty$(Iterator.scala:387)\n\tat scala.collection.AbstractIterator.isEmpty(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.nonEmpty(TraversableOnce.scala:143)\n\tat scala.collection.TraversableOnce.nonEmpty$(TraversableOnce.scala:143)\n\tat scala.collection.AbstractIterator.nonEmpty(Iterator.scala:1431)\n\tat org.apache.spark.rdd.RDD.$anonfun$takeOrdered$2(RDD.scala:1529)\n\tat org.apache.spark.rdd.RDD.$anonfun$takeOrdered$2$adapted(RDD.scala:1528)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:905)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:905)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Most common top tokens\n",
        "Let's check on the most common top tokens, to see if we're actually getting meaningful stuff."
      ],
      "metadata": {
        "id": "cKOtXpxwJTlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "\n",
        "patents_small_df = patents_df.select([\"application_number\", \"top_tokens\"]).limit(100)\n",
        "\n",
        "patents_small_df.select('application_number', explode('top_tokens')).\\\n",
        "  groupBy('application_number','col').count().\\\n",
        "  select('application_number','col','count', rank().over(\n",
        "      Window.partitionBy('application_number').orderBy(desc('count'))\n",
        "  ).alias('rank')).\\\n",
        "  filter(col('rank')==1).\\\n",
        "  join(patents_small_df,'application_number').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "0MkcsQKPJlaC",
        "outputId": "9cd70f06-39a9-4769-cd4c-427c1675d5ed"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/usr/lib/python3.9/socket.py\", line 704, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-cc8f0cf7cf24>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpatents_small_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatents_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"application_number\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"top_tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpatents_small_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'application_number'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'top_tokens'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'application_number'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'col'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   select('application_number','col','count', rank().over(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patents_small_df.toPandas()"
      ],
      "metadata": {
        "id": "pkcI80kSNgHA",
        "outputId": "52de5f9f-1360-41a6-8b3c-3c4f5b6cb836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/usr/lib/python3.9/socket.py\", line 704, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-9ab3637b067e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpatents_small_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/pandas/conversion.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mcolumn_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \"\"\"\n\u001b[1;32m   1215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "6uu0AElSVFHe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d9pVKbQQVsbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Knowledge Graph?"
      ],
      "metadata": {
        "id": "3Sx99RCSV2lZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FsQ_vM03WDy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NLP pre-processing"
      ],
      "metadata": {
        "id": "MNQS95UeV8OU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3pwXYgseU9C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression model "
      ],
      "metadata": {
        "id": "y09EiRHMWETj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XtBg-DfqWND8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interface - liam"
      ],
      "metadata": {
        "id": "jzAcVQcbVQ6t"
      }
    }
  ]
}